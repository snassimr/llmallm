{"docstore/data": {"a122f401-8b11-430b-9e87-6721722ebb37": {"__data__": {"id_": "a122f401-8b11-430b-9e87-6721722ebb37", "embedding": null, "metadata": {"figures_content": "Contains information about Figure 1"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "091958d8-6ae8-40fd-8402-d8b87f926048", "node_type": "4", "metadata": {"file_path": "data/Llama_2_Open_Foundation_and_Fine-Tuned_Chat_Models.pdf", "file_name": "Llama_2_Open_Foundation_and_Fine-Tuned_Chat_Models.pdf", "file_type": "application/pdf", "file_size": 13661300, "creation_date": "2023-12-03", "last_modified_date": "2023-12-03", "last_accessed_date": "2023-12-05", "filename": "data/Llama_2_Open_Foundation_and_Fine-Tuned_Chat_Models.pdf"}, "hash": "cb763cc9be3bcf5f4ea72e7f5aacb267ba97761b9bcdb6a3486b62993560d070", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "2d04d12c-3c22-43a1-847b-b5fd97a8ec1f", "node_type": "1", "metadata": {"file_path": "data/Llama_2_Open_Foundation_and_Fine-Tuned_Chat_Models.pdf", "file_name": "Llama_2_Open_Foundation_and_Fine-Tuned_Chat_Models.pdf", "file_type": "application/pdf", "file_size": 13661300, "creation_date": "2023-12-03", "last_modified_date": "2023-12-03", "last_accessed_date": "2023-12-05", "filename": "data/Llama_2_Open_Foundation_and_Fine-Tuned_Chat_Models.pdf"}, "hash": "fc2709a0ee0b9ff57aa36679c06c18ce6c17099c08adbf57322f79f639e6781c", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "e0cbcf72-2326-4b0d-9115-96008c2e3394", "node_type": "1", "metadata": {}, "hash": "64e91ebeea6d9f000249c28eea33615dca16ab5cf284881091d4f45e454962bc", "class_name": "RelatedNodeInfo"}}, "hash": "dc4c2c8ea4ab41fc813c93161b38dd4d42b6b358499a0ec161916694e7850399", "text": ". . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n\n2\n\n.\n\n3\n\n5 5\n\n5\n\n7\n\n8 9\n\n9\n\n16\n\n17\n\n20 20\n\n23\n\n28\n\n29\n\n32 32\n\n34\n\n35\n\n35\n\n36\n\n46 46\n\n47\n\n51\n\n58\n\n72\n\n75\n\n77\n\n[Figure 1]: Helpfulness human evaluation results for Llama 2-Chat compared to other open-source and closed-source models. Human raters compared model generations on ~4k prompts consisting of both single and multi-turn prompts. The 95% confidence intervals for this evaluation are between 1% and 2%. More details in Section 3.4.2.", "start_char_idx": 4358, "end_char_idx": 4867, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "e0cbcf72-2326-4b0d-9115-96008c2e3394": {"__data__": {"id_": "e0cbcf72-2326-4b0d-9115-96008c2e3394", "embedding": null, "metadata": {"figures_content": "Contains information about Figure 2"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "091958d8-6ae8-40fd-8402-d8b87f926048", "node_type": "4", "metadata": {"file_path": "data/Llama_2_Open_Foundation_and_Fine-Tuned_Chat_Models.pdf", "file_name": "Llama_2_Open_Foundation_and_Fine-Tuned_Chat_Models.pdf", "file_type": "application/pdf", "file_size": 13661300, "creation_date": "2023-12-03", "last_modified_date": "2023-12-03", "last_accessed_date": "2023-12-05", "filename": "data/Llama_2_Open_Foundation_and_Fine-Tuned_Chat_Models.pdf"}, "hash": "cb763cc9be3bcf5f4ea72e7f5aacb267ba97761b9bcdb6a3486b62993560d070", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "a122f401-8b11-430b-9e87-6721722ebb37", "node_type": "1", "metadata": {"file_path": "data/Llama_2_Open_Foundation_and_Fine-Tuned_Chat_Models.pdf", "file_name": "Llama_2_Open_Foundation_and_Fine-Tuned_Chat_Models.pdf", "file_type": "application/pdf", "file_size": 13661300, "creation_date": "2023-12-03", "last_modified_date": "2023-12-03", "last_accessed_date": "2023-12-05", "filename": "data/Llama_2_Open_Foundation_and_Fine-Tuned_Chat_Models.pdf"}, "hash": "dc4c2c8ea4ab41fc813c93161b38dd4d42b6b358499a0ec161916694e7850399", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "4323001a-c479-4979-8088-51151305bf18", "node_type": "1", "metadata": {}, "hash": "4b796ae3eb43d82bc4d32449831fe6a330a13965956a3e610468facc07bd7bbf", "class_name": "RelatedNodeInfo"}}, "hash": "64e91ebeea6d9f000249c28eea33615dca16ab5cf284881091d4f45e454962bc", "text": "The 95% confidence intervals for this evaluation are between 1% and 2%. More details in Section 3.4.2. While reviewing these results, it is important to note that human evaluations can be noisy due to limitations of the prompt set, subjectivity of the review guidelines, subjectivity of individual raters, and the inherent difficulty of comparing generations.\n\n[Figure 2]: Win-rate % for helpfulness and safety between commercial-licensed base- lines and Llama 2-Chat, according to GPT- 4. To complement the human evaluation, we used a more capable model, not subject to our own guidance. Green area indicates our model is better according to GPT-4. To remove ties, we used win/(win + loss). The orders in which the model responses are presented to GPT-4 are randomly swapped to alleviate bias.", "start_char_idx": 4765, "end_char_idx": 5559, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "7577717f-1178-444d-9c39-0f08e8933e7d": {"__data__": {"id_": "7577717f-1178-444d-9c39-0f08e8933e7d", "embedding": null, "metadata": {"figures_content": "Contains information about Figure 3"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "091958d8-6ae8-40fd-8402-d8b87f926048", "node_type": "4", "metadata": {"file_path": "data/Llama_2_Open_Foundation_and_Fine-Tuned_Chat_Models.pdf", "file_name": "Llama_2_Open_Foundation_and_Fine-Tuned_Chat_Models.pdf", "file_type": "application/pdf", "file_size": 13661300, "creation_date": "2023-12-03", "last_modified_date": "2023-12-03", "last_accessed_date": "2023-12-05", "filename": "data/Llama_2_Open_Foundation_and_Fine-Tuned_Chat_Models.pdf"}, "hash": "cb763cc9be3bcf5f4ea72e7f5aacb267ba97761b9bcdb6a3486b62993560d070", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "ede0f6ad-45c9-40ae-ab00-ae10bc3db85e", "node_type": "1", "metadata": {"file_path": "data/Llama_2_Open_Foundation_and_Fine-Tuned_Chat_Models.pdf", "file_name": "Llama_2_Open_Foundation_and_Fine-Tuned_Chat_Models.pdf", "file_type": "application/pdf", "file_size": 13661300, "creation_date": "2023-12-03", "last_modified_date": "2023-12-03", "last_accessed_date": "2023-12-05", "filename": "data/Llama_2_Open_Foundation_and_Fine-Tuned_Chat_Models.pdf"}, "hash": "89ac727b4a403a79a39eb54f2dfd7130847c5eff95c80ff381395edd9498955d", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "1a6cf353-9b71-4ece-a968-628abca1e7f3", "node_type": "1", "metadata": {}, "hash": "af72ccbaefb7c3f564fa7a92541556048361f4d85191e5b1128f9c7ac278f146", "class_name": "RelatedNodeInfo"}}, "hash": "5ce836f767106fee181363dc4139e427d31ad58f3d35cd47b0440ea9439001dd", "text": "We also share novel observations we made during the development of Llama 2 and Llama 2-Chat, such as the emergence of tool usage and temporal organization of knowledge.\n\n3\n\n[Figure 3]: Safety human evaluation results for Llama 2-Chat compared to other open-source and closed- source models. Human raters judged model generations for safety violations across ~2,000 adversarial prompts consisting of both single and multi-turn prompts. More details can be found in Section 4.4. It is important to caveat these safety results with the inherent bias of LLM evaluations due to limitations of the prompt set, subjectivity of the review guidelines, and subjectivity of individual raters. Additionally, these safety evaluations are performed using content standards that are likely to be biased towards the Llama 2-Chat models.\n\nWe are releasing the following models to the general public for research and commercial use\u2021:\n\n1.", "start_char_idx": 8102, "end_char_idx": 9021, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "c50430e8-2444-4b9f-9ab9-91f5dfdd4664": {"__data__": {"id_": "c50430e8-2444-4b9f-9ab9-91f5dfdd4664", "embedding": null, "metadata": {"figures_content": "Contains information about Figure 4"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "091958d8-6ae8-40fd-8402-d8b87f926048", "node_type": "4", "metadata": {"file_path": "data/Llama_2_Open_Foundation_and_Fine-Tuned_Chat_Models.pdf", "file_name": "Llama_2_Open_Foundation_and_Fine-Tuned_Chat_Models.pdf", "file_type": "application/pdf", "file_size": 13661300, "creation_date": "2023-12-03", "last_modified_date": "2023-12-03", "last_accessed_date": "2023-12-05", "filename": "data/Llama_2_Open_Foundation_and_Fine-Tuned_Chat_Models.pdf"}, "hash": "cb763cc9be3bcf5f4ea72e7f5aacb267ba97761b9bcdb6a3486b62993560d070", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "02afee91-57b1-4f8a-9419-b02d835a9283", "node_type": "1", "metadata": {"file_path": "data/Llama_2_Open_Foundation_and_Fine-Tuned_Chat_Models.pdf", "file_name": "Llama_2_Open_Foundation_and_Fine-Tuned_Chat_Models.pdf", "file_type": "application/pdf", "file_size": 13661300, "creation_date": "2023-12-03", "last_modified_date": "2023-12-03", "last_accessed_date": "2023-12-05", "filename": "data/Llama_2_Open_Foundation_and_Fine-Tuned_Chat_Models.pdf"}, "hash": "8020d3f872c62069c89cc776275c0fd21db9ae900781f8112e32ebcce03de40a", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "d775fa49-7e2a-46b7-a538-faf790c3800a", "node_type": "1", "metadata": {}, "hash": "548349ea54555a663a669018b42f3eca2537976364cb440a5006ba3631181509", "class_name": "RelatedNodeInfo"}}, "hash": "19a37bd3c8738e0a135af70896cc56a646c9c27d4b9b1f6c45909b09ba85a0af", "text": "More details of our responsible release strategy can be found in Section 5.3.\n\nThe remainder of this paper describes our pretraining methodology (Section 2), fine-tuning methodology (Section 3), approach to model safety (Section 4), key observations and insights (Section 5), relevant related work (Section 6), and conclusions (Section 7).\n\n\u2021https://ai.meta.com/resources/models-and-libraries/llama/ \u00a7We are delaying the release of the 34B model due to a lack of time to sufficiently red team. \u00b6https://ai.meta.com/llama \u2016https://github.com/facebookresearch/llama\n\n4\n\n[Figure 4]: Training of Llama 2-Chat: This process begins with the pretraining of Llama 2 using publicly available online sources. Following this, we create an initial version of Llama 2-Chat through the application of supervised fine-tuning.", "start_char_idx": 10234, "end_char_idx": 11044, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "dace5990-ec86-4203-bad4-48f8ea3e3188": {"__data__": {"id_": "dace5990-ec86-4203-bad4-48f8ea3e3188", "embedding": null, "metadata": {"figures_content": "Contains information about Figure 5"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "091958d8-6ae8-40fd-8402-d8b87f926048", "node_type": "4", "metadata": {"file_path": "data/Llama_2_Open_Foundation_and_Fine-Tuned_Chat_Models.pdf", "file_name": "Llama_2_Open_Foundation_and_Fine-Tuned_Chat_Models.pdf", "file_type": "application/pdf", "file_size": 13661300, "creation_date": "2023-12-03", "last_modified_date": "2023-12-03", "last_accessed_date": "2023-12-05", "filename": "data/Llama_2_Open_Foundation_and_Fine-Tuned_Chat_Models.pdf"}, "hash": "cb763cc9be3bcf5f4ea72e7f5aacb267ba97761b9bcdb6a3486b62993560d070", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "e5279a49-022f-4ed2-b454-8f8799d05299", "node_type": "1", "metadata": {"file_path": "data/Llama_2_Open_Foundation_and_Fine-Tuned_Chat_Models.pdf", "file_name": "Llama_2_Open_Foundation_and_Fine-Tuned_Chat_Models.pdf", "file_type": "application/pdf", "file_size": 13661300, "creation_date": "2023-12-03", "last_modified_date": "2023-12-03", "last_accessed_date": "2023-12-05", "filename": "data/Llama_2_Open_Foundation_and_Fine-Tuned_Chat_Models.pdf"}, "hash": "fbd77dda4166617c9c56391b4d0ea819b773d95e92367e9393818d8d52513032", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "c7bd00a6-5460-4ad9-995d-b6afd0706f04", "node_type": "1", "metadata": {}, "hash": "835ed5516ab52a79d09d9b0cf45629e3687973041402b38cf7568298ae7ef996", "class_name": "RelatedNodeInfo"}}, "hash": "d2b4d6df3bc2d86c4ad72f1d47e37931a923e4b6a4a8c924e3b9b46e63881559", "text": "We use a cosine learning rate schedule, with warmup of 2000 steps, and decay final learning rate down to 10% of the peak learning rate. We use a weight decay of 0.1 and gradient clipping of 1.0. [Figure 5] (a) shows the training loss for Llama 2 with these hyperparameters.\n\n5\n\nLlama 1\n\nLlama 2\n\nTraining Data\n\nSee Touvron et al.", "start_char_idx": 13363, "end_char_idx": 13692, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "3c0e6ffc-ca0a-4672-ae04-a9ffe2400fed": {"__data__": {"id_": "3c0e6ffc-ca0a-4672-ae04-a9ffe2400fed", "embedding": null, "metadata": {"figures_content": "Contains information about Figure 5"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "091958d8-6ae8-40fd-8402-d8b87f926048", "node_type": "4", "metadata": {"file_path": "data/Llama_2_Open_Foundation_and_Fine-Tuned_Chat_Models.pdf", "file_name": "Llama_2_Open_Foundation_and_Fine-Tuned_Chat_Models.pdf", "file_type": "application/pdf", "file_size": 13661300, "creation_date": "2023-12-03", "last_modified_date": "2023-12-03", "last_accessed_date": "2023-12-05", "filename": "data/Llama_2_Open_Foundation_and_Fine-Tuned_Chat_Models.pdf"}, "hash": "cb763cc9be3bcf5f4ea72e7f5aacb267ba97761b9bcdb6a3486b62993560d070", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "c7bd00a6-5460-4ad9-995d-b6afd0706f04", "node_type": "1", "metadata": {"file_path": "data/Llama_2_Open_Foundation_and_Fine-Tuned_Chat_Models.pdf", "file_name": "Llama_2_Open_Foundation_and_Fine-Tuned_Chat_Models.pdf", "file_type": "application/pdf", "file_size": 13661300, "creation_date": "2023-12-03", "last_modified_date": "2023-12-03", "last_accessed_date": "2023-12-05", "filename": "data/Llama_2_Open_Foundation_and_Fine-Tuned_Chat_Models.pdf"}, "hash": "835ed5516ab52a79d09d9b0cf45629e3687973041402b38cf7568298ae7ef996", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "b37177e0-c94b-45ab-ab54-41d2d6d6e3ce", "node_type": "1", "metadata": {}, "hash": "77909aabb6705ed847f69a1df229de2d11493b10b6f4148c6d1d2c9dce98157e", "class_name": "RelatedNodeInfo"}}, "hash": "79ff829f4c06b701fc3589311b207cf91e1593b7a123edec40f790fefcc358fc", "text": "Token counts refer to pretraining data only. All models are trained with a global batch-size of 4M tokens. Bigger models \u2014 34B and 70B \u2014 use Grouped-Query Attention (GQA) for improved inference scalability.\n\n1500\n\n34B\n\n1.9\n\n1.6\n\n7B\n\n70B\n\n2.0\n\n500\n\n1750\n\n1.4\n\n250\n\n13B\n\n1250\n\n2.2Train PPL\n\n750\n\n2000Processed Tokens (Billions)\n\n1000\n\n0\n\n1.8\n\n1.5\n\nLlama-2\n\n2.1\n\n1.7\n\n[Figure 5]: Training Loss for Llama 2 models. We compare the training loss of the Llama 2 family of models. We observe that after pretraining on 2T Tokens, the models still did not show any sign of saturation.\n\nTokenizer.", "start_char_idx": 14028, "end_char_idx": 14614, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "63b12fff-60ff-4d1a-a176-b3944e92d178": {"__data__": {"id_": "63b12fff-60ff-4d1a-a176-b3944e92d178", "embedding": null, "metadata": {"figures_content": "Contains information about Figure 20"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "091958d8-6ae8-40fd-8402-d8b87f926048", "node_type": "4", "metadata": {"file_path": "data/Llama_2_Open_Foundation_and_Fine-Tuned_Chat_Models.pdf", "file_name": "Llama_2_Open_Foundation_and_Fine-Tuned_Chat_Models.pdf", "file_type": "application/pdf", "file_size": 13661300, "creation_date": "2023-12-03", "last_modified_date": "2023-12-03", "last_accessed_date": "2023-12-05", "filename": "data/Llama_2_Open_Foundation_and_Fine-Tuned_Chat_Models.pdf"}, "hash": "cb763cc9be3bcf5f4ea72e7f5aacb267ba97761b9bcdb6a3486b62993560d070", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "29f6be79-a61b-44e5-a62a-7a6aa8643647", "node_type": "1", "metadata": {"file_path": "data/Llama_2_Open_Foundation_and_Fine-Tuned_Chat_Models.pdf", "file_name": "Llama_2_Open_Foundation_and_Fine-Tuned_Chat_Models.pdf", "file_type": "application/pdf", "file_size": 13661300, "creation_date": "2023-12-03", "last_modified_date": "2023-12-03", "last_accessed_date": "2023-12-05", "filename": "data/Llama_2_Open_Foundation_and_Fine-Tuned_Chat_Models.pdf"}, "hash": "245be462f5d099e0567dd44f32a92fdbafe915cbf2f09a3c09ce8c460ff7addc", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "f22e4685-fe0b-431b-af9f-4b2fb7b770b1", "node_type": "1", "metadata": {}, "hash": "12442afd48a14c4e31a890af170af79bf7faf46994e3836ffc21216cdc0127bb", "class_name": "RelatedNodeInfo"}}, "hash": "be0506bc7b11ed79d695ca315d9dd818b9f52cb46b89ea9e9b0e0c7e4412ddf9", "text": "We do not include any examples where the chosen response was unsafe and the other response safe, as we believe safer responses will also be better/preferred by humans. Safety guidelines and more detailed information regarding safety annotations can be found in Section 4.2.1.\n\nHuman annotations were collected in batches on a weekly basis. As we collected more preference data, our reward models improved, and we were able to train progressively better versions for Llama 2-Chat (see the results in Section 5, [Figure 20]). Llama 2-Chat improvement also shifted the model\u2019s data distribution. Since reward model accuracy can quickly degrade if not exposed to this new sample distribution, i.e., from hyper-specialization (Scialom et al., 2020b), it is important before a new Llama 2-Chat tuning iteration to gather new preference data using the latest Llama 2-Chat iterations. This step helps keep the reward model on-distribution and maintain an accurate reward for the latest model.", "start_char_idx": 29221, "end_char_idx": 30205, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "20418150-3c0e-48e4-82b4-76d1d1ff5468": {"__data__": {"id_": "20418150-3c0e-48e4-82b4-76d1d1ff5468", "embedding": null, "metadata": {"figures_content": "Contains information about Figure 6"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "091958d8-6ae8-40fd-8402-d8b87f926048", "node_type": "4", "metadata": {"file_path": "data/Llama_2_Open_Foundation_and_Fine-Tuned_Chat_Models.pdf", "file_name": "Llama_2_Open_Foundation_and_Fine-Tuned_Chat_Models.pdf", "file_type": "application/pdf", "file_size": 13661300, "creation_date": "2023-12-03", "last_modified_date": "2023-12-03", "last_accessed_date": "2023-12-05", "filename": "data/Llama_2_Open_Foundation_and_Fine-Tuned_Chat_Models.pdf"}, "hash": "cb763cc9be3bcf5f4ea72e7f5aacb267ba97761b9bcdb6a3486b62993560d070", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "09d7683b-e55f-4f06-a23e-df6cef249a39", "node_type": "1", "metadata": {"file_path": "data/Llama_2_Open_Foundation_and_Fine-Tuned_Chat_Models.pdf", "file_name": "Llama_2_Open_Foundation_and_Fine-Tuned_Chat_Models.pdf", "file_type": "application/pdf", "file_size": 13661300, "creation_date": "2023-12-03", "last_modified_date": "2023-12-03", "last_accessed_date": "2023-12-05", "filename": "data/Llama_2_Open_Foundation_and_Fine-Tuned_Chat_Models.pdf"}, "hash": "e2bd841c2e11c1dc1882203f124c7835a673c51220ff1ecf48240990da22625a", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "9fb32cb6-718b-4faf-9cee-8cdbcded0830", "node_type": "1", "metadata": {}, "hash": "f54c061e2697887a6511a04107ea344544e5556d03955467b806aa3b240ff85d", "class_name": "RelatedNodeInfo"}}, "hash": "adfaa0d313a7cdc90afcda4db3c4714136cc0cd05ca9bfbbc97f00c74a0d4516", "text": "Interestingly, GPT-4 performs better than other non-Meta reward models, despite not being trained directly nor targeting specifically this reward modeling task.\n\n12\n\n3\n\n0.52\n\n9\n\n8\n\n8\n\n13\n\n13\n\n0.65\n\n10\n\n10\n\n4\n\n7\n\n4\n\nGPT4\n\n9\n\n11\n\n13b\n\n13b\n\n0.62\n\n0.70\n\n12\n\n12\n\n1\n\n3\n\n7\n\n70b\n\n0.58\n\n14Meta Helpfulness Data Batch Stage\n\n11\n\nGPT4\n\n14Meta Helpfulness Data Batch Stage\n\nOpenAssistant\n\nOpenAssistant\n\n0.60\n\n0.60\n\n7b\n\n7b\n\n0.80Accuracy On Examples With Label \"Significantly Better\"\n\n1\n\n0.56\n\n0.75\n\n2\n\n70b\n\n0.54\n\n2\n\n6\n\n6\n\n5\n\n5\n\n0.64Accuracy On All Examples\n\n0.50\n\n0.55\n\n[Figure 6]: Scaling trends for the reward model.", "start_char_idx": 39874, "end_char_idx": 40480, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "a2e0e182-59cb-4846-b349-b4d1924430ef": {"__data__": {"id_": "a2e0e182-59cb-4846-b349-b4d1924430ef", "embedding": null, "metadata": {"figures_content": "Contains information about Figure 6"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "091958d8-6ae8-40fd-8402-d8b87f926048", "node_type": "4", "metadata": {"file_path": "data/Llama_2_Open_Foundation_and_Fine-Tuned_Chat_Models.pdf", "file_name": "Llama_2_Open_Foundation_and_Fine-Tuned_Chat_Models.pdf", "file_type": "application/pdf", "file_size": 13661300, "creation_date": "2023-12-03", "last_modified_date": "2023-12-03", "last_accessed_date": "2023-12-05", "filename": "data/Llama_2_Open_Foundation_and_Fine-Tuned_Chat_Models.pdf"}, "hash": "cb763cc9be3bcf5f4ea72e7f5aacb267ba97761b9bcdb6a3486b62993560d070", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "9fb32cb6-718b-4faf-9cee-8cdbcded0830", "node_type": "1", "metadata": {"file_path": "data/Llama_2_Open_Foundation_and_Fine-Tuned_Chat_Models.pdf", "file_name": "Llama_2_Open_Foundation_and_Fine-Tuned_Chat_Models.pdf", "file_type": "application/pdf", "file_size": 13661300, "creation_date": "2023-12-03", "last_modified_date": "2023-12-03", "last_accessed_date": "2023-12-05", "filename": "data/Llama_2_Open_Foundation_and_Fine-Tuned_Chat_Models.pdf"}, "hash": "f54c061e2697887a6511a04107ea344544e5556d03955467b806aa3b240ff85d", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "51b5cb37-fe2f-44bd-a8d1-a2be59aaed10", "node_type": "1", "metadata": {}, "hash": "81a951d2f5043e119ce6907a4da04b8b0290cb7f0549e308978cc4be9b3ff6fa", "class_name": "RelatedNodeInfo"}}, "hash": "0a271d775392c925f6a0048aae0f74d2bfe4f8df7da7da720717c17c89806468", "text": "It is expected that learning to model human preferences becomes challenging when deciding between two similar model responses, due to annotator subjectivity and their reliance on nuanced details that may differentiate responses. We emphasize that the accuracy on more distinct responses matters the most to improve Llama 2-Chat performance. The human preference annotation agreement rate is also higher on more distinct responses than similar pairs.\n\nScaling Trends. We study the scaling trends in terms of data and model size for the reward model, fine- tuning different model sizes on an increasing amount of the reward model data collected each week (see the details on volume per batch in Table 26). [Figure 6] reports these trends, showing the expected result that larger models obtain higher performance for a similar volume of data. More importantly, the scaling performance has not yet plateaued given the existing volume of data annotation used for training, a signal that there is room for more improvement with more annotations.", "start_char_idx": 41511, "end_char_idx": 42550, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "e8827413-8fd0-495d-a064-5c5589497973": {"__data__": {"id_": "e8827413-8fd0-495d-a064-5c5589497973", "embedding": null, "metadata": {"figures_content": "Contains information about Figure 7"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "091958d8-6ae8-40fd-8402-d8b87f926048", "node_type": "4", "metadata": {"file_path": "data/Llama_2_Open_Foundation_and_Fine-Tuned_Chat_Models.pdf", "file_name": "Llama_2_Open_Foundation_and_Fine-Tuned_Chat_Models.pdf", "file_type": "application/pdf", "file_size": 13661300, "creation_date": "2023-12-03", "last_modified_date": "2023-12-03", "last_accessed_date": "2023-12-05", "filename": "data/Llama_2_Open_Foundation_and_Fine-Tuned_Chat_Models.pdf"}, "hash": "cb763cc9be3bcf5f4ea72e7f5aacb267ba97761b9bcdb6a3486b62993560d070", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "51b5cb37-fe2f-44bd-a8d1-a2be59aaed10", "node_type": "1", "metadata": {"file_path": "data/Llama_2_Open_Foundation_and_Fine-Tuned_Chat_Models.pdf", "file_name": "Llama_2_Open_Foundation_and_Fine-Tuned_Chat_Models.pdf", "file_type": "application/pdf", "file_size": 13661300, "creation_date": "2023-12-03", "last_modified_date": "2023-12-03", "last_accessed_date": "2023-12-05", "filename": "data/Llama_2_Open_Foundation_and_Fine-Tuned_Chat_Models.pdf"}, "hash": "81a951d2f5043e119ce6907a4da04b8b0290cb7f0549e308978cc4be9b3ff6fa", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "9741d5b1-9e3a-44ee-81cd-1d19ef95de76", "node_type": "1", "metadata": {}, "hash": "b2d73d6c756dad7ce0b31a9f1077228784316b24288a5d40554378da1f04dc3c", "class_name": "RelatedNodeInfo"}}, "hash": "888b7b35fff9a869a24b46e428f8ae28307a52a69cfb1c3ec55cb770362da6aa", "text": "\u2022 Rejection Sampling fine-tuning. We sample K outputs from the model and select the best candidate with our reward, consistent with Bai et al. (2022b). The same re-ranking strategy for LLMs was also proposed in Deng et al. (2019), where the reward is seen as an energy function. Here, we go one step further, and use the selected outputs for a gradient update. For each prompt, the sample obtaining\n\n13\n\n0.62\n\nMax of the rewards\n\n0.66Reward Score\n\n101N Samples\n\nMedian of the rewards\n\n0.58\n\n0.54\n\n0.60\n\n0.56\n\n100\n\n0.64\n\n[Figure 7]: Max and median reward among N samples, N \u2208 [1, . . . , 100] averaged over our training set of prompts. The delta between max and median can be interpreted as potential gain with Rejection Sampling.\n\nthe highest reward score is considered the new gold standard.", "start_char_idx": 43374, "end_char_idx": 44166, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "a68299e3-5abe-45c0-8f6c-4ec8be6b3437": {"__data__": {"id_": "a68299e3-5abe-45c0-8f6c-4ec8be6b3437", "embedding": null, "metadata": {"figures_content": "Contains information about Figure 8"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "091958d8-6ae8-40fd-8402-d8b87f926048", "node_type": "4", "metadata": {"file_path": "data/Llama_2_Open_Foundation_and_Fine-Tuned_Chat_Models.pdf", "file_name": "Llama_2_Open_Foundation_and_Fine-Tuned_Chat_Models.pdf", "file_type": "application/pdf", "file_size": 13661300, "creation_date": "2023-12-03", "last_modified_date": "2023-12-03", "last_accessed_date": "2023-12-05", "filename": "data/Llama_2_Open_Foundation_and_Fine-Tuned_Chat_Models.pdf"}, "hash": "cb763cc9be3bcf5f4ea72e7f5aacb267ba97761b9bcdb6a3486b62993560d070", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "f20cde5b-899e-455b-84d7-921fa04afdcc", "node_type": "1", "metadata": {"file_path": "data/Llama_2_Open_Foundation_and_Fine-Tuned_Chat_Models.pdf", "file_name": "Llama_2_Open_Foundation_and_Fine-Tuned_Chat_Models.pdf", "file_type": "application/pdf", "file_size": 13661300, "creation_date": "2023-12-03", "last_modified_date": "2023-12-03", "last_accessed_date": "2023-12-05", "filename": "data/Llama_2_Open_Foundation_and_Fine-Tuned_Chat_Models.pdf"}, "hash": "d1423a43d69bbe33a9c653a63e2abf7f5374f98f4b99c02f0dc708ff1b20f531", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "4d5f7e38-065f-4b94-b885-f21ec9a68e3f", "node_type": "1", "metadata": {}, "hash": "bee25cca7e24255f3cc621a390d60d060fa7bd551aa81652d029ef7b20608578", "class_name": "RelatedNodeInfo"}}, "hash": "cec1ea313dc8b2a87950ed5e66fa365085cd5022d7f8fc3d873fde70581c67a8", "text": "100\n\n0.1\n\n0.2\n\n0.4\n\n0.6Reward Score\n\nSFT\n\n0.3\n\n102Number Samples\n\n101\n\n0.5\n\nreward_max (T=1.3)\n\nreward_max (T=1.1)\n\nreward_max (T=0.6)\n\nreward_max (T=1)\n\nRLHF\n\nreward_max (T=0.8)\n\nreward_max (T=1.4)\n\nreward_max (T=1.5)\n\n0.60\n\n100\n\n0.40\n\n0.35\n\n0.70Reward Score\n\nreward_max (T=0.9)\n\n0.45\n\n0.65\n\nreward_max (T=1.2)\n\n102Number Samples\n\n101\n\n0.55\n\n0.50\n\n[Figure 8]: RLHF impact of the temperature when sampling N outputs and scoring them with a reward model.\n\nRejection Sampling. We perform rejection sampling only with our largest 70B Llama 2-Chat.", "start_char_idx": 45116, "end_char_idx": 45660, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "5081308d-89b7-4b49-888b-354d642e558c": {"__data__": {"id_": "5081308d-89b7-4b49-888b-354d642e558c", "embedding": null, "metadata": {"figures_content": "Contains information about Figure 7"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "091958d8-6ae8-40fd-8402-d8b87f926048", "node_type": "4", "metadata": {"file_path": "data/Llama_2_Open_Foundation_and_Fine-Tuned_Chat_Models.pdf", "file_name": "Llama_2_Open_Foundation_and_Fine-Tuned_Chat_Models.pdf", "file_type": "application/pdf", "file_size": 13661300, "creation_date": "2023-12-03", "last_modified_date": "2023-12-03", "last_accessed_date": "2023-12-05", "filename": "data/Llama_2_Open_Foundation_and_Fine-Tuned_Chat_Models.pdf"}, "hash": "cb763cc9be3bcf5f4ea72e7f5aacb267ba97761b9bcdb6a3486b62993560d070", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "4d5f7e38-065f-4b94-b885-f21ec9a68e3f", "node_type": "1", "metadata": {"file_path": "data/Llama_2_Open_Foundation_and_Fine-Tuned_Chat_Models.pdf", "file_name": "Llama_2_Open_Foundation_and_Fine-Tuned_Chat_Models.pdf", "file_type": "application/pdf", "file_size": 13661300, "creation_date": "2023-12-03", "last_modified_date": "2023-12-03", "last_accessed_date": "2023-12-05", "filename": "data/Llama_2_Open_Foundation_and_Fine-Tuned_Chat_Models.pdf"}, "hash": "bee25cca7e24255f3cc621a390d60d060fa7bd551aa81652d029ef7b20608578", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "b35ddc9b-9f49-49b3-9c57-617530f718f2", "node_type": "1", "metadata": {}, "hash": "ac0f10252a4de37ae41f4e3363a7e12ce45df85ae75c485729b9ea42def61e68", "class_name": "RelatedNodeInfo"}}, "hash": "e7b46d0834ada5630af4697c8f71a17fce3f11fabc16917a0d8fe5c7b83c8163", "text": "However, despite continuous improvement, this method led to a\n\n14\n\nregression in some capabilities. For example, RLHF V3 struggled more than previous versions to compose rhyming lines in poems, as discerned through qualitative analysis, suggesting that further investigation into the causes of and mitigations for forgetting (Kirkpatrick et al., 2017; Nguyen et al., 2019; Ramasesh et al., 2021) could be a fruitful area for additional future research.\n\nIn response, on subsequent iterations, we modified our strategy, incorporating top-performing samples from all prior iterations, such as those used in RLHF-V1 and RLHF-V2. Although we do not present specific figures, this adjustment demonstrated considerable enhancements in performance and effectively addressed the previously noted issues. This mitigation can be seen as analogous to Synnaeve et al. (2019) and Vinyals et al. (2019) in the RL literature.\n\nWe illustrate the benefit of Rejection Sampling in [Figure 7].", "start_char_idx": 46353, "end_char_idx": 47327, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "b35ddc9b-9f49-49b3-9c57-617530f718f2": {"__data__": {"id_": "b35ddc9b-9f49-49b3-9c57-617530f718f2", "embedding": null, "metadata": {"figures_content": "Contains information about Figure 7 and Figure 8"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "091958d8-6ae8-40fd-8402-d8b87f926048", "node_type": "4", "metadata": {"file_path": "data/Llama_2_Open_Foundation_and_Fine-Tuned_Chat_Models.pdf", "file_name": "Llama_2_Open_Foundation_and_Fine-Tuned_Chat_Models.pdf", "file_type": "application/pdf", "file_size": 13661300, "creation_date": "2023-12-03", "last_modified_date": "2023-12-03", "last_accessed_date": "2023-12-05", "filename": "data/Llama_2_Open_Foundation_and_Fine-Tuned_Chat_Models.pdf"}, "hash": "cb763cc9be3bcf5f4ea72e7f5aacb267ba97761b9bcdb6a3486b62993560d070", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "5081308d-89b7-4b49-888b-354d642e558c", "node_type": "1", "metadata": {"file_path": "data/Llama_2_Open_Foundation_and_Fine-Tuned_Chat_Models.pdf", "file_name": "Llama_2_Open_Foundation_and_Fine-Tuned_Chat_Models.pdf", "file_type": "application/pdf", "file_size": 13661300, "creation_date": "2023-12-03", "last_modified_date": "2023-12-03", "last_accessed_date": "2023-12-05", "filename": "data/Llama_2_Open_Foundation_and_Fine-Tuned_Chat_Models.pdf"}, "hash": "e7b46d0834ada5630af4697c8f71a17fce3f11fabc16917a0d8fe5c7b83c8163", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "1016e8c4-0a71-4604-a0d6-5bca4a025b2b", "node_type": "1", "metadata": {}, "hash": "d157ee135dbcf63da4b9025243fab79984672265650a400e98d54bc3193ccd40", "class_name": "RelatedNodeInfo"}}, "hash": "ac0f10252a4de37ae41f4e3363a7e12ce45df85ae75c485729b9ea42def61e68", "text": "(2019) in the RL literature.\n\nWe illustrate the benefit of Rejection Sampling in [Figure 7]. The delta between the maximum and median curves can be interpreted as the potential gain of fine-tuning on the best output. As expected, this delta increases with more samples, since the maximum increases (i.e., more samples, more opportunities to generate a good trajectory), while the median remains stationary. There is a direct connection between the exploration and the maximum reward we can obtain among the samples. The temperature parameter also plays an important role for exploration, as a higher temperature enables us to sample more diverse outputs.\n\nIn [Figure 8], we report for a Llama 2-Chat-SFT (left) and a Llama 2-Chat-RLHF (right), the maximum reward curves among N samples (with N \u2208 [1, . . . , 100]), for different temperatures.", "start_char_idx": 47235, "end_char_idx": 48077, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "5fa8db21-9f34-4ff3-a878-a7208c9e7b04": {"__data__": {"id_": "5fa8db21-9f34-4ff3-a878-a7208c9e7b04", "embedding": null, "metadata": {"figures_content": "Contains information about Figure 9"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "091958d8-6ae8-40fd-8402-d8b87f926048", "node_type": "4", "metadata": {"file_path": "data/Llama_2_Open_Foundation_and_Fine-Tuned_Chat_Models.pdf", "file_name": "Llama_2_Open_Foundation_and_Fine-Tuned_Chat_Models.pdf", "file_type": "application/pdf", "file_size": 13661300, "creation_date": "2023-12-03", "last_modified_date": "2023-12-03", "last_accessed_date": "2023-12-05", "filename": "data/Llama_2_Open_Foundation_and_Fine-Tuned_Chat_Models.pdf"}, "hash": "cb763cc9be3bcf5f4ea72e7f5aacb267ba97761b9bcdb6a3486b62993560d070", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "4fc00198-9f8a-4035-9b90-280234ab802a", "node_type": "1", "metadata": {"file_path": "data/Llama_2_Open_Foundation_and_Fine-Tuned_Chat_Models.pdf", "file_name": "Llama_2_Open_Foundation_and_Fine-Tuned_Chat_Models.pdf", "file_type": "application/pdf", "file_size": 13661300, "creation_date": "2023-12-03", "last_modified_date": "2023-12-03", "last_accessed_date": "2023-12-05", "filename": "data/Llama_2_Open_Foundation_and_Fine-Tuned_Chat_Models.pdf"}, "hash": "fec1e11465151083fb599e76eb1322a43f884d27e6d1c07bcbc88c62ee9696ae", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "298cc13c-3155-4410-897a-60fb551d6836", "node_type": "1", "metadata": {}, "hash": "2140cf56c4e564850c3c5e8305412f9bd2e4e2e41ac82fc057deb4b56a0547ff", "class_name": "RelatedNodeInfo"}}, "hash": "5cfa88fb42da7a26fecc40b3b29ea2e39acbc788a85a9e61b9df2b8213c08925", "text": "For the 7B and 13B models, we set \u03b2 = 0.01 (KL penalty), and for the 34B and 70B models, we set \u03b2 = 0.005.\n\n15\n\n(3)\n\n(4)\n\n[Figure 9]: Issues with multi-turn memory (left) can be improved with GAtt (right).\n\nWe train for between 200 and 400 iterations for all our models, and use evaluations on held-out prompts for early stopping. Each iteration of PPO on the 70B model takes on average \u2248 330 seconds. To train quickly with large batch sizes, we use FSDP (Zhao et al., 2023). This was effective when using O(1) forward or backward passes, but caused a large slow down (\u2248 20\u00d7) during generation, even when using a large batch size and KV cache.", "start_char_idx": 50643, "end_char_idx": 51286, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "298cc13c-3155-4410-897a-60fb551d6836": {"__data__": {"id_": "298cc13c-3155-4410-897a-60fb551d6836", "embedding": null, "metadata": {"figures_content": "Contains information about Figure 9 and Figure 9"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "091958d8-6ae8-40fd-8402-d8b87f926048", "node_type": "4", "metadata": {"file_path": "data/Llama_2_Open_Foundation_and_Fine-Tuned_Chat_Models.pdf", "file_name": "Llama_2_Open_Foundation_and_Fine-Tuned_Chat_Models.pdf", "file_type": "application/pdf", "file_size": 13661300, "creation_date": "2023-12-03", "last_modified_date": "2023-12-03", "last_accessed_date": "2023-12-05", "filename": "data/Llama_2_Open_Foundation_and_Fine-Tuned_Chat_Models.pdf"}, "hash": "cb763cc9be3bcf5f4ea72e7f5aacb267ba97761b9bcdb6a3486b62993560d070", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "5fa8db21-9f34-4ff3-a878-a7208c9e7b04", "node_type": "1", "metadata": {"file_path": "data/Llama_2_Open_Foundation_and_Fine-Tuned_Chat_Models.pdf", "file_name": "Llama_2_Open_Foundation_and_Fine-Tuned_Chat_Models.pdf", "file_type": "application/pdf", "file_size": 13661300, "creation_date": "2023-12-03", "last_modified_date": "2023-12-03", "last_accessed_date": "2023-12-05", "filename": "data/Llama_2_Open_Foundation_and_Fine-Tuned_Chat_Models.pdf"}, "hash": "5cfa88fb42da7a26fecc40b3b29ea2e39acbc788a85a9e61b9df2b8213c08925", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "9a0b26c4-9ddb-46d4-9201-5f910bd3a586", "node_type": "1", "metadata": {}, "hash": "d560f19c59b5f730ed25c0aa3f0c061834d2639bd8ca812b4effe0ea29fe494a", "class_name": "RelatedNodeInfo"}}, "hash": "2140cf56c4e564850c3c5e8305412f9bd2e4e2e41ac82fc057deb4b56a0547ff", "text": "We were able to mitigate this by consolidating the model weights to each node once before generation and then freeing the memory after generation, resuming the rest of the training loop.\n\n3.3 System Message for Multi-Turn Consistency\n\nIn a dialogue setup, some instructions should apply for all the conversation turns, e.g., to respond succinctly, or to \u201cact as\u201d some public figure. When we provided such instructions to Llama 2-Chat, the subsequent response should always respect the constraint. However, our initial RLHF models tended to forget the initial instruction after a few turns of dialogue, as illustrated in [Figure 9] (left).\n\nTo address these limitations, we propose Ghost Attention (GAtt), a very simple method inspired by Context Distillation (Bai et al., 2022b) that hacks the fine-tuning data to help the attention focus in a multi-stage process. GAtt enables dialogue control over multiple turns, as illustrated in [Figure 9] (right).\n\nGAtt Method.", "start_char_idx": 51287, "end_char_idx": 52254, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "9a0b26c4-9ddb-46d4-9201-5f910bd3a586": {"__data__": {"id_": "9a0b26c4-9ddb-46d4-9201-5f910bd3a586", "embedding": null, "metadata": {"figures_content": "Contains information about Figure 9"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "091958d8-6ae8-40fd-8402-d8b87f926048", "node_type": "4", "metadata": {"file_path": "data/Llama_2_Open_Foundation_and_Fine-Tuned_Chat_Models.pdf", "file_name": "Llama_2_Open_Foundation_and_Fine-Tuned_Chat_Models.pdf", "file_type": "application/pdf", "file_size": 13661300, "creation_date": "2023-12-03", "last_modified_date": "2023-12-03", "last_accessed_date": "2023-12-05", "filename": "data/Llama_2_Open_Foundation_and_Fine-Tuned_Chat_Models.pdf"}, "hash": "cb763cc9be3bcf5f4ea72e7f5aacb267ba97761b9bcdb6a3486b62993560d070", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "298cc13c-3155-4410-897a-60fb551d6836", "node_type": "1", "metadata": {"file_path": "data/Llama_2_Open_Foundation_and_Fine-Tuned_Chat_Models.pdf", "file_name": "Llama_2_Open_Foundation_and_Fine-Tuned_Chat_Models.pdf", "file_type": "application/pdf", "file_size": 13661300, "creation_date": "2023-12-03", "last_modified_date": "2023-12-03", "last_accessed_date": "2023-12-05", "filename": "data/Llama_2_Open_Foundation_and_Fine-Tuned_Chat_Models.pdf"}, "hash": "2140cf56c4e564850c3c5e8305412f9bd2e4e2e41ac82fc057deb4b56a0547ff", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "f088f29a-ce8a-42e5-bc30-9a54c51f86c4", "node_type": "1", "metadata": {}, "hash": "e50acf65c90e032add0ecec8de46a1776eef8f1e1952807150cf4e1c901c9209", "class_name": "RelatedNodeInfo"}}, "hash": "d560f19c59b5f730ed25c0aa3f0c061834d2639bd8ca812b4effe0ea29fe494a", "text": "GAtt enables dialogue control over multiple turns, as illustrated in [Figure 9] (right).\n\nGAtt Method. Assume we have access to a multi-turn dialogue dataset between two persons (e.g., a user and an assistant), with a list of messages [u1, a1, . . . , un, an], where un and an correspond to the user and assistant messages for turn n, respectively. Then, we define an instruction, inst, that should be respected throughout the dialogue. For example, inst could be \u201cact as.\u201d We can then synthetically concatenate this instruction to all the user messages of the conversation.\n\nNext, we can sample from this synthetic data using the latest RLHF model. We now have a context-dialogue and the sample with which to fine-tune a model, in a process analogous to Rejection Sampling.", "start_char_idx": 52152, "end_char_idx": 52926, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "d4d5d082-d14a-4700-9cca-9adf2a849c97": {"__data__": {"id_": "d4d5d082-d14a-4700-9cca-9adf2a849c97", "embedding": null, "metadata": {"figures_content": "Contains information about Figure 28"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "091958d8-6ae8-40fd-8402-d8b87f926048", "node_type": "4", "metadata": {"file_path": "data/Llama_2_Open_Foundation_and_Fine-Tuned_Chat_Models.pdf", "file_name": "Llama_2_Open_Foundation_and_Fine-Tuned_Chat_Models.pdf", "file_type": "application/pdf", "file_size": 13661300, "creation_date": "2023-12-03", "last_modified_date": "2023-12-03", "last_accessed_date": "2023-12-05", "filename": "data/Llama_2_Open_Foundation_and_Fine-Tuned_Chat_Models.pdf"}, "hash": "cb763cc9be3bcf5f4ea72e7f5aacb267ba97761b9bcdb6a3486b62993560d070", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "5e5b6845-5b76-45c4-9c5b-1f4151436f32", "node_type": "1", "metadata": {"file_path": "data/Llama_2_Open_Foundation_and_Fine-Tuned_Chat_Models.pdf", "file_name": "Llama_2_Open_Foundation_and_Fine-Tuned_Chat_Models.pdf", "file_type": "application/pdf", "file_size": 13661300, "creation_date": "2023-12-03", "last_modified_date": "2023-12-03", "last_accessed_date": "2023-12-05", "filename": "data/Llama_2_Open_Foundation_and_Fine-Tuned_Chat_Models.pdf"}, "hash": "8112c933f97653006d0c4470baa3ac35649057642358c30bc408533b16ba87e8", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "ffb59428-e36c-4d25-9565-fce9dd50ca21", "node_type": "1", "metadata": {}, "hash": "c1bd87491fa10b6178d04b84aa33e98f67b64768ab99e25e6fbdf05d618d6175", "class_name": "RelatedNodeInfo"}}, "hash": "197f1dcaf900dd2259c9119ddb8096d74021338308ede88411d3ebb4d08f9364", "text": "GAtt Evaluation. We applied GAtt after RLHF V3. We report a quantitative analysis indicating that GAtt is consistent up to 20+ turns, until the maximum context length is reached (see Appendix A.3.5). We tried to set constraints not present in the training of GAtt at inference time, for instance \u201cAlways answer with Haiku,\u201d for which the model remained consistent as illustrated in Appendix [Figure 28].\n\nlive in?\n\n. It is\n\n. It is\n\n. It is\n\ncourse!\n\n. It is\n\n. It is\n\nlive in?\n\n. It is\n\nWilde\n\nWilde\n\nWilde\n\nWilde\n\nlive in?\n\nens, of\n\n. It is\n\nlive in?\n\nens, of\n\nens, of\n\nony.\n\nony.\n\nony.\n\nony.\n\nanswersWh\n\nname is Oscar\n\n. It is\n\nanswersWh\n\nbest city to\n\nbest city to\n\nbest city to\n\nbest city to\n\ncourse!", "start_char_idx": 54219, "end_char_idx": 54924, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "a2dde18a-f5a7-4a2c-8d6a-1dff22ea1d90": {"__data__": {"id_": "a2dde18a-f5a7-4a2c-8d6a-1dff22ea1d90", "embedding": null, "metadata": {"figures_content": "Contains information about Figure 10 and Figure 10"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "091958d8-6ae8-40fd-8402-d8b87f926048", "node_type": "4", "metadata": {"file_path": "data/Llama_2_Open_Foundation_and_Fine-Tuned_Chat_Models.pdf", "file_name": "Llama_2_Open_Foundation_and_Fine-Tuned_Chat_Models.pdf", "file_type": "application/pdf", "file_size": 13661300, "creation_date": "2023-12-03", "last_modified_date": "2023-12-03", "last_accessed_date": "2023-12-05", "filename": "data/Llama_2_Open_Foundation_and_Fine-Tuned_Chat_Models.pdf"}, "hash": "cb763cc9be3bcf5f4ea72e7f5aacb267ba97761b9bcdb6a3486b62993560d070", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "82777007-837d-495e-a615-2741a138b7e8", "node_type": "1", "metadata": {"file_path": "data/Llama_2_Open_Foundation_and_Fine-Tuned_Chat_Models.pdf", "file_name": "Llama_2_Open_Foundation_and_Fine-Tuned_Chat_Models.pdf", "file_type": "application/pdf", "file_size": 13661300, "creation_date": "2023-12-03", "last_modified_date": "2023-12-03", "last_accessed_date": "2023-12-05", "filename": "data/Llama_2_Open_Foundation_and_Fine-Tuned_Chat_Models.pdf"}, "hash": "efd9202e5a2230e91a9f516daad3e7e9659444008ccfa7419c17752561cd6c8b", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "910dd7bc-f573-49ec-b184-058072cfa9cc", "node_type": "1", "metadata": {}, "hash": "667123ec9e5e8bf320ee4c672fec0705f958d10815c228e2610fae39f96e5958", "class_name": "RelatedNodeInfo"}}, "hash": "b467f11d1ddd47e59e890f3b80eaee543cfbfccc4712c5f5baf65c2c0a86bb2b", "text": "My\n\nfuture, where\n\nLondon, of\n\nLondon, of\n\nLondon, of\n\nthe city of\n\nthe city of\n\nthe great univers\n\nthe great univers\n\nthe great univers\n\nthe city of\n\nthe city of\n\nthe new bl\n\nAct as Oscar\n\nation and culture\n\nthe city of\n\nthe city of\n\nand galleries\n\nthe city of\n\nis the ep\n\nfuture, where\n\nis the ep\n\nis the ep\n\nWhat is your\n\nname is OscarBaseline after GAtt\n\nis the ep\n\nand galleries\n\nand galleries\n\nthe museums\n\nthe museums\n\nthe museums\n\nthe city of\n\nLondon, of\n\nand galleries\n\n[Figure 10]: Attention visualization for a dialogue with and without GAtt. We considered the maximum activations across the network and we bin neighboring tokens together.\n\nTo illustrate how GAtt helped reshape attention during fine-tuning, we display the maximum attention activations of the model in [Figure 10]. The left-hand side of each figure corresponds to the system message (\u201cAct as Oscar Wilde\u201d).", "start_char_idx": 56064, "end_char_idx": 56949, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "faac303c-56b3-4bdc-bc50-f65c4e4842aa": {"__data__": {"id_": "faac303c-56b3-4bdc-bc50-f65c4e4842aa", "embedding": null, "metadata": {"figures_content": "Contains information about Figure 29"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "091958d8-6ae8-40fd-8402-d8b87f926048", "node_type": "4", "metadata": {"file_path": "data/Llama_2_Open_Foundation_and_Fine-Tuned_Chat_Models.pdf", "file_name": "Llama_2_Open_Foundation_and_Fine-Tuned_Chat_Models.pdf", "file_type": "application/pdf", "file_size": 13661300, "creation_date": "2023-12-03", "last_modified_date": "2023-12-03", "last_accessed_date": "2023-12-05", "filename": "data/Llama_2_Open_Foundation_and_Fine-Tuned_Chat_Models.pdf"}, "hash": "cb763cc9be3bcf5f4ea72e7f5aacb267ba97761b9bcdb6a3486b62993560d070", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "910dd7bc-f573-49ec-b184-058072cfa9cc", "node_type": "1", "metadata": {"file_path": "data/Llama_2_Open_Foundation_and_Fine-Tuned_Chat_Models.pdf", "file_name": "Llama_2_Open_Foundation_and_Fine-Tuned_Chat_Models.pdf", "file_type": "application/pdf", "file_size": 13661300, "creation_date": "2023-12-03", "last_modified_date": "2023-12-03", "last_accessed_date": "2023-12-05", "filename": "data/Llama_2_Open_Foundation_and_Fine-Tuned_Chat_Models.pdf"}, "hash": "667123ec9e5e8bf320ee4c672fec0705f958d10815c228e2610fae39f96e5958", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "2c0e31f3-af8a-44c7-8e14-cc7654e4b83e", "node_type": "1", "metadata": {}, "hash": "ef4c77034595444b5bb9f001933511777ad574a1c4723964233c6a63ce12eb9d", "class_name": "RelatedNodeInfo"}}, "hash": "cf5c5e846cb5442849a4ff9b64ec1d11a970b73565114475daf5f2c42b8b7a81", "text": "Thus, to select the best-performing models among several ablations at each iteration from RLHF-V1 to V5, we first observed the improvement of the rewards from the latest reward models, to save costs and increase iteration speed. We later validated major model versions with human evaluations.\n\nHow Far Can Model-Based Evaluation Go? To measure the robustness of our reward model, we collected a test set of prompts for both helpfulness and safety, and asked three annotators to judge the quality of the answers based on a 7-point Likert scale (the higher the better). We observe that our reward models overall are well calibrated with our human preference annotations, as illustrated in [Figure 29] in the appendix. This confirms the relevance of using our reward as a point-wise metric, despite being trained with a Pairwise Ranking Loss.\n\nStill, as Goodhart\u2019s Law states, when a measure becomes a target, it ceases to be a good measure.", "start_char_idx": 57722, "end_char_idx": 58660, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "2c0e31f3-af8a-44c7-8e14-cc7654e4b83e": {"__data__": {"id_": "2c0e31f3-af8a-44c7-8e14-cc7654e4b83e", "embedding": null, "metadata": {"figures_content": "Contains information about Figure 11"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "091958d8-6ae8-40fd-8402-d8b87f926048", "node_type": "4", "metadata": {"file_path": "data/Llama_2_Open_Foundation_and_Fine-Tuned_Chat_Models.pdf", "file_name": "Llama_2_Open_Foundation_and_Fine-Tuned_Chat_Models.pdf", "file_type": "application/pdf", "file_size": 13661300, "creation_date": "2023-12-03", "last_modified_date": "2023-12-03", "last_accessed_date": "2023-12-05", "filename": "data/Llama_2_Open_Foundation_and_Fine-Tuned_Chat_Models.pdf"}, "hash": "cb763cc9be3bcf5f4ea72e7f5aacb267ba97761b9bcdb6a3486b62993560d070", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "faac303c-56b3-4bdc-bc50-f65c4e4842aa", "node_type": "1", "metadata": {"file_path": "data/Llama_2_Open_Foundation_and_Fine-Tuned_Chat_Models.pdf", "file_name": "Llama_2_Open_Foundation_and_Fine-Tuned_Chat_Models.pdf", "file_type": "application/pdf", "file_size": 13661300, "creation_date": "2023-12-03", "last_modified_date": "2023-12-03", "last_accessed_date": "2023-12-05", "filename": "data/Llama_2_Open_Foundation_and_Fine-Tuned_Chat_Models.pdf"}, "hash": "cf5c5e846cb5442849a4ff9b64ec1d11a970b73565114475daf5f2c42b8b7a81", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "5fb969c4-420f-464e-9517-d1bab78b851b", "node_type": "1", "metadata": {}, "hash": "6a6789bc4b09ba35c51f54f3b8ff9a4f9f01790320d8d634171d3c54d0e80712", "class_name": "RelatedNodeInfo"}}, "hash": "ef4c77034595444b5bb9f001933511777ad574a1c4723964233c6a63ce12eb9d", "text": "Still, as Goodhart\u2019s Law states, when a measure becomes a target, it ceases to be a good measure. To ensure our measure won\u2019t diverge from the human preferences, we additionally used a more general reward, trained\n\n17\n\nRLHF-v5(with PPO)RLHF-v5(no PPO)RLHF-v4RLHF-v3 RLHF-v2 RLHF-v1SFT-v2 SFT-v110%20%30%40%50%60%70%80%90%10%20%30%40%50%60%70%80%HelpfulnessJudge: Meta Reward ModelsHarmlessness\n\nRLHF-v5 (with PPO)RLHF-v5 (no PPO) RLHF-v4RLHF-v3 RLHF-v2RLHF-v1 SFT-v2 SFT-v110%20%30%40%50%60%70%80%90%10%20%30%40%50%60%70%80%HelpfulnessJudge: GPT-4Harmlessness\n\n[Figure 11]: Evolution of Llama 2-Chat.", "start_char_idx": 58563, "end_char_idx": 59163, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "5fb969c4-420f-464e-9517-d1bab78b851b": {"__data__": {"id_": "5fb969c4-420f-464e-9517-d1bab78b851b", "embedding": null, "metadata": {"figures_content": "Contains information about Figure 11"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "091958d8-6ae8-40fd-8402-d8b87f926048", "node_type": "4", "metadata": {"file_path": "data/Llama_2_Open_Foundation_and_Fine-Tuned_Chat_Models.pdf", "file_name": "Llama_2_Open_Foundation_and_Fine-Tuned_Chat_Models.pdf", "file_type": "application/pdf", "file_size": 13661300, "creation_date": "2023-12-03", "last_modified_date": "2023-12-03", "last_accessed_date": "2023-12-05", "filename": "data/Llama_2_Open_Foundation_and_Fine-Tuned_Chat_Models.pdf"}, "hash": "cb763cc9be3bcf5f4ea72e7f5aacb267ba97761b9bcdb6a3486b62993560d070", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "2c0e31f3-af8a-44c7-8e14-cc7654e4b83e", "node_type": "1", "metadata": {"file_path": "data/Llama_2_Open_Foundation_and_Fine-Tuned_Chat_Models.pdf", "file_name": "Llama_2_Open_Foundation_and_Fine-Tuned_Chat_Models.pdf", "file_type": "application/pdf", "file_size": 13661300, "creation_date": "2023-12-03", "last_modified_date": "2023-12-03", "last_accessed_date": "2023-12-05", "filename": "data/Llama_2_Open_Foundation_and_Fine-Tuned_Chat_Models.pdf"}, "hash": "ef4c77034595444b5bb9f001933511777ad574a1c4723964233c6a63ce12eb9d", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "71ec13c9-2d25-4b66-ac95-1a03315fea29", "node_type": "1", "metadata": {}, "hash": "bf7b8908f813d69f3f9bced380ab5067c1bbecc4f60484a21ed6fe1551f414f2", "class_name": "RelatedNodeInfo"}}, "hash": "6a6789bc4b09ba35c51f54f3b8ff9a4f9f01790320d8d634171d3c54d0e80712", "text": "We show the evolution after multiple iterations fine-tuning for the win-rate % of Llama 2-Chat compared to ChatGPT. Left: the judge is our reward model, which may favor our model, and right, the judge is GPT-4, which should be more neutral.\n\non diverse open-source Reward Modeling datasets. We have not yet observed any such divergence, and hypothesize that iterative model updates may be helping to prevent this.\n\nAs a last verification step to ensure no regression between our new model and the previous one, we use both to sample during the next annotation iteration. This enables a model comparison \u201cfor free\u201d on new prompts and can help to increase diversity when sampling.\n\nProgression of Models. [Figure 11] reports the progress of our different SFT and then RLHF versions for both Safety and Helpfulness axes, measured by our in-house Safety and Helpfulness reward models.", "start_char_idx": 59164, "end_char_idx": 60044, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "5a822087-6902-4c91-ab11-59fab7e6178c": {"__data__": {"id_": "5a822087-6902-4c91-ab11-59fab7e6178c", "embedding": null, "metadata": {"figures_content": "Contains information about Figure 12"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "091958d8-6ae8-40fd-8402-d8b87f926048", "node_type": "4", "metadata": {"file_path": "data/Llama_2_Open_Foundation_and_Fine-Tuned_Chat_Models.pdf", "file_name": "Llama_2_Open_Foundation_and_Fine-Tuned_Chat_Models.pdf", "file_type": "application/pdf", "file_size": 13661300, "creation_date": "2023-12-03", "last_modified_date": "2023-12-03", "last_accessed_date": "2023-12-05", "filename": "data/Llama_2_Open_Foundation_and_Fine-Tuned_Chat_Models.pdf"}, "hash": "cb763cc9be3bcf5f4ea72e7f5aacb267ba97761b9bcdb6a3486b62993560d070", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "80b0f136-c7a1-4653-b1e6-6903f7f35639", "node_type": "1", "metadata": {"file_path": "data/Llama_2_Open_Foundation_and_Fine-Tuned_Chat_Models.pdf", "file_name": "Llama_2_Open_Foundation_and_Fine-Tuned_Chat_Models.pdf", "file_type": "application/pdf", "file_size": 13661300, "creation_date": "2023-12-03", "last_modified_date": "2023-12-03", "last_accessed_date": "2023-12-05", "filename": "data/Llama_2_Open_Foundation_and_Fine-Tuned_Chat_Models.pdf"}, "hash": "93aa329d40478cc97724191dac94c3007a7538d30569e8ce47105e6da0096783", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "716c8e87-0353-4c66-995d-a8f5b53ca46b", "node_type": "1", "metadata": {}, "hash": "69caa39052dd031baecbb09c52edc68d262c1f1fbea47568934880f224b8ec0c", "class_name": "RelatedNodeInfo"}}, "hash": "e5167b29c5856750cfdffdc7f7f5b655c37ff89a75714c346716b7f348a340b7", "text": "The final prompt count for human evaluations for each model is shown in Table 32. See more methodology details in Appendix, Section A.3.7. The following section shows helpfulness results; safety results are presented in Section 4.4.\n\nResults. As shown in [Figure 12], Llama 2-Chat models outperform open-source models by a significant margin on both single turn and multi-turn prompts. Particularly, Llama 2-Chat 7B model outperforms MPT-7B-chat on 60% of the prompts. Llama 2-Chat 34B has an overall win rate of more than 75% against equivalently sized Vicuna-33B and Falcon 40B models.\n\n18\n\n[Figure 12]: Human evaluation results for Llama 2-Chat models compared to open- and closed-source models across ~4,000 helpfulness prompts with three raters per prompt.\n\nThe largest Llama 2-Chat model is competitive with ChatGPT.", "start_char_idx": 61460, "end_char_idx": 62282, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "b0f5cd20-ce8c-42f9-98dc-61c6e54081c8": {"__data__": {"id_": "b0f5cd20-ce8c-42f9-98dc-61c6e54081c8", "embedding": null, "metadata": {"figures_content": "Contains information about Figure 13"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "091958d8-6ae8-40fd-8402-d8b87f926048", "node_type": "4", "metadata": {"file_path": "data/Llama_2_Open_Foundation_and_Fine-Tuned_Chat_Models.pdf", "file_name": "Llama_2_Open_Foundation_and_Fine-Tuned_Chat_Models.pdf", "file_type": "application/pdf", "file_size": 13661300, "creation_date": "2023-12-03", "last_modified_date": "2023-12-03", "last_accessed_date": "2023-12-05", "filename": "data/Llama_2_Open_Foundation_and_Fine-Tuned_Chat_Models.pdf"}, "hash": "cb763cc9be3bcf5f4ea72e7f5aacb267ba97761b9bcdb6a3486b62993560d070", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "0c426fbb-d2f3-40de-8cb8-1f7d51053173", "node_type": "1", "metadata": {"file_path": "data/Llama_2_Open_Foundation_and_Fine-Tuned_Chat_Models.pdf", "file_name": "Llama_2_Open_Foundation_and_Fine-Tuned_Chat_Models.pdf", "file_type": "application/pdf", "file_size": 13661300, "creation_date": "2023-12-03", "last_modified_date": "2023-12-03", "last_accessed_date": "2023-12-05", "filename": "data/Llama_2_Open_Foundation_and_Fine-Tuned_Chat_Models.pdf"}, "hash": "563cdd4991c0c4d0d674527baf00e87eb98023838da92fe9b428aa96c34c6d93", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "27bef25b-6e8a-4a52-afb0-f5729f0916ba", "node_type": "1", "metadata": {}, "hash": "91ba4e53058de2aa456296e3c339a57409edb1ec84c333027070cde726f61a65", "class_name": "RelatedNodeInfo"}}, "hash": "c3165efa57b07285ec751a333a802a7a06fd5aed74d9afebe8c1b60ce6660042", "text": "8% american 4.3% indian 4.0% chinese 3.6% korean 3.5% mexican\n\n69.4% european 16.5% african 16.3% asian 5.1% latin 4.9% indigenous\n\n20.7% christian 11.5% religious 7.4% spiritual 6.2% catholic 3.7% jewish\n\n(b) The percentage listed below each demographic axis represents the percentage of all documents that mention any of the descriptor terms in this axis. The percentage listed for each demographic descriptor represents, among the documents that mention a descriptor in the given demographic axis, the percentage that mention this specific descriptor.\n\nTable 9: Demographic representations. Analysis of pronouns and identities in our pretraining corpus shows some skews that may affect performance, such as higher representations of Western demographics.\n\n[Figure 13]: Pretraining data toxicity.", "start_char_idx": 70689, "end_char_idx": 71487, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "27bef25b-6e8a-4a52-afb0-f5729f0916ba": {"__data__": {"id_": "27bef25b-6e8a-4a52-afb0-f5729f0916ba", "embedding": null, "metadata": {"figures_content": "Contains information about Figure 13 and Figure 13"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "091958d8-6ae8-40fd-8402-d8b87f926048", "node_type": "4", "metadata": {"file_path": "data/Llama_2_Open_Foundation_and_Fine-Tuned_Chat_Models.pdf", "file_name": "Llama_2_Open_Foundation_and_Fine-Tuned_Chat_Models.pdf", "file_type": "application/pdf", "file_size": 13661300, "creation_date": "2023-12-03", "last_modified_date": "2023-12-03", "last_accessed_date": "2023-12-05", "filename": "data/Llama_2_Open_Foundation_and_Fine-Tuned_Chat_Models.pdf"}, "hash": "cb763cc9be3bcf5f4ea72e7f5aacb267ba97761b9bcdb6a3486b62993560d070", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "b0f5cd20-ce8c-42f9-98dc-61c6e54081c8", "node_type": "1", "metadata": {"file_path": "data/Llama_2_Open_Foundation_and_Fine-Tuned_Chat_Models.pdf", "file_name": "Llama_2_Open_Foundation_and_Fine-Tuned_Chat_Models.pdf", "file_type": "application/pdf", "file_size": 13661300, "creation_date": "2023-12-03", "last_modified_date": "2023-12-03", "last_accessed_date": "2023-12-05", "filename": "data/Llama_2_Open_Foundation_and_Fine-Tuned_Chat_Models.pdf"}, "hash": "c3165efa57b07285ec751a333a802a7a06fd5aed74d9afebe8c1b60ce6660042", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "6da5a49e-07f9-45f7-90ea-87026ef3436b", "node_type": "1", "metadata": {}, "hash": "96d253da440cbe98f533c5800f0228601e55945708eeaa31b51fb13cbf7f15fa", "class_name": "RelatedNodeInfo"}}, "hash": "91ba4e53058de2aa456296e3c339a57409edb1ec84c333027070cde726f61a65", "text": "[Figure 13]: Pretraining data toxicity. To allow for better downstream generalization, we chose not to scrub toxic data from pretraining. The HateBERT classifier assigns a toxicity likelihood of 0.5 or higher to about 0.2% of documents in our pretraining corpus.\n\nData Toxicity. We measure the prevalence of toxicity in the English-language portion of the pretraining corpus using a HateBERT classifier fine-tuned on the ToxiGen dataset (Hartvigsen et al., 2022). We score each line of a document separately and average them to assign a document score. [Figure 13] shows the distribution of scores in a 10% random sample of the full corpus. About 0.2% of documents evaluated are assigned a likelihood score of 0.5 or higher, meaning there is a small amount of toxicity in our pretraining data.\n\nLanguage Identification. While our pretraining data is mostly English, it also includes text from a small number of other languages.", "start_char_idx": 71448, "end_char_idx": 72375, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "a5af0d70-ab78-4aa2-a2df-17c481317f05": {"__data__": {"id_": "a5af0d70-ab78-4aa2-a2df-17c481317f05", "embedding": null, "metadata": {"figures_content": "Contains information about Figure 14"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "091958d8-6ae8-40fd-8402-d8b87f926048", "node_type": "4", "metadata": {"file_path": "data/Llama_2_Open_Foundation_and_Fine-Tuned_Chat_Models.pdf", "file_name": "Llama_2_Open_Foundation_and_Fine-Tuned_Chat_Models.pdf", "file_type": "application/pdf", "file_size": 13661300, "creation_date": "2023-12-03", "last_modified_date": "2023-12-03", "last_accessed_date": "2023-12-05", "filename": "data/Llama_2_Open_Foundation_and_Fine-Tuned_Chat_Models.pdf"}, "hash": "cb763cc9be3bcf5f4ea72e7f5aacb267ba97761b9bcdb6a3486b62993560d070", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "a24a597b-103f-4725-8f28-7a0074f8a386", "node_type": "1", "metadata": {"file_path": "data/Llama_2_Open_Foundation_and_Fine-Tuned_Chat_Models.pdf", "file_name": "Llama_2_Open_Foundation_and_Fine-Tuned_Chat_Models.pdf", "file_type": "application/pdf", "file_size": 13661300, "creation_date": "2023-12-03", "last_modified_date": "2023-12-03", "last_accessed_date": "2023-12-05", "filename": "data/Llama_2_Open_Foundation_and_Fine-Tuned_Chat_Models.pdf"}, "hash": "6460676f72b476512a36db31b37f2896854c11c0205fcfa60f56871dac1fbe32", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "e964bbc0-0f38-4bad-a658-9031bc65d037", "node_type": "1", "metadata": {}, "hash": "7045b5975717c64b1db44c068f458c12fcd2d19a07019753b735aa63b49c6e1f", "class_name": "RelatedNodeInfo"}}, "hash": "e638ce791ad2af8d172fa2c61d8670ca470a9a7a0340b720e5dbe17f507e8642", "text": "We then use the human preference data to train a safety reward model (see Section 3.2.2), and also reuse the adversarial prompts to sample from the model during the RLHF stage.\n\nBetter Long-Tail Safety Robustness without Hurting Helpfulness Safety is inherently a long-tail problem, where the challenge comes from a small number of very specific cases. We investigate the impact of Safety RLHF by taking two intermediate Llama 2-Chat checkpoints\u2014one without adversarial prompts in the RLHF stage and one with them\u2014and score their responses on our test sets using our safety and helpfulness reward models. In [Figure 14], we plot the score distribution shift of the safety RM on the safety test set (left) and that of the helpfulness RM on the helpfulness test set (right).", "start_char_idx": 82544, "end_char_idx": 83316, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "e964bbc0-0f38-4bad-a658-9031bc65d037": {"__data__": {"id_": "e964bbc0-0f38-4bad-a658-9031bc65d037", "embedding": null, "metadata": {"figures_content": "Contains information about Figure 14"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "091958d8-6ae8-40fd-8402-d8b87f926048", "node_type": "4", "metadata": {"file_path": "data/Llama_2_Open_Foundation_and_Fine-Tuned_Chat_Models.pdf", "file_name": "Llama_2_Open_Foundation_and_Fine-Tuned_Chat_Models.pdf", "file_type": "application/pdf", "file_size": 13661300, "creation_date": "2023-12-03", "last_modified_date": "2023-12-03", "last_accessed_date": "2023-12-05", "filename": "data/Llama_2_Open_Foundation_and_Fine-Tuned_Chat_Models.pdf"}, "hash": "cb763cc9be3bcf5f4ea72e7f5aacb267ba97761b9bcdb6a3486b62993560d070", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "a5af0d70-ab78-4aa2-a2df-17c481317f05", "node_type": "1", "metadata": {"file_path": "data/Llama_2_Open_Foundation_and_Fine-Tuned_Chat_Models.pdf", "file_name": "Llama_2_Open_Foundation_and_Fine-Tuned_Chat_Models.pdf", "file_type": "application/pdf", "file_size": 13661300, "creation_date": "2023-12-03", "last_modified_date": "2023-12-03", "last_accessed_date": "2023-12-05", "filename": "data/Llama_2_Open_Foundation_and_Fine-Tuned_Chat_Models.pdf"}, "hash": "e638ce791ad2af8d172fa2c61d8670ca470a9a7a0340b720e5dbe17f507e8642", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "1cd7e6e0-dc3b-447c-b644-dbbdd9280e2e", "node_type": "1", "metadata": {}, "hash": "a015c3b7fcb81feac05debc5c704063f8002e9edfccf37a3e437025400fc2688", "class_name": "RelatedNodeInfo"}}, "hash": "7045b5975717c64b1db44c068f458c12fcd2d19a07019753b735aa63b49c6e1f", "text": "In the left hand side of the figure, we observe that the distribution of safety RM scores on the safety set shifts to higher reward scores after safety tuning with RLHF, and that the long tail of the distribution near zero thins out. A clear cluster appears on the top-left corner suggesting the improvements of model safety. On the right side, we do not observe any gathering pattern below the y = x line on the right hand side of [Figure 14], which indicates that the helpfulness score distribution is preserved after safety tuning with RLHF. Put another way, given sufficient helpfulness training data, the addition of an additional stage of safety mitigation does not negatively impact model performance on helpfulness to any notable degradation. A qualitative example is shown in Table 12.\n\nImpact of Safety Data Scaling. A tension between helpfulness and safety of LLMs has been observed in previous studies (Bai et al., 2022a).", "start_char_idx": 83317, "end_char_idx": 84251, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "15d52232-7a03-417e-ad17-928160dee42e": {"__data__": {"id_": "15d52232-7a03-417e-ad17-928160dee42e", "embedding": null, "metadata": {"figures_content": "Contains information about Figure 14"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "091958d8-6ae8-40fd-8402-d8b87f926048", "node_type": "4", "metadata": {"file_path": "data/Llama_2_Open_Foundation_and_Fine-Tuned_Chat_Models.pdf", "file_name": "Llama_2_Open_Foundation_and_Fine-Tuned_Chat_Models.pdf", "file_type": "application/pdf", "file_size": 13661300, "creation_date": "2023-12-03", "last_modified_date": "2023-12-03", "last_accessed_date": "2023-12-05", "filename": "data/Llama_2_Open_Foundation_and_Fine-Tuned_Chat_Models.pdf"}, "hash": "cb763cc9be3bcf5f4ea72e7f5aacb267ba97761b9bcdb6a3486b62993560d070", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "1cd7e6e0-dc3b-447c-b644-dbbdd9280e2e", "node_type": "1", "metadata": {"file_path": "data/Llama_2_Open_Foundation_and_Fine-Tuned_Chat_Models.pdf", "file_name": "Llama_2_Open_Foundation_and_Fine-Tuned_Chat_Models.pdf", "file_type": "application/pdf", "file_size": 13661300, "creation_date": "2023-12-03", "last_modified_date": "2023-12-03", "last_accessed_date": "2023-12-05", "filename": "data/Llama_2_Open_Foundation_and_Fine-Tuned_Chat_Models.pdf"}, "hash": "a015c3b7fcb81feac05debc5c704063f8002e9edfccf37a3e437025400fc2688", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "85e71e77-df18-407a-b146-d52ed7be46b4", "node_type": "1", "metadata": {}, "hash": "9cd4c3d8efb6f94f3c4c0e9ba57fb83d284848efd18c12a6a54fa311f4de2cc7", "class_name": "RelatedNodeInfo"}}, "hash": "e5e9a920af004c00baaeccb136b78f91bc9ebad49b25ebd30fd6c0fd43b12d1c", "text": "We evaluate them using our safety and helpfulness reward models described in Section 3.2.2. For\n\n24\n\n0\n\n0\n\n1.0Safety RM Score before Safety RLHF\n\n0.2\n\n0.2\n\n0.2\n\n0.2\n\n1000\n\n0\n\n1000\n\n1000\n\n0.8\n\n0.8\n\n0.8\n\n0.8\n\n0\n\n0.0\n\n1.0Helpfulness RM Score before Safety RLHF\n\n0.0\n\n0.0\n\n0.6\n\n0.6\n\n0.6\n\n0.6\n\n0.0\n\n1.0Helpfulness RM Score after Safety RLHF\n\nSafety Improvement\n\n0.4\n\n0.4\n\n0.4\n\n0.4\n\n1.0Safety RM Score after Safety RLHF\n\n1000\n\n[Figure 14]: Impact of safety RLHF measured by reward model score distributions. Left: safety reward model scores of generations on the Meta Safety test set.", "start_char_idx": 84955, "end_char_idx": 85533, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "57463a6a-25ab-406e-bfa6-9e71f47dcbc6": {"__data__": {"id_": "57463a6a-25ab-406e-bfa6-9e71f47dcbc6", "embedding": null, "metadata": {"figures_content": "Contains information about Figure 15"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "091958d8-6ae8-40fd-8402-d8b87f926048", "node_type": "4", "metadata": {"file_path": "data/Llama_2_Open_Foundation_and_Fine-Tuned_Chat_Models.pdf", "file_name": "Llama_2_Open_Foundation_and_Fine-Tuned_Chat_Models.pdf", "file_type": "application/pdf", "file_size": 13661300, "creation_date": "2023-12-03", "last_modified_date": "2023-12-03", "last_accessed_date": "2023-12-05", "filename": "data/Llama_2_Open_Foundation_and_Fine-Tuned_Chat_Models.pdf"}, "hash": "cb763cc9be3bcf5f4ea72e7f5aacb267ba97761b9bcdb6a3486b62993560d070", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "92b6fe33-d23c-4730-9fbc-08aa48312f4a", "node_type": "1", "metadata": {"file_path": "data/Llama_2_Open_Foundation_and_Fine-Tuned_Chat_Models.pdf", "file_name": "Llama_2_Open_Foundation_and_Fine-Tuned_Chat_Models.pdf", "file_type": "application/pdf", "file_size": 13661300, "creation_date": "2023-12-03", "last_modified_date": "2023-12-03", "last_accessed_date": "2023-12-05", "filename": "data/Llama_2_Open_Foundation_and_Fine-Tuned_Chat_Models.pdf"}, "hash": "8678ce32f3e313d09afa4709e412dc7d13dd7921bdeb37c5e0f9c3e5a77d55c9", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "4af99be8-58f3-408b-927e-cb9542ce4208", "node_type": "1", "metadata": {}, "hash": "e1473c4049d4971c7d47192b70efb28d0bf8e5d18c1283bc642d47afd1beb485", "class_name": "RelatedNodeInfo"}}, "hash": "c79932c9174a46d4021bd8caec097e5fb37b35277f3b299d9b2e4ebf8687def0", "text": "If you have any questions or concerns, please feel free to ask and I will do my best to assist you in a responsible and safe manner. Let\u2019s all strive to use the internet and email for positive and beneficial pur- poses. Is there something else I can help you with?\n\nTable 12: Example of safer response after safety RLHF. Left: response is generated by an early version of the model (SFT-v2). Right: response is generated by the latest version of the model (RLHF-V5 with PPO).\n\n25\n\neach variant, we use the safety and helpfulness reward models to score model generations corresponding to prompts in the Meta Safety and Helpful test sets, respectively.\n\nAs shown in [Figure 15], we use the mean reward model scores as proxies of model performance on safety and helpfulness. We observe that when we increase the proportion of safety data, the model\u2019s performance on handling risky and adversarial prompts improves dramatically, and we see a lighter tail in the safety reward model score distribution.", "start_char_idx": 87045, "end_char_idx": 88042, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "270ccca4-3a46-45d8-80f3-0f253c4f6888": {"__data__": {"id_": "270ccca4-3a46-45d8-80f3-0f253c4f6888", "embedding": null, "metadata": {"figures_content": "Contains information about Figure 15"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "091958d8-6ae8-40fd-8402-d8b87f926048", "node_type": "4", "metadata": {"file_path": "data/Llama_2_Open_Foundation_and_Fine-Tuned_Chat_Models.pdf", "file_name": "Llama_2_Open_Foundation_and_Fine-Tuned_Chat_Models.pdf", "file_type": "application/pdf", "file_size": 13661300, "creation_date": "2023-12-03", "last_modified_date": "2023-12-03", "last_accessed_date": "2023-12-05", "filename": "data/Llama_2_Open_Foundation_and_Fine-Tuned_Chat_Models.pdf"}, "hash": "cb763cc9be3bcf5f4ea72e7f5aacb267ba97761b9bcdb6a3486b62993560d070", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "4af99be8-58f3-408b-927e-cb9542ce4208", "node_type": "1", "metadata": {"file_path": "data/Llama_2_Open_Foundation_and_Fine-Tuned_Chat_Models.pdf", "file_name": "Llama_2_Open_Foundation_and_Fine-Tuned_Chat_Models.pdf", "file_type": "application/pdf", "file_size": 13661300, "creation_date": "2023-12-03", "last_modified_date": "2023-12-03", "last_accessed_date": "2023-12-05", "filename": "data/Llama_2_Open_Foundation_and_Fine-Tuned_Chat_Models.pdf"}, "hash": "e1473c4049d4971c7d47192b70efb28d0bf8e5d18c1283bc642d47afd1beb485", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "415a1ca1-77b2-4357-850b-96da759a9075", "node_type": "1", "metadata": {}, "hash": "2a82386ec78685f4ee9e3d87acd943ff68ffe7f7e4dbf9440580fcd2f0bd09bb", "class_name": "RelatedNodeInfo"}}, "hash": "e60767536ca307ed05f3aa41458ab568c856da7613963642e4224d0c1a47bd14", "text": "100%\n\n0.675\n\n75\n\n0.4\n\nSafety Data Pct. 50%\n\n0.725\n\n[Figure 15]: Safety data scaling trends. Left: as we increase the amount of safety data in model training, the mean safety RM score improves significantly while the helpfulness counterpart remains relatively stable. Right: the left tail of safety RM scores (i.e., most unsafe responses) gradually disappears with the addition of more safety training data.\n\nMeasure of False Refusal. Even though we do not see overall regression on model helpfulness, we qualita- tively observe, through interaction, that the model with more safety mitigation answers certain questions in a more conservative manner (e.g., example shown in Appendix Table 38). As a follow-up, we measure false refusal to quantify the frequency that the model incorrectly refuses to answer non-adversarial prompts. Here, we define false refusal as the model incorrectly refusing to answer legitimate user prompts due to irrelevant safety concerns.", "start_char_idx": 88688, "end_char_idx": 89650, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "415a1ca1-77b2-4357-850b-96da759a9075": {"__data__": {"id_": "415a1ca1-77b2-4357-850b-96da759a9075", "embedding": null, "metadata": {"figures_content": "Contains information about Figure 33"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "091958d8-6ae8-40fd-8402-d8b87f926048", "node_type": "4", "metadata": {"file_path": "data/Llama_2_Open_Foundation_and_Fine-Tuned_Chat_Models.pdf", "file_name": "Llama_2_Open_Foundation_and_Fine-Tuned_Chat_Models.pdf", "file_type": "application/pdf", "file_size": 13661300, "creation_date": "2023-12-03", "last_modified_date": "2023-12-03", "last_accessed_date": "2023-12-05", "filename": "data/Llama_2_Open_Foundation_and_Fine-Tuned_Chat_Models.pdf"}, "hash": "cb763cc9be3bcf5f4ea72e7f5aacb267ba97761b9bcdb6a3486b62993560d070", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "270ccca4-3a46-45d8-80f3-0f253c4f6888", "node_type": "1", "metadata": {"file_path": "data/Llama_2_Open_Foundation_and_Fine-Tuned_Chat_Models.pdf", "file_name": "Llama_2_Open_Foundation_and_Fine-Tuned_Chat_Models.pdf", "file_type": "application/pdf", "file_size": 13661300, "creation_date": "2023-12-03", "last_modified_date": "2023-12-03", "last_accessed_date": "2023-12-05", "filename": "data/Llama_2_Open_Foundation_and_Fine-Tuned_Chat_Models.pdf"}, "hash": "e60767536ca307ed05f3aa41458ab568c856da7613963642e4224d0c1a47bd14", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "116a6221-cb4d-48b8-8227-96e0d47c9b04", "node_type": "1", "metadata": {}, "hash": "f565e4bc4a8454e1d4ea4059098c6f23c9d2374b49c8b5aa3ca412c3d8b38403", "class_name": "RelatedNodeInfo"}}, "hash": "2a82386ec78685f4ee9e3d87acd943ff68ffe7f7e4dbf9440580fcd2f0bd09bb", "text": "Here, we define false refusal as the model incorrectly refusing to answer legitimate user prompts due to irrelevant safety concerns. Refusing due to reasonable causes exceeding the model\u2019s capability, e.g., \u201cI am not capable of participating in video calls\u201d and \u201c2024 is beyond my knowledge cut-off date,\u201d are not counted as false refusals. We train a classifier for detecting refusals in responses and apply the classifier on 1) the above helpfulness test sets and 2) a curated borderline test set consisting of 210 samples for the purpose of boundary testing similar to OpenAI (2023). The borderline dataset is designed intentionally so that its prompts look adversarial (e.g., containing sensitive words or subwords) but are not actually unsafe (e.g., \u201cgive me a recipe for Christmas Crack\u201d) (see Appendix Table 41 for more examples). With more safety data mixed in model tuning, the false-refusal rate becomes larger on both datasets (see Appendix [Figure 33]).", "start_char_idx": 89518, "end_char_idx": 90483, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "116a6221-cb4d-48b8-8227-96e0d47c9b04": {"__data__": {"id_": "116a6221-cb4d-48b8-8227-96e0d47c9b04", "embedding": null, "metadata": {"figures_content": "Contains information about Figure 33"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "091958d8-6ae8-40fd-8402-d8b87f926048", "node_type": "4", "metadata": {"file_path": "data/Llama_2_Open_Foundation_and_Fine-Tuned_Chat_Models.pdf", "file_name": "Llama_2_Open_Foundation_and_Fine-Tuned_Chat_Models.pdf", "file_type": "application/pdf", "file_size": 13661300, "creation_date": "2023-12-03", "last_modified_date": "2023-12-03", "last_accessed_date": "2023-12-05", "filename": "data/Llama_2_Open_Foundation_and_Fine-Tuned_Chat_Models.pdf"}, "hash": "cb763cc9be3bcf5f4ea72e7f5aacb267ba97761b9bcdb6a3486b62993560d070", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "415a1ca1-77b2-4357-850b-96da759a9075", "node_type": "1", "metadata": {"file_path": "data/Llama_2_Open_Foundation_and_Fine-Tuned_Chat_Models.pdf", "file_name": "Llama_2_Open_Foundation_and_Fine-Tuned_Chat_Models.pdf", "file_type": "application/pdf", "file_size": 13661300, "creation_date": "2023-12-03", "last_modified_date": "2023-12-03", "last_accessed_date": "2023-12-05", "filename": "data/Llama_2_Open_Foundation_and_Fine-Tuned_Chat_Models.pdf"}, "hash": "2a82386ec78685f4ee9e3d87acd943ff68ffe7f7e4dbf9440580fcd2f0bd09bb", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "1b3374ba-8fdf-4c44-ad34-9a7ec9e3e203", "node_type": "1", "metadata": {}, "hash": "9c257b4c2919d4142abfe006e3b69312e0b8dd1f41b9c3d29160a76974fb5bf4", "class_name": "RelatedNodeInfo"}}, "hash": "f565e4bc4a8454e1d4ea4059098c6f23c9d2374b49c8b5aa3ca412c3d8b38403", "text": "With more safety data mixed in model tuning, the false-refusal rate becomes larger on both datasets (see Appendix [Figure 33]). However, false refusal is overall rare\u2014approximately 0.05%\u2014on the helpfulness dataset, even with 100% safety data. On the other hand, the false-refusal rate is much larger on the borderline set due to its difficulty. Llama 2-Chat sometimes has difficulty distinguishing whether a prompt is safe when the prompt contains words that frequently occur in unsafe generations (such as \u201cbomb\u201d). Appendix Table 41 shows some examples of false refusals we discovered.\n\n26\n\nGeneric Preprompt\n\nPreprompt with Answer Template\n\nThe following is a discussion between a human and a knowledgeable and empathetic assistant. The assistant\u2019s answers should not include any harmful, unethical, or socially biased content, and should move the conversation in a positive direction.\n\nThe following is a question that can ellicit unsafe behavior from you.", "start_char_idx": 90356, "end_char_idx": 91315, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "495a62f6-4350-467d-b347-2ccfefd60594": {"__data__": {"id_": "495a62f6-4350-467d-b347-2ccfefd60594", "embedding": null, "metadata": {"figures_content": "Contains information about Table 39 and Figure 16"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "091958d8-6ae8-40fd-8402-d8b87f926048", "node_type": "4", "metadata": {"file_path": "data/Llama_2_Open_Foundation_and_Fine-Tuned_Chat_Models.pdf", "file_name": "Llama_2_Open_Foundation_and_Fine-Tuned_Chat_Models.pdf", "file_type": "application/pdf", "file_size": 13661300, "creation_date": "2023-12-03", "last_modified_date": "2023-12-03", "last_accessed_date": "2023-12-05", "filename": "data/Llama_2_Open_Foundation_and_Fine-Tuned_Chat_Models.pdf"}, "hash": "cb763cc9be3bcf5f4ea72e7f5aacb267ba97761b9bcdb6a3486b62993560d070", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "4f3425a4-1080-4adf-9693-552cd4f65bd5", "node_type": "1", "metadata": {"file_path": "data/Llama_2_Open_Foundation_and_Fine-Tuned_Chat_Models.pdf", "file_name": "Llama_2_Open_Foundation_and_Fine-Tuned_Chat_Models.pdf", "file_type": "application/pdf", "file_size": 13661300, "creation_date": "2023-12-03", "last_modified_date": "2023-12-03", "last_accessed_date": "2023-12-05", "filename": "data/Llama_2_Open_Foundation_and_Fine-Tuned_Chat_Models.pdf"}, "hash": "a8c8d5cf5f2eb530edeb6305a8711ea8c56642a477e6d895c1e808bdc4df3af9", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "33bd5a70-8ee3-44e2-9510-0bf9bdaaf186", "node_type": "1", "metadata": {}, "hash": "68661fafaf685a424cba7d666f7b3b89d8e8beab9415e0a4fccd558d01d823c3", "class_name": "RelatedNodeInfo"}}, "hash": "8908962077a90ad0c195c3af5b06c7924c9482f2dea4bf02bf913ee739b0deb4", "text": "Specifically, we apply context distillation by prefixing a safety preprompt to adversarial prompts to generate safer responses, and then fine-tune the model on its own safe output given the adversarial prompt without the preprompt. We generate safety preprompts automatically with templates. In particular, we use various adjectives usually associated with safe behavior such as \u201cresponsible,\u201d \u201crespectful\u2019,\u2019 or \u201cwise,\u201d with the intuition that the model associates them with positive traits that we want to see reflected in safe answers. We show examples of safety preprompts in Appendix Table 39.\n\nContext Distillation with Answer Templates During the prompt collection phase, we also asked annotators to label prompts according to risk categories, which enables even more targeted preprompts. Specifically, this allows us to provide some dedicated answer templates of how adversarial prompts should be addressed, based on each identified risk category. [Figure 16]a shows the impact of context distillation and context distillation with answer templates on the safety RM scores.", "start_char_idx": 93991, "end_char_idx": 95071, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "33bd5a70-8ee3-44e2-9510-0bf9bdaaf186": {"__data__": {"id_": "33bd5a70-8ee3-44e2-9510-0bf9bdaaf186", "embedding": null, "metadata": {"figures_content": "Contains information about Figure 16"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "091958d8-6ae8-40fd-8402-d8b87f926048", "node_type": "4", "metadata": {"file_path": "data/Llama_2_Open_Foundation_and_Fine-Tuned_Chat_Models.pdf", "file_name": "Llama_2_Open_Foundation_and_Fine-Tuned_Chat_Models.pdf", "file_type": "application/pdf", "file_size": 13661300, "creation_date": "2023-12-03", "last_modified_date": "2023-12-03", "last_accessed_date": "2023-12-05", "filename": "data/Llama_2_Open_Foundation_and_Fine-Tuned_Chat_Models.pdf"}, "hash": "cb763cc9be3bcf5f4ea72e7f5aacb267ba97761b9bcdb6a3486b62993560d070", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "495a62f6-4350-467d-b347-2ccfefd60594", "node_type": "1", "metadata": {"file_path": "data/Llama_2_Open_Foundation_and_Fine-Tuned_Chat_Models.pdf", "file_name": "Llama_2_Open_Foundation_and_Fine-Tuned_Chat_Models.pdf", "file_type": "application/pdf", "file_size": 13661300, "creation_date": "2023-12-03", "last_modified_date": "2023-12-03", "last_accessed_date": "2023-12-05", "filename": "data/Llama_2_Open_Foundation_and_Fine-Tuned_Chat_Models.pdf"}, "hash": "8908962077a90ad0c195c3af5b06c7924c9482f2dea4bf02bf913ee739b0deb4", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "fe940f9d-30b6-40e9-bb9f-754612fd2cd0", "node_type": "1", "metadata": {}, "hash": "dd1c3650a69de78e4a964929819797ec0c2fcb6be83bc6aad57f1f1b44f0e2c9", "class_name": "RelatedNodeInfo"}}, "hash": "68661fafaf685a424cba7d666f7b3b89d8e8beab9415e0a4fccd558d01d823c3", "text": "[Figure 16]a shows the impact of context distillation and context distillation with answer templates on the safety RM scores.\n\n27\n\nSafety RM ScorePercent\n\n00.20.40.60.810123456\n\nModelBase\n\n+ Generic Preprompt\n\n+ Preprompt w/ Answer Template\n\nOriginal Safety RM ScoreScore increase with CD\n\nRejected\n\n00.20.40.60.81\u22120.6\u22120.4\u22120.200.20.40.60.8\n\nSelected?Selected\n\n(a) Impact on Safety RM Score.\n\n(b) Targeted Context Distillation.\n\n[Figure 16]: Context distillation analysis. Left: Distribution of safety RM scores from the base model, when adding a generic preprompt, and when adding a preprompt based on the risk category with tailored answer template. While a generic preprompt increases safety RM scores, a preprompt with tailored answer template helps even more.", "start_char_idx": 94946, "end_char_idx": 95709, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "50e3451d-351f-43e5-9ec7-67a2cc72a498": {"__data__": {"id_": "50e3451d-351f-43e5-9ec7-67a2cc72a498", "embedding": null, "metadata": {"figures_content": "Contains information about Figure 16"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "091958d8-6ae8-40fd-8402-d8b87f926048", "node_type": "4", "metadata": {"file_path": "data/Llama_2_Open_Foundation_and_Fine-Tuned_Chat_Models.pdf", "file_name": "Llama_2_Open_Foundation_and_Fine-Tuned_Chat_Models.pdf", "file_type": "application/pdf", "file_size": 13661300, "creation_date": "2023-12-03", "last_modified_date": "2023-12-03", "last_accessed_date": "2023-12-05", "filename": "data/Llama_2_Open_Foundation_and_Fine-Tuned_Chat_Models.pdf"}, "hash": "cb763cc9be3bcf5f4ea72e7f5aacb267ba97761b9bcdb6a3486b62993560d070", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "fe940f9d-30b6-40e9-bb9f-754612fd2cd0", "node_type": "1", "metadata": {"file_path": "data/Llama_2_Open_Foundation_and_Fine-Tuned_Chat_Models.pdf", "file_name": "Llama_2_Open_Foundation_and_Fine-Tuned_Chat_Models.pdf", "file_type": "application/pdf", "file_size": 13661300, "creation_date": "2023-12-03", "last_modified_date": "2023-12-03", "last_accessed_date": "2023-12-05", "filename": "data/Llama_2_Open_Foundation_and_Fine-Tuned_Chat_Models.pdf"}, "hash": "dd1c3650a69de78e4a964929819797ec0c2fcb6be83bc6aad57f1f1b44f0e2c9", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "a986fc83-3fea-41b6-a41d-86c6503d1332", "node_type": "1", "metadata": {}, "hash": "fd48d4649c5f0f78a6bd55198408be931a3e611462fd8b9b1414559db117df02", "class_name": "RelatedNodeInfo"}}, "hash": "d8d416ea9b3c830b7f536e36da421d021ab776fd1438524e319b209d13e001ce", "text": "However, we observed that context distillation can sometimes degrade response quality, even when dealing with adversarial prompts. Specifically, if the model responses are already of high quality, the application of context distillation can result in less pertinent replies, as the model tends to overemphasize the preprompt, often resorting to generic concerns excessively (see Appendix Table 40 for an example of vague answers due to context distillation). We thus leverage the safety reward model to decide whether to use safety context distillation \u2013 we keep the context-distilled output only on the examples where it gets a better reward model score than the original answer. We notice that this is particularly helpful on prompts that the model is very bad at, but limits the negative impact of context distillation (see [Figure 16]b).\n\n4.3 Red Teaming\n\nGiven how broad the capabilities of LLMs are and how varied their training data is, it is insufficient to identify risks solely via ex post facto usage and analysis.", "start_char_idx": 96318, "end_char_idx": 97343, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "6ee2b1a0-f4d6-418a-a005-262ddff287d2": {"__data__": {"id_": "6ee2b1a0-f4d6-418a-a005-262ddff287d2", "embedding": null, "metadata": {"figures_content": "Contains information about Figure 17"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "091958d8-6ae8-40fd-8402-d8b87f926048", "node_type": "4", "metadata": {"file_path": "data/Llama_2_Open_Foundation_and_Fine-Tuned_Chat_Models.pdf", "file_name": "Llama_2_Open_Foundation_and_Fine-Tuned_Chat_Models.pdf", "file_type": "application/pdf", "file_size": 13661300, "creation_date": "2023-12-03", "last_modified_date": "2023-12-03", "last_accessed_date": "2023-12-05", "filename": "data/Llama_2_Open_Foundation_and_Fine-Tuned_Chat_Models.pdf"}, "hash": "cb763cc9be3bcf5f4ea72e7f5aacb267ba97761b9bcdb6a3486b62993560d070", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "1e7f53e6-1d73-4ab3-a87a-22cbba735a77", "node_type": "1", "metadata": {"file_path": "data/Llama_2_Open_Foundation_and_Fine-Tuned_Chat_Models.pdf", "file_name": "Llama_2_Open_Foundation_and_Fine-Tuned_Chat_Models.pdf", "file_type": "application/pdf", "file_size": 13661300, "creation_date": "2023-12-03", "last_modified_date": "2023-12-03", "last_accessed_date": "2023-12-05", "filename": "data/Llama_2_Open_Foundation_and_Fine-Tuned_Chat_Models.pdf"}, "hash": "b614e4c1a027cf12087c115e2e87a005e675081bda705113c72495776920c185", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "b9ff7545-d408-4d44-8da0-c859692cd69c", "node_type": "1", "metadata": {}, "hash": "5bb38f4f118bb358b433d33a1c1d053953129ab154b584c3557da08ebe777b27", "class_name": "RelatedNodeInfo"}}, "hash": "fc14637725ea43dd7458ed3198cd565926d2050f0ed6e7bc7ea40b76c8ab765e", "text": "On average, we had a 90% rejection rate model over model.\n\n4.4 Safety Evaluation of Llama 2-Chat\n\nSafety Human Evaluation. We collected roughly 2,000 adversarial prompts for human evaluation according to the safety categories in Section 4.2.1, in which 1,351 prompts are single-turn and 623 are multi-turn. Examples of evaluation prompts and responses can be found in Appendix A.4.6.\n\nWe then asked raters to judge models for safety violations on a five-point Likert scale with the following definitions:\n\n5 - No safety violations and very helpful \u2022 4 - No safety violations and only minor non-safety issues \u2022 3 - No safety violations but not helpful or other major non-safety issues \u2022 2 - Mild or moderate safety violations 29\n\n(a) Overall violation percentage.\n\n(b) Overall safety and helpfulness mean rating.\n\n[Figure 17]: Overall safety measures. Left: Llama 2-Chat has low violation percentage overall across model sizes.", "start_char_idx": 102147, "end_char_idx": 103073, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "b9ff7545-d408-4d44-8da0-c859692cd69c": {"__data__": {"id_": "b9ff7545-d408-4d44-8da0-c859692cd69c", "embedding": null, "metadata": {"figures_content": "Contains information about Figure 17"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "091958d8-6ae8-40fd-8402-d8b87f926048", "node_type": "4", "metadata": {"file_path": "data/Llama_2_Open_Foundation_and_Fine-Tuned_Chat_Models.pdf", "file_name": "Llama_2_Open_Foundation_and_Fine-Tuned_Chat_Models.pdf", "file_type": "application/pdf", "file_size": 13661300, "creation_date": "2023-12-03", "last_modified_date": "2023-12-03", "last_accessed_date": "2023-12-05", "filename": "data/Llama_2_Open_Foundation_and_Fine-Tuned_Chat_Models.pdf"}, "hash": "cb763cc9be3bcf5f4ea72e7f5aacb267ba97761b9bcdb6a3486b62993560d070", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "6ee2b1a0-f4d6-418a-a005-262ddff287d2", "node_type": "1", "metadata": {"file_path": "data/Llama_2_Open_Foundation_and_Fine-Tuned_Chat_Models.pdf", "file_name": "Llama_2_Open_Foundation_and_Fine-Tuned_Chat_Models.pdf", "file_type": "application/pdf", "file_size": 13661300, "creation_date": "2023-12-03", "last_modified_date": "2023-12-03", "last_accessed_date": "2023-12-05", "filename": "data/Llama_2_Open_Foundation_and_Fine-Tuned_Chat_Models.pdf"}, "hash": "fc14637725ea43dd7458ed3198cd565926d2050f0ed6e7bc7ea40b76c8ab765e", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "a32f6c94-7301-432f-ab02-bfa0d53f8f1e", "node_type": "1", "metadata": {}, "hash": "7528d35421af6c5ffc2c1dc09e060dd691ad07c055b0feeff4b3df3cbc76b23b", "class_name": "RelatedNodeInfo"}}, "hash": "5bb38f4f118bb358b433d33a1c1d053953129ab154b584c3557da08ebe777b27", "text": "[Figure 17]: Overall safety measures. Left: Llama 2-Chat has low violation percentage overall across model sizes. Right: Llama 2-Chat has high safety and helpfulness mean rating overall across model sizes. It is important to note that these results are subject to limitations of the prompt set, subjectivity of the review guidelines, and subjectivity of individual raters.\n\n1 - Severe safety violations\n\nWe consider a rating of 1 or 2 as violation and use violation percentage as our main evaluation metric, with the mean rating as a supplement. Each example is annotated by three annotators and we take the majority vote to determine if the response is violating or not. We used Gwet\u2019s AC1/2 statistic to measure inter-rater reliability (IRR) as in the helpfulness human evaluation. The IRR scores range from 0.70to0.95 depending on the annotation batch, indicating a high degree of agreement among annotators on safety assessments.", "start_char_idx": 102960, "end_char_idx": 103893, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "a32f6c94-7301-432f-ab02-bfa0d53f8f1e": {"__data__": {"id_": "a32f6c94-7301-432f-ab02-bfa0d53f8f1e", "embedding": null, "metadata": {"figures_content": "Contains information about Figure 18 and Figure 17"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "091958d8-6ae8-40fd-8402-d8b87f926048", "node_type": "4", "metadata": {"file_path": "data/Llama_2_Open_Foundation_and_Fine-Tuned_Chat_Models.pdf", "file_name": "Llama_2_Open_Foundation_and_Fine-Tuned_Chat_Models.pdf", "file_type": "application/pdf", "file_size": 13661300, "creation_date": "2023-12-03", "last_modified_date": "2023-12-03", "last_accessed_date": "2023-12-05", "filename": "data/Llama_2_Open_Foundation_and_Fine-Tuned_Chat_Models.pdf"}, "hash": "cb763cc9be3bcf5f4ea72e7f5aacb267ba97761b9bcdb6a3486b62993560d070", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "b9ff7545-d408-4d44-8da0-c859692cd69c", "node_type": "1", "metadata": {"file_path": "data/Llama_2_Open_Foundation_and_Fine-Tuned_Chat_Models.pdf", "file_name": "Llama_2_Open_Foundation_and_Fine-Tuned_Chat_Models.pdf", "file_type": "application/pdf", "file_size": 13661300, "creation_date": "2023-12-03", "last_modified_date": "2023-12-03", "last_accessed_date": "2023-12-05", "filename": "data/Llama_2_Open_Foundation_and_Fine-Tuned_Chat_Models.pdf"}, "hash": "5bb38f4f118bb358b433d33a1c1d053953129ab154b584c3557da08ebe777b27", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "33c43575-ab5e-434c-8bc6-93e2f86c4305", "node_type": "1", "metadata": {}, "hash": "b50f26e9c75f4599309dc6e77563e167744b313319c2e298e852e3414df8c7da", "class_name": "RelatedNodeInfo"}}, "hash": "7528d35421af6c5ffc2c1dc09e060dd691ad07c055b0feeff4b3df3cbc76b23b", "text": "On Llama 2-Chat annotations, the average IRR is 0.92 according to Gwet\u2019s AC2 measure. We see lower IRR scores on batches where the models have a high violation rate (e.g., Vicuna) and higher IRR scores on batches where the models have relatively low violation rates (e.g., Llama 2-Chat, Falcon, and ChatGPT).\n\n[Figure 18]: Single-turn and multi-turn violation percentage. Note that these results should be interpreted carefully due to limitations of the prompt set, subjectivity of the review guidelines, content standards, and individual raters.\n\nWe show the overall violation percentage and safety rating of various LLMs in [Figure 17].", "start_char_idx": 103894, "end_char_idx": 104532, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "33c43575-ab5e-434c-8bc6-93e2f86c4305": {"__data__": {"id_": "33c43575-ab5e-434c-8bc6-93e2f86c4305", "embedding": null, "metadata": {"figures_content": "Contains information about Figure 17"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "091958d8-6ae8-40fd-8402-d8b87f926048", "node_type": "4", "metadata": {"file_path": "data/Llama_2_Open_Foundation_and_Fine-Tuned_Chat_Models.pdf", "file_name": "Llama_2_Open_Foundation_and_Fine-Tuned_Chat_Models.pdf", "file_type": "application/pdf", "file_size": 13661300, "creation_date": "2023-12-03", "last_modified_date": "2023-12-03", "last_accessed_date": "2023-12-05", "filename": "data/Llama_2_Open_Foundation_and_Fine-Tuned_Chat_Models.pdf"}, "hash": "cb763cc9be3bcf5f4ea72e7f5aacb267ba97761b9bcdb6a3486b62993560d070", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "a32f6c94-7301-432f-ab02-bfa0d53f8f1e", "node_type": "1", "metadata": {"file_path": "data/Llama_2_Open_Foundation_and_Fine-Tuned_Chat_Models.pdf", "file_name": "Llama_2_Open_Foundation_and_Fine-Tuned_Chat_Models.pdf", "file_type": "application/pdf", "file_size": 13661300, "creation_date": "2023-12-03", "last_modified_date": "2023-12-03", "last_accessed_date": "2023-12-05", "filename": "data/Llama_2_Open_Foundation_and_Fine-Tuned_Chat_Models.pdf"}, "hash": "7528d35421af6c5ffc2c1dc09e060dd691ad07c055b0feeff4b3df3cbc76b23b", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "408240e0-9251-472b-b4bf-0163b6c6dd15", "node_type": "1", "metadata": {}, "hash": "ae08721ec61d255c40f8e29a5505c83d34cd9d0f49d62b16646995c4e17f1d2d", "class_name": "RelatedNodeInfo"}}, "hash": "b50f26e9c75f4599309dc6e77563e167744b313319c2e298e852e3414df8c7da", "text": "We show the overall violation percentage and safety rating of various LLMs in [Figure 17]. Llama 2-Chat has comparable or lower overall violation percentage across model sizes, while ChatGPT and Falcon (Almazrouei et al., 2023) come next, then MPT (MosaicML NLP Team et al., 2023) and Vicuna (Chiang et al., 2023). It is important to interpret these results carefully, as they are affected by limitations of the prompt set, subjectivity of the review guidelines, content standards, and subjectivity of individual raters. Upon manual analysis, we found that the response of Falcon is typically short (one or two sentences), thus less prone to generating unsafe content but also generally less helpful. This is reflected by a large number of responses of Falcon with rating= 3.", "start_char_idx": 104442, "end_char_idx": 105217, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "408240e0-9251-472b-b4bf-0163b6c6dd15": {"__data__": {"id_": "408240e0-9251-472b-b4bf-0163b6c6dd15", "embedding": null, "metadata": {"figures_content": "Contains information about Figure 17 and Figure 19 and Figure 18"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "091958d8-6ae8-40fd-8402-d8b87f926048", "node_type": "4", "metadata": {"file_path": "data/Llama_2_Open_Foundation_and_Fine-Tuned_Chat_Models.pdf", "file_name": "Llama_2_Open_Foundation_and_Fine-Tuned_Chat_Models.pdf", "file_type": "application/pdf", "file_size": 13661300, "creation_date": "2023-12-03", "last_modified_date": "2023-12-03", "last_accessed_date": "2023-12-05", "filename": "data/Llama_2_Open_Foundation_and_Fine-Tuned_Chat_Models.pdf"}, "hash": "cb763cc9be3bcf5f4ea72e7f5aacb267ba97761b9bcdb6a3486b62993560d070", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "33c43575-ab5e-434c-8bc6-93e2f86c4305", "node_type": "1", "metadata": {"file_path": "data/Llama_2_Open_Foundation_and_Fine-Tuned_Chat_Models.pdf", "file_name": "Llama_2_Open_Foundation_and_Fine-Tuned_Chat_Models.pdf", "file_type": "application/pdf", "file_size": 13661300, "creation_date": "2023-12-03", "last_modified_date": "2023-12-03", "last_accessed_date": "2023-12-05", "filename": "data/Llama_2_Open_Foundation_and_Fine-Tuned_Chat_Models.pdf"}, "hash": "b50f26e9c75f4599309dc6e77563e167744b313319c2e298e852e3414df8c7da", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "0ee31883-91a3-48e7-a7a7-c28d2d09db92", "node_type": "1", "metadata": {}, "hash": "b85f74c779d271aa93b54da06cca7b174b790b4c7d4cfc29ef9c00f485d43fa3", "class_name": "RelatedNodeInfo"}}, "hash": "ae08721ec61d255c40f8e29a5505c83d34cd9d0f49d62b16646995c4e17f1d2d", "text": "This is reflected by a large number of responses of Falcon with rating= 3. As a result, we note that in [Figure 17]b the average rating of Falcon is much lower than Llama 2-Chat (34B) although their violation percentages look similar (3.88 vs 4.45).\n\n30\n\n[Figure 19]: Violation percentage per risk category. Note: these results should be interpreted carefully due to limitations of the prompt set, subjectivity of the review guidelines, content standards, and individual raters.\n\nIn [Figure 18], we report the violation percentage on single- and multi-turn conversations, respectively. A trend across models is that multi-turn conversations are more prone to inducing unsafe responses. That said, Llama 2-Chat still performs well compared to baselines, especially on multi-turn conversations.", "start_char_idx": 105143, "end_char_idx": 105935, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "0ee31883-91a3-48e7-a7a7-c28d2d09db92": {"__data__": {"id_": "0ee31883-91a3-48e7-a7a7-c28d2d09db92", "embedding": null, "metadata": {"figures_content": "Contains information about Figure 19"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "091958d8-6ae8-40fd-8402-d8b87f926048", "node_type": "4", "metadata": {"file_path": "data/Llama_2_Open_Foundation_and_Fine-Tuned_Chat_Models.pdf", "file_name": "Llama_2_Open_Foundation_and_Fine-Tuned_Chat_Models.pdf", "file_type": "application/pdf", "file_size": 13661300, "creation_date": "2023-12-03", "last_modified_date": "2023-12-03", "last_accessed_date": "2023-12-05", "filename": "data/Llama_2_Open_Foundation_and_Fine-Tuned_Chat_Models.pdf"}, "hash": "cb763cc9be3bcf5f4ea72e7f5aacb267ba97761b9bcdb6a3486b62993560d070", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "408240e0-9251-472b-b4bf-0163b6c6dd15", "node_type": "1", "metadata": {"file_path": "data/Llama_2_Open_Foundation_and_Fine-Tuned_Chat_Models.pdf", "file_name": "Llama_2_Open_Foundation_and_Fine-Tuned_Chat_Models.pdf", "file_type": "application/pdf", "file_size": 13661300, "creation_date": "2023-12-03", "last_modified_date": "2023-12-03", "last_accessed_date": "2023-12-05", "filename": "data/Llama_2_Open_Foundation_and_Fine-Tuned_Chat_Models.pdf"}, "hash": "ae08721ec61d255c40f8e29a5505c83d34cd9d0f49d62b16646995c4e17f1d2d", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "204d735f-1a20-49e7-8b25-21f86d11ab3f", "node_type": "1", "metadata": {}, "hash": "64354b8583f904fdd071e2a362105ac68fde35c1e4d91d40124398c071c64cb9", "class_name": "RelatedNodeInfo"}}, "hash": "b85f74c779d271aa93b54da06cca7b174b790b4c7d4cfc29ef9c00f485d43fa3", "text": "That said, Llama 2-Chat still performs well compared to baselines, especially on multi-turn conversations. We also observe that Falcon performs particularly well on single-turn conversations (largely due to its conciseness) but much worse on multi-turn conversations, which could be due to its lack of multi-turn supervised fine-tuning data.\n\nIn [Figure 19], we show the per-category safety violation percentage of different LLMs. While model perfor- mance is similar across categories, Llama 2-Chat has relatively more violations under the unqualified advice category (although still low in an absolute sense), for various reasons, including lack of an appropriate disclaimer (e.g., \u201cI am not a professional\u201d) at times. For the other two categories, Llama 2-Chat achieves comparable or lower violation percentage consistently regardless of model sizes.\n\nIn Table 14, fine-tuned Llama 2-Chat shows great improvement over Truthfulness, Toxicity, and Bias.", "start_char_idx": 105829, "end_char_idx": 106783, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "e7572db6-2f3c-4833-9221-0563067f08cd": {"__data__": {"id_": "e7572db6-2f3c-4833-9221-0563067f08cd", "embedding": null, "metadata": {"figures_content": "Contains information about Figure 20"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "091958d8-6ae8-40fd-8402-d8b87f926048", "node_type": "4", "metadata": {"file_path": "data/Llama_2_Open_Foundation_and_Fine-Tuned_Chat_Models.pdf", "file_name": "Llama_2_Open_Foundation_and_Fine-Tuned_Chat_Models.pdf", "file_type": "application/pdf", "file_size": 13661300, "creation_date": "2023-12-03", "last_modified_date": "2023-12-03", "last_accessed_date": "2023-12-05", "filename": "data/Llama_2_Open_Foundation_and_Fine-Tuned_Chat_Models.pdf"}, "hash": "cb763cc9be3bcf5f4ea72e7f5aacb267ba97761b9bcdb6a3486b62993560d070", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "44513b00-26ce-42c2-b7b6-b0bc36c769f2", "node_type": "1", "metadata": {"file_path": "data/Llama_2_Open_Foundation_and_Fine-Tuned_Chat_Models.pdf", "file_name": "Llama_2_Open_Foundation_and_Fine-Tuned_Chat_Models.pdf", "file_type": "application/pdf", "file_size": 13661300, "creation_date": "2023-12-03", "last_modified_date": "2023-12-03", "last_accessed_date": "2023-12-05", "filename": "data/Llama_2_Open_Foundation_and_Fine-Tuned_Chat_Models.pdf"}, "hash": "7d4856e3b6556c092a54740e027eeb53181a47c32c94acf1572cc06e60ff7c9e", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "ae635a7b-8269-4027-ac49-0d119140778c", "node_type": "1", "metadata": {}, "hash": "ae086c43098784186089d6e679a102f40f4c6e4ae87e52bd90dfa59e26db0679", "class_name": "RelatedNodeInfo"}}, "hash": "1276b24a092273f8afd83ad782139463bf99804173284c64207c0d37a79582ce", "text": "We then discuss the limitations of Llama 2-Chat (Section 5.2). Lastly, we present our strategy for responsibly releasing these models (Section 5.3).\n\n5.1 Learnings and Observations\n\nOur tuning process revealed several interesting results, such as Llama 2-Chat\u2019s abilities to temporally organize its knowledge, or to call APIs for external tools.\n\nSFT (Annotation)\n\nSFT (Mix)\n\nRLHF (V2)\n\nRLHF (V1)0.00.20.40.60.81.0Reward Model Score\n\n[Figure 20]: Distribution shift for progressive versions of Llama 2-Chat, from SFT models towards RLHF.\n\nBeyond Human Supervision. At the outset of the project, many among us expressed a preference for supervised annotation, attracted by its denser signal. Meanwhile reinforcement learning, known for its insta- bility, seemed a somewhat shadowy field for those in the NLP research community.", "start_char_idx": 108092, "end_char_idx": 108918, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "a6c06295-576d-4efc-80f7-220c28316c17": {"__data__": {"id_": "a6c06295-576d-4efc-80f7-220c28316c17", "embedding": null, "metadata": {"figures_content": "Contains information about Figure 20"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "091958d8-6ae8-40fd-8402-d8b87f926048", "node_type": "4", "metadata": {"file_path": "data/Llama_2_Open_Foundation_and_Fine-Tuned_Chat_Models.pdf", "file_name": "Llama_2_Open_Foundation_and_Fine-Tuned_Chat_Models.pdf", "file_type": "application/pdf", "file_size": 13661300, "creation_date": "2023-12-03", "last_modified_date": "2023-12-03", "last_accessed_date": "2023-12-05", "filename": "data/Llama_2_Open_Foundation_and_Fine-Tuned_Chat_Models.pdf"}, "hash": "cb763cc9be3bcf5f4ea72e7f5aacb267ba97761b9bcdb6a3486b62993560d070", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "ae635a7b-8269-4027-ac49-0d119140778c", "node_type": "1", "metadata": {"file_path": "data/Llama_2_Open_Foundation_and_Fine-Tuned_Chat_Models.pdf", "file_name": "Llama_2_Open_Foundation_and_Fine-Tuned_Chat_Models.pdf", "file_type": "application/pdf", "file_size": 13661300, "creation_date": "2023-12-03", "last_modified_date": "2023-12-03", "last_accessed_date": "2023-12-05", "filename": "data/Llama_2_Open_Foundation_and_Fine-Tuned_Chat_Models.pdf"}, "hash": "ae086c43098784186089d6e679a102f40f4c6e4ae87e52bd90dfa59e26db0679", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "7b0f046c-2b20-4f18-8af9-cf7f72fc092b", "node_type": "1", "metadata": {}, "hash": "a8296f6748db96c09673db80d51f5f0ee70ba48b2156343de158d7e4623d9ec3", "class_name": "RelatedNodeInfo"}}, "hash": "e1b3f6fa7a0f95fec7d262eeaa3d1c2d8f0a8a19b9f701db217796f353baae79", "text": "Consequently, the reward mechanism swiftly learns to assign low scores to undesirable tail-end distribution and aligns towards the human preference. This phenomena is illustrated in [Figure 20], where we can see that the worst answers are progressively removed, shifting the distribution to the right.\n\nIn addition, during annotation, the model has the potential to venture into writing trajectories that even the best annotators may not chart. Nonetheless, humans can still provide valuable feedback when comparing two answers, beyond their own writing competencies. Drawing a parallel, while we may not all be accomplished artists, our ability to appreciate and critique art remains intact. We posit that the superior writing abilities of LLMs, as manifested in surpassing human annotators in certain tasks, are fundamentally driven by RLHF, as documented in Gilardi et al. (2023) and Huang et al. (2023).", "start_char_idx": 109628, "end_char_idx": 110535, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "7b0f046c-2b20-4f18-8af9-cf7f72fc092b": {"__data__": {"id_": "7b0f046c-2b20-4f18-8af9-cf7f72fc092b", "embedding": null, "metadata": {"figures_content": "Contains information about Figure 8 and Figure 21"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "091958d8-6ae8-40fd-8402-d8b87f926048", "node_type": "4", "metadata": {"file_path": "data/Llama_2_Open_Foundation_and_Fine-Tuned_Chat_Models.pdf", "file_name": "Llama_2_Open_Foundation_and_Fine-Tuned_Chat_Models.pdf", "file_type": "application/pdf", "file_size": 13661300, "creation_date": "2023-12-03", "last_modified_date": "2023-12-03", "last_accessed_date": "2023-12-05", "filename": "data/Llama_2_Open_Foundation_and_Fine-Tuned_Chat_Models.pdf"}, "hash": "cb763cc9be3bcf5f4ea72e7f5aacb267ba97761b9bcdb6a3486b62993560d070", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "a6c06295-576d-4efc-80f7-220c28316c17", "node_type": "1", "metadata": {"file_path": "data/Llama_2_Open_Foundation_and_Fine-Tuned_Chat_Models.pdf", "file_name": "Llama_2_Open_Foundation_and_Fine-Tuned_Chat_Models.pdf", "file_type": "application/pdf", "file_size": 13661300, "creation_date": "2023-12-03", "last_modified_date": "2023-12-03", "last_accessed_date": "2023-12-05", "filename": "data/Llama_2_Open_Foundation_and_Fine-Tuned_Chat_Models.pdf"}, "hash": "e1b3f6fa7a0f95fec7d262eeaa3d1c2d8f0a8a19b9f701db217796f353baae79", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "7aafb702-b71d-443a-b5e3-373808a84f83", "node_type": "1", "metadata": {}, "hash": "8f68d4c263eb55f3a0bbaaa1b3892abd223f47970ba18d0d60ba1197a5a810ab", "class_name": "RelatedNodeInfo"}}, "hash": "a8296f6748db96c09673db80d51f5f0ee70ba48b2156343de158d7e4623d9ec3", "text": "(2023) and Huang et al. (2023). Supervised data may no longer be the gold standard, and this evolving circumstance compels a re-evaluation of the concept of \u201csupervision.\u201d\n\nIn-Context Temperature Rescaling. We have observed an intriguing phenomenon related to RLHF, a feature not previously reported to the best of our knowledge: the dynamic re-scaling of temperature contingent upon the context. As indicated in [Figure 8], the temperature appears to be influenced by RLHF. Yet, intriguingly, our findings also revealed that the shifts are not uniformly applied across all prompts, as shown in [Figure 21].\n\nFor instance, when it comes to prompts associated with creativity, such as \u201cWrite a poem,\u201d an increase in temperature continues to generate diversity across our various RLHF iterations. This can be observed in the Self-BLEU slope, which mirrors a pattern comparable to that of the SFT model.", "start_char_idx": 110504, "end_char_idx": 111404, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "7aafb702-b71d-443a-b5e3-373808a84f83": {"__data__": {"id_": "7aafb702-b71d-443a-b5e3-373808a84f83", "embedding": null, "metadata": {"figures_content": "Contains information about Figure 21"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "091958d8-6ae8-40fd-8402-d8b87f926048", "node_type": "4", "metadata": {"file_path": "data/Llama_2_Open_Foundation_and_Fine-Tuned_Chat_Models.pdf", "file_name": "Llama_2_Open_Foundation_and_Fine-Tuned_Chat_Models.pdf", "file_type": "application/pdf", "file_size": 13661300, "creation_date": "2023-12-03", "last_modified_date": "2023-12-03", "last_accessed_date": "2023-12-05", "filename": "data/Llama_2_Open_Foundation_and_Fine-Tuned_Chat_Models.pdf"}, "hash": "cb763cc9be3bcf5f4ea72e7f5aacb267ba97761b9bcdb6a3486b62993560d070", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "7b0f046c-2b20-4f18-8af9-cf7f72fc092b", "node_type": "1", "metadata": {"file_path": "data/Llama_2_Open_Foundation_and_Fine-Tuned_Chat_Models.pdf", "file_name": "Llama_2_Open_Foundation_and_Fine-Tuned_Chat_Models.pdf", "file_type": "application/pdf", "file_size": 13661300, "creation_date": "2023-12-03", "last_modified_date": "2023-12-03", "last_accessed_date": "2023-12-05", "filename": "data/Llama_2_Open_Foundation_and_Fine-Tuned_Chat_Models.pdf"}, "hash": "a8296f6748db96c09673db80d51f5f0ee70ba48b2156343de158d7e4623d9ec3", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "cbda5a75-8cc2-4d02-8556-02f28f309cfc", "node_type": "1", "metadata": {}, "hash": "4d6fa42f99291bbab3ce0322c992302dc2dd3a93f52621995f345103c34bfffe", "class_name": "RelatedNodeInfo"}}, "hash": "8f68d4c263eb55f3a0bbaaa1b3892abd223f47970ba18d0d60ba1197a5a810ab", "text": "This can be observed in the Self-BLEU slope, which mirrors a pattern comparable to that of the SFT model.\n\nOn the other hand, for prompts based on factual information, such as \u201cWhat is the capital of ?\u201d the Self-BLEU slope diminishes over time. This pattern suggests that despite the rising temperature, the model learns to consistently provide the same response to factual prompts.\n\n32\n\nRLHF v1\n\n60\n\nCreative Prompts\n\n80\n\n90\n\n1.2\n\n1.2\n\n100Self-BLEU\n\nSFT\n\n95\n\n85\n\n0.6\n\n0.6\n\n1.0\n\n1.0\n\n1.4Temperature\n\n1.4Temperature\n\nRLHF v3\n\n75\n\n0.4\n\n0.4\n\nRLHF v2\n\n70\n\n65\n\n0.8\n\nFactual Prompts\n\n0.8\n\n[Figure 21]: RLHF learns to adapt the temperature with regard to the type of prompt.", "start_char_idx": 111299, "end_char_idx": 111966, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "cbda5a75-8cc2-4d02-8556-02f28f309cfc": {"__data__": {"id_": "cbda5a75-8cc2-4d02-8556-02f28f309cfc", "embedding": null, "metadata": {"figures_content": "Contains information about Figure 22 and Figure 22"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "091958d8-6ae8-40fd-8402-d8b87f926048", "node_type": "4", "metadata": {"file_path": "data/Llama_2_Open_Foundation_and_Fine-Tuned_Chat_Models.pdf", "file_name": "Llama_2_Open_Foundation_and_Fine-Tuned_Chat_Models.pdf", "file_type": "application/pdf", "file_size": 13661300, "creation_date": "2023-12-03", "last_modified_date": "2023-12-03", "last_accessed_date": "2023-12-05", "filename": "data/Llama_2_Open_Foundation_and_Fine-Tuned_Chat_Models.pdf"}, "hash": "cb763cc9be3bcf5f4ea72e7f5aacb267ba97761b9bcdb6a3486b62993560d070", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "7aafb702-b71d-443a-b5e3-373808a84f83", "node_type": "1", "metadata": {"file_path": "data/Llama_2_Open_Foundation_and_Fine-Tuned_Chat_Models.pdf", "file_name": "Llama_2_Open_Foundation_and_Fine-Tuned_Chat_Models.pdf", "file_type": "application/pdf", "file_size": 13661300, "creation_date": "2023-12-03", "last_modified_date": "2023-12-03", "last_accessed_date": "2023-12-05", "filename": "data/Llama_2_Open_Foundation_and_Fine-Tuned_Chat_Models.pdf"}, "hash": "8f68d4c263eb55f3a0bbaaa1b3892abd223f47970ba18d0d60ba1197a5a810ab", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "2d26efe5-b9d1-4376-9a62-61c8045d136f", "node_type": "1", "metadata": {}, "hash": "c556b4958ff418a52a681216693d1bb04cbb28b0b37a97c74be9612c4a6c7869", "class_name": "RelatedNodeInfo"}}, "hash": "4d6fa42f99291bbab3ce0322c992302dc2dd3a93f52621995f345103c34bfffe", "text": "Lower Self-BLEU corresponds to more diversity: RLHF eliminates diversity in responses to factual prompts but retains more diversity when generating responses to creative prompts. We prompt each model with a diverse set of 10 creative and 10 factual instructions and sample 25 responses. This is repeated for the temperatures T \u2208 {k/10 | k \u2208 N : 1 \u2264 k \u2264 15}. For each of the 25 responses we compute the Self-BLEU metric and report the mean and standard deviation against the temperature.\n\n[Figure 22]: Time awareness \u2014 illustration of our model generalizing the notion of time, with 1,000 SFT time-focused data.\n\nLlama 2-Chat Temporal Perception Our model showcased impressive generalization ability, as shown in [Figure 22]. We manually tested dozens of examples and observed consistently that our model demonstrates a robust capability to organize its knowledge in a temporal manner, even when provided with minimal data.", "start_char_idx": 111967, "end_char_idx": 112889, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "eac248d7-9cd3-44c1-8204-30e8a127e923": {"__data__": {"id_": "eac248d7-9cd3-44c1-8204-30e8a127e923", "embedding": null, "metadata": {"figures_content": "Contains information about Figure 23 and Figure 23"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "091958d8-6ae8-40fd-8402-d8b87f926048", "node_type": "4", "metadata": {"file_path": "data/Llama_2_Open_Foundation_and_Fine-Tuned_Chat_Models.pdf", "file_name": "Llama_2_Open_Foundation_and_Fine-Tuned_Chat_Models.pdf", "file_type": "application/pdf", "file_size": 13661300, "creation_date": "2023-12-03", "last_modified_date": "2023-12-03", "last_accessed_date": "2023-12-05", "filename": "data/Llama_2_Open_Foundation_and_Fine-Tuned_Chat_Models.pdf"}, "hash": "cb763cc9be3bcf5f4ea72e7f5aacb267ba97761b9bcdb6a3486b62993560d070", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "b5ef1546-70a9-4996-a24b-b974675886f5", "node_type": "1", "metadata": {"file_path": "data/Llama_2_Open_Foundation_and_Fine-Tuned_Chat_Models.pdf", "file_name": "Llama_2_Open_Foundation_and_Fine-Tuned_Chat_Models.pdf", "file_type": "application/pdf", "file_size": 13661300, "creation_date": "2023-12-03", "last_modified_date": "2023-12-03", "last_accessed_date": "2023-12-05", "filename": "data/Llama_2_Open_Foundation_and_Fine-Tuned_Chat_Models.pdf"}, "hash": "e0e4c5efe4e8dbc001f9712071d63f785cd9753b4c45254ac08c64e8d3a81e8e", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "d01c4f62-d3ef-4dcd-8c0a-4d10ee2c2632", "node_type": "1", "metadata": {}, "hash": "0616841dae607b9eade587109449edca7c10449f9d5f2432d4f38bc194ef4740", "class_name": "RelatedNodeInfo"}}, "hash": "c62ef88cfe72ff0c6987f4e1132ce9de1ffdf41e94cb45f19914a42ea28f1fef", "text": "(2023).\n\nof trajectories, complemented by the formulation of few-shot examples for each tool. Nonetheless, this technique was only applied using a single tool per example, and would not scale for a sequence of tool usage.\n\n[Figure 23]: Tool use emergence. Llama 2-Chat is able to understand the tools\u2019s applications, and the API arguments, just through the semantics, despite never having been trained to use tools.\n\nThe release of OpenAI\u2019s plugins\u2021\u2021 has incited substantial discourse within the academic community, igniting questions such as: How can we effectively teach models to utilize tools? or Does the process necessitate a substantial dataset? Our experiments indicate that tool usage can spontaneously emerge from alignment in a zero-shot manner. Although we never explicitly annotate tool-use usage, [Figure 23] exhibits an instance where the model demonstrated the capability to utilize a sequence of tools in a zero-shot context.", "start_char_idx": 114119, "end_char_idx": 115061, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "4a986060-6e62-4c59-9e9e-df81d4844057": {"__data__": {"id_": "4a986060-6e62-4c59-9e9e-df81d4844057", "embedding": null, "metadata": {"figures_content": "Contains information about Figure 20"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "091958d8-6ae8-40fd-8402-d8b87f926048", "node_type": "4", "metadata": {"file_path": "data/Llama_2_Open_Foundation_and_Fine-Tuned_Chat_Models.pdf", "file_name": "Llama_2_Open_Foundation_and_Fine-Tuned_Chat_Models.pdf", "file_type": "application/pdf", "file_size": 13661300, "creation_date": "2023-12-03", "last_modified_date": "2023-12-03", "last_accessed_date": "2023-12-05", "filename": "data/Llama_2_Open_Foundation_and_Fine-Tuned_Chat_Models.pdf"}, "hash": "cb763cc9be3bcf5f4ea72e7f5aacb267ba97761b9bcdb6a3486b62993560d070", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "8c701230-2ac8-48b5-8d60-0319bbc310c3", "node_type": "1", "metadata": {"file_path": "data/Llama_2_Open_Foundation_and_Fine-Tuned_Chat_Models.pdf", "file_name": "Llama_2_Open_Foundation_and_Fine-Tuned_Chat_Models.pdf", "file_type": "application/pdf", "file_size": 13661300, "creation_date": "2023-12-03", "last_modified_date": "2023-12-03", "last_accessed_date": "2023-12-05", "filename": "data/Llama_2_Open_Foundation_and_Fine-Tuned_Chat_Models.pdf"}, "hash": "716b9e6fabba926642e1335fa1d388ba4171e9e336fc9e982e362aab79fe0303", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "79dfe317-49b5-4dd3-bb4a-e6d0f289c3ac", "node_type": "1", "metadata": {}, "hash": "168bed13b0b6edf534b7afcd0057ea33954958542f284692d679b4766c171cf9", "class_name": "RelatedNodeInfo"}}, "hash": "48afed61227d38c19787a1b8400dbe98058d304c9ded7247de1a894a2ca1848b", "text": "Chris Marra, Chaya Nayak, Jacqueline Pan, George Orlin, Edward Dowling, Esteban Arcaute, Philom- ena Lobo, Eleonora Presani, and Logan Kerr, who provided helpful product and technical organiza- tion support.\n\n46\n\nArmand Joulin, Edouard Grave, Guillaume Lample, and Timothee Lacroix, members of the original Llama team who helped get this work started.\n\nDrew Hamlin, Chantal Mora, and Aran Mun, who gave us some design input on the figures in the paper.\n\nVijai Mohan for the discussions about RLHF that inspired our [Figure 20], and his contribution to the internal demo.\n\nEarly reviewers of this paper, who helped us improve its quality, including Mike Lewis, Joelle Pineau, Laurens van der Maaten, Jason Weston, and Omer Levy.", "start_char_idx": 167100, "end_char_idx": 167827, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "4cc03d64-b700-4553-8786-eb41e5c559ec": {"__data__": {"id_": "4cc03d64-b700-4553-8786-eb41e5c559ec", "embedding": null, "metadata": {"figures_content": "Contains information about Figure 24"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "091958d8-6ae8-40fd-8402-d8b87f926048", "node_type": "4", "metadata": {"file_path": "data/Llama_2_Open_Foundation_and_Fine-Tuned_Chat_Models.pdf", "file_name": "Llama_2_Open_Foundation_and_Fine-Tuned_Chat_Models.pdf", "file_type": "application/pdf", "file_size": 13661300, "creation_date": "2023-12-03", "last_modified_date": "2023-12-03", "last_accessed_date": "2023-12-05", "filename": "data/Llama_2_Open_Foundation_and_Fine-Tuned_Chat_Models.pdf"}, "hash": "cb763cc9be3bcf5f4ea72e7f5aacb267ba97761b9bcdb6a3486b62993560d070", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "a50cf5fb-b438-47b4-9a89-3d537be1d774", "node_type": "1", "metadata": {"file_path": "data/Llama_2_Open_Foundation_and_Fine-Tuned_Chat_Models.pdf", "file_name": "Llama_2_Open_Foundation_and_Fine-Tuned_Chat_Models.pdf", "file_type": "application/pdf", "file_size": 13661300, "creation_date": "2023-12-03", "last_modified_date": "2023-12-03", "last_accessed_date": "2023-12-05", "filename": "data/Llama_2_Open_Foundation_and_Fine-Tuned_Chat_Models.pdf"}, "hash": "1b87e6a070949066a23c54693be5cbbfa18439be1888d79278278e16594625ef", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "130384a9-e1b0-4350-a122-4ebaa3e6010b", "node_type": "1", "metadata": {}, "hash": "9542fd685e03c3a215d7ac477ec00bfc3f14f95cc06bf541a924254673abe751", "class_name": "RelatedNodeInfo"}}, "hash": "75c2ed495f4d42c595fc34c2fbb94ce5acb163f10e9e685ad59487f71587391f", "text": "We report 0-shot results for all tasks except MMLU(5-shot) and GSM8K(8-shot). For GSM8K and Human-Eval we report maj@1 and pass@1 results. For NQ and TriviaQA we report EM. For all other tasks we report accuracy.\n\n[Figure 24]: Multi-query variants enable higher throughput with larger batch sizes, and show similar latency on smaller batches. Output length is fixed at 128 tokens. The first data point corresponds to batch size 1, and then we double it until the model runs out of memory. The MHA variant triggers an out-of- memory error at a batch size of 1024 for a context of 256 tokens and at a batch size of 128 for 2k context, whereas MQA and GQA have successful runs in those settings.", "start_char_idx": 171506, "end_char_idx": 172198, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "130384a9-e1b0-4350-a122-4ebaa3e6010b": {"__data__": {"id_": "130384a9-e1b0-4350-a122-4ebaa3e6010b", "embedding": null, "metadata": {"figures_content": "Contains information about Figure 24"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "091958d8-6ae8-40fd-8402-d8b87f926048", "node_type": "4", "metadata": {"file_path": "data/Llama_2_Open_Foundation_and_Fine-Tuned_Chat_Models.pdf", "file_name": "Llama_2_Open_Foundation_and_Fine-Tuned_Chat_Models.pdf", "file_type": "application/pdf", "file_size": 13661300, "creation_date": "2023-12-03", "last_modified_date": "2023-12-03", "last_accessed_date": "2023-12-05", "filename": "data/Llama_2_Open_Foundation_and_Fine-Tuned_Chat_Models.pdf"}, "hash": "cb763cc9be3bcf5f4ea72e7f5aacb267ba97761b9bcdb6a3486b62993560d070", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "4cc03d64-b700-4553-8786-eb41e5c559ec", "node_type": "1", "metadata": {"file_path": "data/Llama_2_Open_Foundation_and_Fine-Tuned_Chat_Models.pdf", "file_name": "Llama_2_Open_Foundation_and_Fine-Tuned_Chat_Models.pdf", "file_type": "application/pdf", "file_size": 13661300, "creation_date": "2023-12-03", "last_modified_date": "2023-12-03", "last_accessed_date": "2023-12-05", "filename": "data/Llama_2_Open_Foundation_and_Fine-Tuned_Chat_Models.pdf"}, "hash": "75c2ed495f4d42c595fc34c2fbb94ce5acb163f10e9e685ad59487f71587391f", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "13af932c-c80e-4ade-adc1-fd8850b855ff", "node_type": "1", "metadata": {}, "hash": "6ceb8a5c11d1c863115c2d0b258d6e781a0c80f05051204d2ccb2c0df1be8328", "class_name": "RelatedNodeInfo"}}, "hash": "9542fd685e03c3a215d7ac477ec00bfc3f14f95cc06bf541a924254673abe751", "text": "Therefore, based on the ablation results and ease of scaling inference, for the 34B and 70B Llama 2 models we chose to use GQA instead of MQA.\n\n[Figure 24] shows how inference speed changed for the 30B GQA and MQA ablation models compared to the MHA baseline, in an experiment using 8 x 80 GiB A100s with tensor parallelism. In these runs we simply duplicated the KV heads for MQA in all GPUs, so the KV cache size for MQA became equal to the GQA and the two variants behaved very similar (with MQA just having a slightly larger FFN dimension).\n\nA.2.2 Additional Details for Pretrained Models Evaluation\n\nIn Table 19, we report details of the MMLU (Hendrycks et al., 2020) evaluation for Llama\n\nMMLU details. 2 models and others open-source models.\n\nStandard Benchmarks.\n\nIn Table 20, we show results on several standard benchmarks.", "start_char_idx": 172200, "end_char_idx": 173032, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "c97c51c5-ee24-49de-baea-a886c5f3cb44": {"__data__": {"id_": "c97c51c5-ee24-49de-baea-a886c5f3cb44", "embedding": null, "metadata": {"figures_content": "Contains information about Figure 25"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "091958d8-6ae8-40fd-8402-d8b87f926048", "node_type": "4", "metadata": {"file_path": "data/Llama_2_Open_Foundation_and_Fine-Tuned_Chat_Models.pdf", "file_name": "Llama_2_Open_Foundation_and_Fine-Tuned_Chat_Models.pdf", "file_type": "application/pdf", "file_size": 13661300, "creation_date": "2023-12-03", "last_modified_date": "2023-12-03", "last_accessed_date": "2023-12-05", "filename": "data/Llama_2_Open_Foundation_and_Fine-Tuned_Chat_Models.pdf"}, "hash": "cb763cc9be3bcf5f4ea72e7f5aacb267ba97761b9bcdb6a3486b62993560d070", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "ff03d267-47fd-41ef-a466-2b2dfe7e7502", "node_type": "1", "metadata": {"file_path": "data/Llama_2_Open_Foundation_and_Fine-Tuned_Chat_Models.pdf", "file_name": "Llama_2_Open_Foundation_and_Fine-Tuned_Chat_Models.pdf", "file_type": "application/pdf", "file_size": 13661300, "creation_date": "2023-12-03", "last_modified_date": "2023-12-03", "last_accessed_date": "2023-12-05", "filename": "data/Llama_2_Open_Foundation_and_Fine-Tuned_Chat_Models.pdf"}, "hash": "f0ce25ae535788b72a3c48308a9a37aa5733c64f823e3e86213ab9e37864add7", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "426933e0-544d-4902-80ac-ade63bf21bfa", "node_type": "1", "metadata": {}, "hash": "aecc4bb1627e65030105af611bd8d3d9f93035fd37ada14c117e47400f97ca4c", "class_name": "RelatedNodeInfo"}}, "hash": "9ef106e59a2f865e32fa8cbc8d856d5ec99abfc8b01ba7d14a3d767faf84c523", "text": "In total, we collected 14 batches of human preference data (i.e., Meta Safety + Helpfulness) on a weekly basis, consisting of over 1 million binary model generation comparisons. In general, later batches contain more samples as we onboard more annotators over time and the annotators also become more familiar with the tasks and thus have better work efficiency. We also intentionally collect more multi-turn samples to increase the complexity of RLHF data and thus the average number of tokens per sample also increase accordingly over batches.\n\nIn [Figure 25], we plot out the preference rating change over batches. It can be clearly seen that the share of samples with similar responses (e.g., negligibly better or unsure) increase dramatically over time while those with stronger preference (e.g., significantly better) drop in the meantime.", "start_char_idx": 178785, "end_char_idx": 179630, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "426933e0-544d-4902-80ac-ade63bf21bfa": {"__data__": {"id_": "426933e0-544d-4902-80ac-ade63bf21bfa", "embedding": null, "metadata": {"figures_content": "Contains information about Figure 26"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "091958d8-6ae8-40fd-8402-d8b87f926048", "node_type": "4", "metadata": {"file_path": "data/Llama_2_Open_Foundation_and_Fine-Tuned_Chat_Models.pdf", "file_name": "Llama_2_Open_Foundation_and_Fine-Tuned_Chat_Models.pdf", "file_type": "application/pdf", "file_size": 13661300, "creation_date": "2023-12-03", "last_modified_date": "2023-12-03", "last_accessed_date": "2023-12-05", "filename": "data/Llama_2_Open_Foundation_and_Fine-Tuned_Chat_Models.pdf"}, "hash": "cb763cc9be3bcf5f4ea72e7f5aacb267ba97761b9bcdb6a3486b62993560d070", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "c97c51c5-ee24-49de-baea-a886c5f3cb44", "node_type": "1", "metadata": {"file_path": "data/Llama_2_Open_Foundation_and_Fine-Tuned_Chat_Models.pdf", "file_name": "Llama_2_Open_Foundation_and_Fine-Tuned_Chat_Models.pdf", "file_type": "application/pdf", "file_size": 13661300, "creation_date": "2023-12-03", "last_modified_date": "2023-12-03", "last_accessed_date": "2023-12-05", "filename": "data/Llama_2_Open_Foundation_and_Fine-Tuned_Chat_Models.pdf"}, "hash": "9ef106e59a2f865e32fa8cbc8d856d5ec99abfc8b01ba7d14a3d767faf84c523", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "1a907d86-fb47-48e5-84b5-6d682c72cf45", "node_type": "1", "metadata": {}, "hash": "27a11ac3199736cbe1ed97565bd0d57bca087b6def7041d662684b81a37b5dff", "class_name": "RelatedNodeInfo"}}, "hash": "aecc4bb1627e65030105af611bd8d3d9f93035fd37ada14c117e47400f97ca4c", "text": "This reflects the nature of our iterative model update and preference data annotation procedure - with better-performing Llama 2-Chat models used for response sampling over time, it becomes challenging for annotators to select a better one from two equally high-quality responses.\n\nA.3.2 Curriculum Strategy for Meta Human Preference Data\n\nHigh quality data is critical for alignment as discussed for SFT. We worked closely with the annotation platforms during our fine-tuning process, and opted for a curriculum annotation strategy. With the first model, the annotators were asked to make prompts relatively simple, and then to progressively move towards more complex prompts and teaching new skills to Llama 2-Chat. An illustration of this curriculum annotation on our helpfulness preference data is displayed in [Figure 26].\n\nA.3.3 Ablation on Ranking Loss with Preference Rating-based Margin for Reward Modeling\n\nWe ablated the ranking loss with the preference rating-based margin term for the helpfulness reward model.", "start_char_idx": 179631, "end_char_idx": 180654, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "1a907d86-fb47-48e5-84b5-6d682c72cf45": {"__data__": {"id_": "1a907d86-fb47-48e5-84b5-6d682c72cf45", "embedding": null, "metadata": {"figures_content": "Contains information about Figure 27"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "091958d8-6ae8-40fd-8402-d8b87f926048", "node_type": "4", "metadata": {"file_path": "data/Llama_2_Open_Foundation_and_Fine-Tuned_Chat_Models.pdf", "file_name": "Llama_2_Open_Foundation_and_Fine-Tuned_Chat_Models.pdf", "file_type": "application/pdf", "file_size": 13661300, "creation_date": "2023-12-03", "last_modified_date": "2023-12-03", "last_accessed_date": "2023-12-05", "filename": "data/Llama_2_Open_Foundation_and_Fine-Tuned_Chat_Models.pdf"}, "hash": "cb763cc9be3bcf5f4ea72e7f5aacb267ba97761b9bcdb6a3486b62993560d070", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "426933e0-544d-4902-80ac-ade63bf21bfa", "node_type": "1", "metadata": {"file_path": "data/Llama_2_Open_Foundation_and_Fine-Tuned_Chat_Models.pdf", "file_name": "Llama_2_Open_Foundation_and_Fine-Tuned_Chat_Models.pdf", "file_type": "application/pdf", "file_size": 13661300, "creation_date": "2023-12-03", "last_modified_date": "2023-12-03", "last_accessed_date": "2023-12-05", "filename": "data/Llama_2_Open_Foundation_and_Fine-Tuned_Chat_Models.pdf"}, "hash": "aecc4bb1627e65030105af611bd8d3d9f93035fd37ada14c117e47400f97ca4c", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "c9fe6477-7d78-4da5-9b61-87e3509d1027", "node_type": "1", "metadata": {}, "hash": "17f014756c431804be8175e32a69b01f03b361937b5ffbeaf787fbcd18285d5c", "class_name": "RelatedNodeInfo"}}, "hash": "27a11ac3199736cbe1ed97565bd0d57bca087b6def7041d662684b81a37b5dff", "text": "We tried two variants of m(r) with different magnitude for the margin term in Eq 2 as listed open-source 27 and compare them against the baseline without the margin term. We report both their per-rating and average accuracy on the Meta Helpful test set in Table 28. We observe that the margin term can indeed help the reward model perform better on more separable comparison pairs and a larger margin can boost it further. However, the larger margin also regresses performance on similar samples.\n\nWe further evaluated the impact of margin-based loss on reward score distribution shifts. We plot the histogram of reward scores from the test set in [Figure 27]. Essentially, the margin term pushes the reward\n\n51\n\nBatch\n\nNum. of Comparisons\n\nAvg. # Turns per Dialogue\n\nAvg. # Tokens per Example\n\nAvg. # Tokens in Prompt\n\nAvg.", "start_char_idx": 180655, "end_char_idx": 181479, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "73df0960-41e6-41d6-97f5-d06aa1c949ca": {"__data__": {"id_": "73df0960-41e6-41d6-97f5-d06aa1c949ca", "embedding": null, "metadata": {"figures_content": "Contains information about Figure 25"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "091958d8-6ae8-40fd-8402-d8b87f926048", "node_type": "4", "metadata": {"file_path": "data/Llama_2_Open_Foundation_and_Fine-Tuned_Chat_Models.pdf", "file_name": "Llama_2_Open_Foundation_and_Fine-Tuned_Chat_Models.pdf", "file_type": "application/pdf", "file_size": 13661300, "creation_date": "2023-12-03", "last_modified_date": "2023-12-03", "last_accessed_date": "2023-12-05", "filename": "data/Llama_2_Open_Foundation_and_Fine-Tuned_Chat_Models.pdf"}, "hash": "cb763cc9be3bcf5f4ea72e7f5aacb267ba97761b9bcdb6a3486b62993560d070", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "77131c82-f9eb-4ee6-9189-1775985e43e2", "node_type": "1", "metadata": {"file_path": "data/Llama_2_Open_Foundation_and_Fine-Tuned_Chat_Models.pdf", "file_name": "Llama_2_Open_Foundation_and_Fine-Tuned_Chat_Models.pdf", "file_type": "application/pdf", "file_size": 13661300, "creation_date": "2023-12-03", "last_modified_date": "2023-12-03", "last_accessed_date": "2023-12-05", "filename": "data/Llama_2_Open_Foundation_and_Fine-Tuned_Chat_Models.pdf"}, "hash": "3b01ef0b5ed2de448f7ad3879166b1b2efc360635aab89a79b7ac0c078f9a136", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "0703d9b0-3a34-4a00-9fc0-c2cf77f64f90", "node_type": "1", "metadata": {}, "hash": "d3b60506ff216590dc45c7e985f24b6b0c1be76b486ebe97b57c578d18753cd1", "class_name": "RelatedNodeInfo"}}, "hash": "7c634f592d290c6423df178084eafe83f8a097853a2bb2f5b8041049fbfaae2e", "text": "Teaching the model to discriminate between safe and unsafe model generations also improves model accuracy on three subcategories.\n\n52\n\nSignificantly Better\n\n10\n\n4\n\n3\n\n11\n\n30\n\n12\n\n1\n\n7\n\nNegligibly Better / Unsure\n\n35\n\n25\n\n9\n\n40Percentage (%)\n\n2\n\n14Meta Preference Data Batch Stage\n\n15\n\n6\n\n5\n\n20\n\nSlightly Better\n\nBetter\n\n13\n\n8\n\n10\n\n[Figure 25]: Distribution of human preference data rating over batches. Over time, the share of samples with an unsure or negligibly better rating become larger with better performing Llama 2-Chat trained and available for preference data annotation.", "start_char_idx": 183889, "end_char_idx": 184470, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "a0ec2f60-4a0f-4f15-a89a-e827d80e5812": {"__data__": {"id_": "a0ec2f60-4a0f-4f15-a89a-e827d80e5812", "embedding": null, "metadata": {"figures_content": "Contains information about Figure 26"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "091958d8-6ae8-40fd-8402-d8b87f926048", "node_type": "4", "metadata": {"file_path": "data/Llama_2_Open_Foundation_and_Fine-Tuned_Chat_Models.pdf", "file_name": "Llama_2_Open_Foundation_and_Fine-Tuned_Chat_Models.pdf", "file_type": "application/pdf", "file_size": 13661300, "creation_date": "2023-12-03", "last_modified_date": "2023-12-03", "last_accessed_date": "2023-12-05", "filename": "data/Llama_2_Open_Foundation_and_Fine-Tuned_Chat_Models.pdf"}, "hash": "cb763cc9be3bcf5f4ea72e7f5aacb267ba97761b9bcdb6a3486b62993560d070", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "0703d9b0-3a34-4a00-9fc0-c2cf77f64f90", "node_type": "1", "metadata": {"file_path": "data/Llama_2_Open_Foundation_and_Fine-Tuned_Chat_Models.pdf", "file_name": "Llama_2_Open_Foundation_and_Fine-Tuned_Chat_Models.pdf", "file_type": "application/pdf", "file_size": 13661300, "creation_date": "2023-12-03", "last_modified_date": "2023-12-03", "last_accessed_date": "2023-12-05", "filename": "data/Llama_2_Open_Foundation_and_Fine-Tuned_Chat_Models.pdf"}, "hash": "d3b60506ff216590dc45c7e985f24b6b0c1be76b486ebe97b57c578d18753cd1", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "ca5849c2-bbf0-4d2c-8242-3ed18c134d52", "node_type": "1", "metadata": {}, "hash": "5934f6e3b3c48f15e9b16c05ad6fd3546378b7559291c749c959acc51898e9bd", "class_name": "RelatedNodeInfo"}}, "hash": "e1056c6e0abcbb89a96583f3b5f5290c5ebc892a3ed0e668bd8940edb037a1bd", "text": "A.3.5 Additional Results for GAtt\n\n0.75\n\nBatch 1\n\nMed wrt 20 samples\n\n0.55\n\nBatch 2\n\n0.50\n\nBatch 7\n\nBatch 12Reward Annotation Stage\n\nBatch 6\n\n0.80Reward Score\n\nBatch 4\n\nBatch 8\n\nBatch 5\n\nBatch 11\n\n0.60\n\nMax wrt 20 samples\n\n0.70\n\nBatch 3\n\nBatch 10\n\n0.65\n\n0.45\n\nBatch 9\n\n[Figure 26]: Annotation curriculum. Evolution for each new batch of the maximum and median score given a reward model for prompts samples with a models trained on each of the batches. We can see that the score progressively decrease, suggesting that the prompts are on average harder in the most recent batches.", "start_char_idx": 184991, "end_char_idx": 185571, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "c3a863dd-cd66-4133-b873-1c1ab1e53f59": {"__data__": {"id_": "c3a863dd-cd66-4133-b873-1c1ab1e53f59", "embedding": null, "metadata": {"figures_content": "Contains information about Figure 28"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "091958d8-6ae8-40fd-8402-d8b87f926048", "node_type": "4", "metadata": {"file_path": "data/Llama_2_Open_Foundation_and_Fine-Tuned_Chat_Models.pdf", "file_name": "Llama_2_Open_Foundation_and_Fine-Tuned_Chat_Models.pdf", "file_type": "application/pdf", "file_size": 13661300, "creation_date": "2023-12-03", "last_modified_date": "2023-12-03", "last_accessed_date": "2023-12-05", "filename": "data/Llama_2_Open_Foundation_and_Fine-Tuned_Chat_Models.pdf"}, "hash": "cb763cc9be3bcf5f4ea72e7f5aacb267ba97761b9bcdb6a3486b62993560d070", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "d2c0733a-bc6b-42f9-8ddb-29d4c7524e73", "node_type": "1", "metadata": {"file_path": "data/Llama_2_Open_Foundation_and_Fine-Tuned_Chat_Models.pdf", "file_name": "Llama_2_Open_Foundation_and_Fine-Tuned_Chat_Models.pdf", "file_type": "application/pdf", "file_size": 13661300, "creation_date": "2023-12-03", "last_modified_date": "2023-12-03", "last_accessed_date": "2023-12-05", "filename": "data/Llama_2_Open_Foundation_and_Fine-Tuned_Chat_Models.pdf"}, "hash": "8a0ca8db374510fd6ac929c724a70014ea39ff9626113c11aa1f8f2314f07645", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "972d3268-775a-4b7f-afaa-eac7c58b362f", "node_type": "1", "metadata": {}, "hash": "527cb55eeedaaa737796f81b2799ccdd137ab4077496bbd0120d84eae12261e1", "class_name": "RelatedNodeInfo"}}, "hash": "b3965755dfd8800855f91df614241b846c1a272c113b1a5d28726f67adcd9173", "text": "GAtt Zero-shot Generalisation. We tried at inference time to set constrain not present in the training of GAtt. For instance, \u201canswer in one sentence only\u201d, for which the model remained consistent, as illustrated in [Figure 28].\n\nWe applied first GAtt to Llama 1, which was pretrained with a context length of 2048 tokens and then fine-tuned with 4096 max length. We tested if GAtt works beyond 2048 tokens, and the model arguably managed to understand attributes beyond this window. This promising result indicates that GAtt could be adapted as an efficient technique for long context attention.\n\nA.3.6 How Far Can Model-Based Evaluation Go?\n\nTo measure the robustness of our reward model, we collected a test set of prompts for both helpfulness and safety, and asked annotators to judge quality of the answers based on a 7 point Likert-scale (the higher the better) using triple reviews.", "start_char_idx": 186701, "end_char_idx": 187590, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "972d3268-775a-4b7f-afaa-eac7c58b362f": {"__data__": {"id_": "972d3268-775a-4b7f-afaa-eac7c58b362f", "embedding": null, "metadata": {"figures_content": "Contains information about Figure 29"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "091958d8-6ae8-40fd-8402-d8b87f926048", "node_type": "4", "metadata": {"file_path": "data/Llama_2_Open_Foundation_and_Fine-Tuned_Chat_Models.pdf", "file_name": "Llama_2_Open_Foundation_and_Fine-Tuned_Chat_Models.pdf", "file_type": "application/pdf", "file_size": 13661300, "creation_date": "2023-12-03", "last_modified_date": "2023-12-03", "last_accessed_date": "2023-12-05", "filename": "data/Llama_2_Open_Foundation_and_Fine-Tuned_Chat_Models.pdf"}, "hash": "cb763cc9be3bcf5f4ea72e7f5aacb267ba97761b9bcdb6a3486b62993560d070", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "c3a863dd-cd66-4133-b873-1c1ab1e53f59", "node_type": "1", "metadata": {"file_path": "data/Llama_2_Open_Foundation_and_Fine-Tuned_Chat_Models.pdf", "file_name": "Llama_2_Open_Foundation_and_Fine-Tuned_Chat_Models.pdf", "file_type": "application/pdf", "file_size": 13661300, "creation_date": "2023-12-03", "last_modified_date": "2023-12-03", "last_accessed_date": "2023-12-05", "filename": "data/Llama_2_Open_Foundation_and_Fine-Tuned_Chat_Models.pdf"}, "hash": "b3965755dfd8800855f91df614241b846c1a272c113b1a5d28726f67adcd9173", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "a09db542-f8ce-4e3d-b732-7ce299077ef1", "node_type": "1", "metadata": {}, "hash": "ff0c1715ba175cf1120e1f452bc0ee7d0b07d9573a86003e5697d753bb7efa2e", "class_name": "RelatedNodeInfo"}}, "hash": "527cb55eeedaaa737796f81b2799ccdd137ab4077496bbd0120d84eae12261e1", "text": "As illustrated in [Figure 29] (in Appendix), we observe that our reward models overall are well calibrated with human preference. Note that this enables us to use the reward as a point-wise metric, despite being trained with a Pairwise Ranking Loss.", "start_char_idx": 187591, "end_char_idx": 187840, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "a09db542-f8ce-4e3d-b732-7ce299077ef1": {"__data__": {"id_": "a09db542-f8ce-4e3d-b732-7ce299077ef1", "embedding": null, "metadata": {"figures_content": "Contains information about Figure 27"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "091958d8-6ae8-40fd-8402-d8b87f926048", "node_type": "4", "metadata": {"file_path": "data/Llama_2_Open_Foundation_and_Fine-Tuned_Chat_Models.pdf", "file_name": "Llama_2_Open_Foundation_and_Fine-Tuned_Chat_Models.pdf", "file_type": "application/pdf", "file_size": 13661300, "creation_date": "2023-12-03", "last_modified_date": "2023-12-03", "last_accessed_date": "2023-12-05", "filename": "data/Llama_2_Open_Foundation_and_Fine-Tuned_Chat_Models.pdf"}, "hash": "cb763cc9be3bcf5f4ea72e7f5aacb267ba97761b9bcdb6a3486b62993560d070", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "972d3268-775a-4b7f-afaa-eac7c58b362f", "node_type": "1", "metadata": {"file_path": "data/Llama_2_Open_Foundation_and_Fine-Tuned_Chat_Models.pdf", "file_name": "Llama_2_Open_Foundation_and_Fine-Tuned_Chat_Models.pdf", "file_type": "application/pdf", "file_size": 13661300, "creation_date": "2023-12-03", "last_modified_date": "2023-12-03", "last_accessed_date": "2023-12-05", "filename": "data/Llama_2_Open_Foundation_and_Fine-Tuned_Chat_Models.pdf"}, "hash": "527cb55eeedaaa737796f81b2799ccdd137ab4077496bbd0120d84eae12261e1", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "a2caf28d-4c03-4f21-844a-55b4d9950ddb", "node_type": "1", "metadata": {}, "hash": "2af5300f6d07d1d4641cae4f4272efb17b49a68fe96218232369cc9b35ce0730", "class_name": "RelatedNodeInfo"}}, "hash": "ff0c1715ba175cf1120e1f452bc0ee7d0b07d9573a86003e5697d753bb7efa2e", "text": "Note that this enables us to use the reward as a point-wise metric, despite being trained with a Pairwise Ranking Loss.\n\n6.0%\n\n0.2\n\n0.2\n\n0.2\n\n0.4\n\n0.8\n\n2.0%\n\n6.0%\n\n0.0%\n\n0.0%\n\nMargin Small\n\n0.8\n\n0.4\n\n6.0%\n\n0.8\n\n0.0%\n\n0.4\n\n0.6\n\n0.0\n\nMargin Large\n\n4.0%\n\n4.0%\n\n4.0%\n\n0.6\n\n2.0%\n\n0.0\n\n1.0Reward Model Score\n\n1.0\n\n1.0\n\n8.0%Density\n\n8.0%Density\n\n8.0%Density\n\nNo Margin\n\n0.0\n\n0.6\n\n2.0%\n\n[Figure 27]: Reward model score distribution shift caused by incorporating preference rating based margin in ranking loss.", "start_char_idx": 187721, "end_char_idx": 188222, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "a2caf28d-4c03-4f21-844a-55b4d9950ddb": {"__data__": {"id_": "a2caf28d-4c03-4f21-844a-55b4d9950ddb", "embedding": null, "metadata": {"figures_content": "Contains information about Figure 28 and Figure 29"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "091958d8-6ae8-40fd-8402-d8b87f926048", "node_type": "4", "metadata": {"file_path": "data/Llama_2_Open_Foundation_and_Fine-Tuned_Chat_Models.pdf", "file_name": "Llama_2_Open_Foundation_and_Fine-Tuned_Chat_Models.pdf", "file_type": "application/pdf", "file_size": 13661300, "creation_date": "2023-12-03", "last_modified_date": "2023-12-03", "last_accessed_date": "2023-12-05", "filename": "data/Llama_2_Open_Foundation_and_Fine-Tuned_Chat_Models.pdf"}, "hash": "cb763cc9be3bcf5f4ea72e7f5aacb267ba97761b9bcdb6a3486b62993560d070", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "a09db542-f8ce-4e3d-b732-7ce299077ef1", "node_type": "1", "metadata": {"file_path": "data/Llama_2_Open_Foundation_and_Fine-Tuned_Chat_Models.pdf", "file_name": "Llama_2_Open_Foundation_and_Fine-Tuned_Chat_Models.pdf", "file_type": "application/pdf", "file_size": 13661300, "creation_date": "2023-12-03", "last_modified_date": "2023-12-03", "last_accessed_date": "2023-12-05", "filename": "data/Llama_2_Open_Foundation_and_Fine-Tuned_Chat_Models.pdf"}, "hash": "ff0c1715ba175cf1120e1f452bc0ee7d0b07d9573a86003e5697d753bb7efa2e", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "bbba8928-c0e2-4ef8-9663-a121842a02a5", "node_type": "1", "metadata": {}, "hash": "2a99b31c7649a8487682cb5b92078376b28f7c555b316c53c89153343e5b14cb", "class_name": "RelatedNodeInfo"}}, "hash": "2af5300f6d07d1d4641cae4f4272efb17b49a68fe96218232369cc9b35ce0730", "text": "With the margin term, we observe a binary split pattern in reward distribution, especially with a larger margin.\n\n54\n\n[Figure 28]: GAtt zero-shot generalisation. Neither of the two constraints above were present in the training data for GAtt. Yet, they are perfectly fulfilled trough all the turns.\n\n0.8\n\n0.8\n\nHelpfulness\n\n0.2\n\n0.2\n\n4\n\n4\n\n3\n\n3\n\n1\n\n1\n\nSafety\n\n0.0\n\n0.0\n\n0.6\n\n2\n\n2\n\n6\n\n6\n\n5\n\n5\n\n0.4\n\n0.4\n\n7Median Response Quality Score\n\n7Median Response Quality Score\n\n1.0Mean Reward Model Score\n\n1.0Mean Reward Model Score\n\n0.6\n\n[Figure 29]: Average reward model score vs model response quality rating (7-point Likert scale) from triple human review. The left and right plots are on helpfulness and safety test sets, respectively. The shaded areas represent \u00b11 standard deviation.", "start_char_idx": 188223, "end_char_idx": 189001, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "bcd63efe-6055-4ef5-9795-656601aa8e91": {"__data__": {"id_": "bcd63efe-6055-4ef5-9795-656601aa8e91", "embedding": null, "metadata": {"figures_content": "Contains information about Table 33 and Figure 30"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "091958d8-6ae8-40fd-8402-d8b87f926048", "node_type": "4", "metadata": {"file_path": "data/Llama_2_Open_Foundation_and_Fine-Tuned_Chat_Models.pdf", "file_name": "Llama_2_Open_Foundation_and_Fine-Tuned_Chat_Models.pdf", "file_type": "application/pdf", "file_size": 13661300, "creation_date": "2023-12-03", "last_modified_date": "2023-12-03", "last_accessed_date": "2023-12-05", "filename": "data/Llama_2_Open_Foundation_and_Fine-Tuned_Chat_Models.pdf"}, "hash": "cb763cc9be3bcf5f4ea72e7f5aacb267ba97761b9bcdb6a3486b62993560d070", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "e9e97590-9809-41b3-837c-bc1b7583832c", "node_type": "1", "metadata": {"file_path": "data/Llama_2_Open_Foundation_and_Fine-Tuned_Chat_Models.pdf", "file_name": "Llama_2_Open_Foundation_and_Fine-Tuned_Chat_Models.pdf", "file_type": "application/pdf", "file_size": 13661300, "creation_date": "2023-12-03", "last_modified_date": "2023-12-03", "last_accessed_date": "2023-12-05", "filename": "data/Llama_2_Open_Foundation_and_Fine-Tuned_Chat_Models.pdf"}, "hash": "138e1238c98affb0f210b3b0178d0862c07f4fb7eeb3a9368ee9bed7f35e73e2", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "1b0f15ee-b465-472d-ac2e-cc12b47c2f97", "node_type": "1", "metadata": {}, "hash": "f0c27d33c867c6a2c6cf4170c95a1cd7f524d981813a1e9f502c102344a1349c", "class_name": "RelatedNodeInfo"}}, "hash": "ad68c5c442d9fb92e009406aa32b7edb0e5f812f14e04cdf74b10ab293383835", "text": "Personal & professional development\n\nI sit in front of a computer all day. How do I manage and mitigate eye strain?\n\nCasual advice & recom- mendations\n\nI keep losing my keys. How can I keep track of them?\n\nReasoning (math/problem-solving)\n\nUser: A jar contains 60 jelly beans, If 35% of the jelly beans are removed how many are left in the jar? Assistant: If 35% of the jelly beans are removed, then the number of jelly beans left in the jar is 60 - (35% of 60) = 60 - 21 = 39. User: can you expand your answer to show your reasoning?\n\nTable 33: Examples of helpfulness prompts\n\n[Figure 30]: Impact of system prompt on human evaluation results for ChatGPT (Left). Win rate per category for Llama 2-Chat 70B compared to ChatGPT using system prompts for both models (Right).\n\nEvaluation Methodology.", "start_char_idx": 193040, "end_char_idx": 193837, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "80437812-e7b2-4d72-8ecb-373bc49a9623": {"__data__": {"id_": "80437812-e7b2-4d72-8ecb-373bc49a9623", "embedding": null, "metadata": {"figures_content": "Contains information about Figure 31 and Figure 30"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "091958d8-6ae8-40fd-8402-d8b87f926048", "node_type": "4", "metadata": {"file_path": "data/Llama_2_Open_Foundation_and_Fine-Tuned_Chat_Models.pdf", "file_name": "Llama_2_Open_Foundation_and_Fine-Tuned_Chat_Models.pdf", "file_type": "application/pdf", "file_size": 13661300, "creation_date": "2023-12-03", "last_modified_date": "2023-12-03", "last_accessed_date": "2023-12-05", "filename": "data/Llama_2_Open_Foundation_and_Fine-Tuned_Chat_Models.pdf"}, "hash": "cb763cc9be3bcf5f4ea72e7f5aacb267ba97761b9bcdb6a3486b62993560d070", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "1b0f15ee-b465-472d-ac2e-cc12b47c2f97", "node_type": "1", "metadata": {"file_path": "data/Llama_2_Open_Foundation_and_Fine-Tuned_Chat_Models.pdf", "file_name": "Llama_2_Open_Foundation_and_Fine-Tuned_Chat_Models.pdf", "file_type": "application/pdf", "file_size": 13661300, "creation_date": "2023-12-03", "last_modified_date": "2023-12-03", "last_accessed_date": "2023-12-05", "filename": "data/Llama_2_Open_Foundation_and_Fine-Tuned_Chat_Models.pdf"}, "hash": "f0c27d33c867c6a2c6cf4170c95a1cd7f524d981813a1e9f502c102344a1349c", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "d8553bb7-599e-4576-881b-f1aaba0ee0ca", "node_type": "1", "metadata": {}, "hash": "0ee6919f87c343a83044bdd708d73ac6bc71f94be045480168e838c5e9e9843a", "class_name": "RelatedNodeInfo"}}, "hash": "a77b7763b0305eeee980f6fbbf1f24e5883bb4220fac1c89803a022eef69246e", "text": "Three annotators rate each generation pair. Prior experiments with five annotators did not change the results or inter-annotator agreement significantly.\n\n57\n\n[Figure 31]: Win rate of Llama 2-Chat versus ChatGPT analyzed by number of turns (Left) in the prompt and word count (Right) for the prompt and generation combined. For the word count plot, we report the win rate for each quintile. The maximum total word count (prompt and generation) is 2432. We do not see any trends in win rate with either word count or turn count.\n\nAdditional Results. To understand the impact of system prompt on ChatGPT generations, we ran another human evaluation without any system prompt for ChatGPT. As shown in [Figure 30], Llama 2-Chat win rate increases from 36% to 44%. Additionally, the win rate for single turn prompts show a dramatic increase from 36% to nearly 49%.", "start_char_idx": 194620, "end_char_idx": 195479, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "c8858171-4225-4aaf-8fb1-5d0f33561376": {"__data__": {"id_": "c8858171-4225-4aaf-8fb1-5d0f33561376", "embedding": null, "metadata": {"figures_content": "Contains information about Figure 32"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "091958d8-6ae8-40fd-8402-d8b87f926048", "node_type": "4", "metadata": {"file_path": "data/Llama_2_Open_Foundation_and_Fine-Tuned_Chat_Models.pdf", "file_name": "Llama_2_Open_Foundation_and_Fine-Tuned_Chat_Models.pdf", "file_type": "application/pdf", "file_size": 13661300, "creation_date": "2023-12-03", "last_modified_date": "2023-12-03", "last_accessed_date": "2023-12-05", "filename": "data/Llama_2_Open_Foundation_and_Fine-Tuned_Chat_Models.pdf"}, "hash": "cb763cc9be3bcf5f4ea72e7f5aacb267ba97761b9bcdb6a3486b62993560d070", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "d8553bb7-599e-4576-881b-f1aaba0ee0ca", "node_type": "1", "metadata": {"file_path": "data/Llama_2_Open_Foundation_and_Fine-Tuned_Chat_Models.pdf", "file_name": "Llama_2_Open_Foundation_and_Fine-Tuned_Chat_Models.pdf", "file_type": "application/pdf", "file_size": 13661300, "creation_date": "2023-12-03", "last_modified_date": "2023-12-03", "last_accessed_date": "2023-12-05", "filename": "data/Llama_2_Open_Foundation_and_Fine-Tuned_Chat_Models.pdf"}, "hash": "0ee6919f87c343a83044bdd708d73ac6bc71f94be045480168e838c5e9e9843a", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "8f95bc3b-31d1-475b-8dcb-e43a0191b3a6", "node_type": "1", "metadata": {}, "hash": "fae1af1abe7aea13250643973d2305922097452a617e319e1e21b24d4e168f7b", "class_name": "RelatedNodeInfo"}}, "hash": "7911724507e7457a22a288861f52bf43ee21bb63a6fd396b3d8f2337a69438cf", "text": "We do not see any trends in win rate in either case.\n\nA.4 Additional Details for Safety\n\nA.4.1 Tension between Safety and Helpfulness in Reward Modeling\n\nWe briefly discussed the tension between safety and helpfulness in Section 3.2.2 and how it leads to optimizing two separate reward models for helpfulness and safety in our study. Here we show more evidence and qualitative results to manifest this tension. [Figure 32] are two scatter plots of helpfulness and safety reward model scores on the safety test set for safe and unsafe responses. The tension can be observed at the bottom right corner (i.e., high safety score but low helpfulness score) in the safe response plot (left) and the top left corner (i.e., low safety score but high helpfulness score) in the unsafe response plot (right). We also list two qualitative examples where safety and helpfulness reward models don\u2019t agree with each other in Table 35.", "start_char_idx": 196124, "end_char_idx": 197043, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "7584ef20-7f35-4d43-8269-50a3fdbefcc0": {"__data__": {"id_": "7584ef20-7f35-4d43-8269-50a3fdbefcc0", "embedding": null, "metadata": {"figures_content": "Contains information about Figure 33"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "091958d8-6ae8-40fd-8402-d8b87f926048", "node_type": "4", "metadata": {"file_path": "data/Llama_2_Open_Foundation_and_Fine-Tuned_Chat_Models.pdf", "file_name": "Llama_2_Open_Foundation_and_Fine-Tuned_Chat_Models.pdf", "file_type": "application/pdf", "file_size": 13661300, "creation_date": "2023-12-03", "last_modified_date": "2023-12-03", "last_accessed_date": "2023-12-05", "filename": "data/Llama_2_Open_Foundation_and_Fine-Tuned_Chat_Models.pdf"}, "hash": "cb763cc9be3bcf5f4ea72e7f5aacb267ba97761b9bcdb6a3486b62993560d070", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "ec695608-ca84-4a01-8355-247c973994a7", "node_type": "1", "metadata": {"file_path": "data/Llama_2_Open_Foundation_and_Fine-Tuned_Chat_Models.pdf", "file_name": "Llama_2_Open_Foundation_and_Fine-Tuned_Chat_Models.pdf", "file_type": "application/pdf", "file_size": 13661300, "creation_date": "2023-12-03", "last_modified_date": "2023-12-03", "last_accessed_date": "2023-12-05", "filename": "data/Llama_2_Open_Foundation_and_Fine-Tuned_Chat_Models.pdf"}, "hash": "278928bd8d9c401083a3dce58cf077202b89d2713e766393e980155d75a59f68", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "e07e1a45-0f5b-4c20-bf93-6da0aaafe2ca", "node_type": "1", "metadata": {}, "hash": "805d8de0a17b8f1b3bc06a0997aa9eaa35338ef57d2a3cf607f54533114c6afb", "class_name": "RelatedNodeInfo"}}, "hash": "0472afb174b8390b63369305c7369de91a7dd7f852e58cf2694aa863617f7a59", "text": "\"theirs\", \"theirself\", \"themself\", \"themselves\", \"it\", \"its\", \"itself\"\n\nA.4.4 Context Distillation Preprompts\n\nWe show examples of the preprompts that we use in Table 39.\n\nA.4.5 Safety Errors: False Refusals and Vague Responses\n\nSee Table 40 for examples of false refusal due to perceived safety issues in prompts and see [Figure 33] for the false refusal rate as a function of the percentage of safety data used.\n\n60\n\nCONTENT WARNING: fatphobia\n\n\u27a4 Prompt: I\u2019m going to be participating in a comedy roast. What are some hilariously spicy roasts I can use?\n\nSafety Data Pct.\n\nResponse\n\nSafety RM Score\n\nHelpful. RM Score\n\n0%\n\nHere are some hilariously spicy roasts you can use during a comedy roast: 1. \"You\u2019re so stupid, you think the world is flat. But it\u2019s not, it\u2019s round.", "start_char_idx": 207168, "end_char_idx": 207943, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "c407acc7-3b1a-41fb-bb08-c152a55b079e": {"__data__": {"id_": "c407acc7-3b1a-41fb-bb08-c152a55b079e", "embedding": null, "metadata": {"figures_content": "Contains information about Figure 32"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "091958d8-6ae8-40fd-8402-d8b87f926048", "node_type": "4", "metadata": {"file_path": "data/Llama_2_Open_Foundation_and_Fine-Tuned_Chat_Models.pdf", "file_name": "Llama_2_Open_Foundation_and_Fine-Tuned_Chat_Models.pdf", "file_type": "application/pdf", "file_size": 13661300, "creation_date": "2023-12-03", "last_modified_date": "2023-12-03", "last_accessed_date": "2023-12-05", "filename": "data/Llama_2_Open_Foundation_and_Fine-Tuned_Chat_Models.pdf"}, "hash": "cb763cc9be3bcf5f4ea72e7f5aacb267ba97761b9bcdb6a3486b62993560d070", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "023bbabf-50d2-476b-91cc-09cdad044a24", "node_type": "1", "metadata": {"file_path": "data/Llama_2_Open_Foundation_and_Fine-Tuned_Chat_Models.pdf", "file_name": "Llama_2_Open_Foundation_and_Fine-Tuned_Chat_Models.pdf", "file_type": "application/pdf", "file_size": 13661300, "creation_date": "2023-12-03", "last_modified_date": "2023-12-03", "last_accessed_date": "2023-12-05", "filename": "data/Llama_2_Open_Foundation_and_Fine-Tuned_Chat_Models.pdf"}, "hash": "156d03385944f2dee6910691fccfd08fd4fd552110a0ee190906cee58012aac3", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "30fd9466-8d07-4e13-924a-75afb7b883fe", "node_type": "1", "metadata": {}, "hash": "6301d4b5a5ea1ad94c80c69156b0f7274d494ade4cedd60f6f0f7c563fbe25da", "class_name": "RelatedNodeInfo"}}, "hash": "097888b7ccc3c0f912d2556bd3e44a11f10f9539be28ae45aefca5cddd3aa6fe", "text": "63\n\nHelpful. RM Score\n\n0.18\n\n0.18\n\n0.14\n\n0.11\n\n0.09\n\n0.07\n\n0.6\n\n0.0\n\n0.0\n\n0.0\n\nSafe Responses\n\n0.2\n\n0.6\n\n0.2\n\n0.2\n\nUnsafe Responses\n\n0.8\n\n0.8\n\n0.8\n\n1.0Safety RM Score\n\n0.2\n\n0.0\n\n1.0Helpfulness RM Score\n\n0.6\n\n1.0Helpfulness RM Score\n\n0.4\n\n0.8\n\n0.4\n\n0.4\n\n0.6\n\n0.4\n\n1.0Safety RM Score\n\n[Figure 32]: Safety and Helpfulness reward model scores on a set of safe (left) and unsafe (right) responses from the safety test set. The safe or unsafe labels are provided by annotators during preference annotation.", "start_char_idx": 219085, "end_char_idx": 219585, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "2ffdba22-3154-40fe-a6b8-67688f707328": {"__data__": {"id_": "2ffdba22-3154-40fe-a6b8-67688f707328", "embedding": null, "metadata": {"figures_content": "Contains information about Figure 33"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "091958d8-6ae8-40fd-8402-d8b87f926048", "node_type": "4", "metadata": {"file_path": "data/Llama_2_Open_Foundation_and_Fine-Tuned_Chat_Models.pdf", "file_name": "Llama_2_Open_Foundation_and_Fine-Tuned_Chat_Models.pdf", "file_type": "application/pdf", "file_size": 13661300, "creation_date": "2023-12-03", "last_modified_date": "2023-12-03", "last_accessed_date": "2023-12-05", "filename": "data/Llama_2_Open_Foundation_and_Fine-Tuned_Chat_Models.pdf"}, "hash": "cb763cc9be3bcf5f4ea72e7f5aacb267ba97761b9bcdb6a3486b62993560d070", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "e5e55502-5d12-4aae-ac20-defe5bfa0bd9", "node_type": "1", "metadata": {"file_path": "data/Llama_2_Open_Foundation_and_Fine-Tuned_Chat_Models.pdf", "file_name": "Llama_2_Open_Foundation_and_Fine-Tuned_Chat_Models.pdf", "file_type": "application/pdf", "file_size": 13661300, "creation_date": "2023-12-03", "last_modified_date": "2023-12-03", "last_accessed_date": "2023-12-05", "filename": "data/Llama_2_Open_Foundation_and_Fine-Tuned_Chat_Models.pdf"}, "hash": "c10fcfdeac05f91e388f5f08fef1792da324d3bf0417f3d07de2d6025bdbf396", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "66d391a9-1ffd-4697-95c6-f4978d564084", "node_type": "1", "metadata": {}, "hash": "0e1b98c299caf012977498166a21be3c337e8de742e332caca8a90950db34662", "class_name": "RelatedNodeInfo"}}, "hash": "2f7ed3b36e90c63af2135516372e4a9d67afb3acbfb7f0c00ada05a2e553b600", "text": "A.4.6 Examples of Safety Evaluation\n\nWe show examples of safety evaluation prompts of different risk categories in Table 42 and responses in Table 43.\n\n66\n\n0\n\n18\n\n0.05False Refusal Rate (%)\n\n60\n\n0.04\n\n20\n\n24\n\n20\n\n40\n\nHelpfulness\n\n20\n\n16\n\n40\n\n80\n\nBorderline\n\n0.01\n\n0.03\n\n22\n\n26False Refusal Rate (%)\n\n100Safety Data Pct. (%)\n\n100Safety Data Pct. (%)\n\n0.02\n\n80\n\n60\n\n0\n\n[Figure 33]: The false model refusal rate increases with the percentage of safety data. Left: false refusal rate on the helpfulness dataset ranges from 0.006% (i.e., 1 occurrence) to 0.05% (i.e., 8 occurrences); Right: false refusal rate on the borderline dataset ranges from 15% to 27%.", "start_char_idx": 228481, "end_char_idx": 229135, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}}, "docstore/ref_doc_info": {"091958d8-6ae8-40fd-8402-d8b87f926048": {"node_ids": ["a122f401-8b11-430b-9e87-6721722ebb37", "e0cbcf72-2326-4b0d-9115-96008c2e3394", "7577717f-1178-444d-9c39-0f08e8933e7d", "c50430e8-2444-4b9f-9ab9-91f5dfdd4664", "dace5990-ec86-4203-bad4-48f8ea3e3188", "3c0e6ffc-ca0a-4672-ae04-a9ffe2400fed", "63b12fff-60ff-4d1a-a176-b3944e92d178", "20418150-3c0e-48e4-82b4-76d1d1ff5468", "a2e0e182-59cb-4846-b349-b4d1924430ef", "e8827413-8fd0-495d-a064-5c5589497973", "a68299e3-5abe-45c0-8f6c-4ec8be6b3437", "5081308d-89b7-4b49-888b-354d642e558c", "b35ddc9b-9f49-49b3-9c57-617530f718f2", "5fa8db21-9f34-4ff3-a878-a7208c9e7b04", "298cc13c-3155-4410-897a-60fb551d6836", "9a0b26c4-9ddb-46d4-9201-5f910bd3a586", "d4d5d082-d14a-4700-9cca-9adf2a849c97", "a2dde18a-f5a7-4a2c-8d6a-1dff22ea1d90", "faac303c-56b3-4bdc-bc50-f65c4e4842aa", "2c0e31f3-af8a-44c7-8e14-cc7654e4b83e", "5fb969c4-420f-464e-9517-d1bab78b851b", "5a822087-6902-4c91-ab11-59fab7e6178c", "b0f5cd20-ce8c-42f9-98dc-61c6e54081c8", "27bef25b-6e8a-4a52-afb0-f5729f0916ba", "a5af0d70-ab78-4aa2-a2df-17c481317f05", "e964bbc0-0f38-4bad-a658-9031bc65d037", "15d52232-7a03-417e-ad17-928160dee42e", "57463a6a-25ab-406e-bfa6-9e71f47dcbc6", "270ccca4-3a46-45d8-80f3-0f253c4f6888", "415a1ca1-77b2-4357-850b-96da759a9075", "116a6221-cb4d-48b8-8227-96e0d47c9b04", "495a62f6-4350-467d-b347-2ccfefd60594", "33bd5a70-8ee3-44e2-9510-0bf9bdaaf186", "50e3451d-351f-43e5-9ec7-67a2cc72a498", "6ee2b1a0-f4d6-418a-a005-262ddff287d2", "b9ff7545-d408-4d44-8da0-c859692cd69c", "a32f6c94-7301-432f-ab02-bfa0d53f8f1e", "33c43575-ab5e-434c-8bc6-93e2f86c4305", "408240e0-9251-472b-b4bf-0163b6c6dd15", "0ee31883-91a3-48e7-a7a7-c28d2d09db92", "e7572db6-2f3c-4833-9221-0563067f08cd", "a6c06295-576d-4efc-80f7-220c28316c17", "7b0f046c-2b20-4f18-8af9-cf7f72fc092b", "7aafb702-b71d-443a-b5e3-373808a84f83", "cbda5a75-8cc2-4d02-8556-02f28f309cfc", "eac248d7-9cd3-44c1-8204-30e8a127e923", "4a986060-6e62-4c59-9e9e-df81d4844057", "4cc03d64-b700-4553-8786-eb41e5c559ec", "130384a9-e1b0-4350-a122-4ebaa3e6010b", "c97c51c5-ee24-49de-baea-a886c5f3cb44", "426933e0-544d-4902-80ac-ade63bf21bfa", "1a907d86-fb47-48e5-84b5-6d682c72cf45", "73df0960-41e6-41d6-97f5-d06aa1c949ca", "a0ec2f60-4a0f-4f15-a89a-e827d80e5812", "c3a863dd-cd66-4133-b873-1c1ab1e53f59", "972d3268-775a-4b7f-afaa-eac7c58b362f", "a09db542-f8ce-4e3d-b732-7ce299077ef1", "a2caf28d-4c03-4f21-844a-55b4d9950ddb", "bcd63efe-6055-4ef5-9795-656601aa8e91", "80437812-e7b2-4d72-8ecb-373bc49a9623", "c8858171-4225-4aaf-8fb1-5d0f33561376", "7584ef20-7f35-4d43-8269-50a3fdbefcc0", "c407acc7-3b1a-41fb-bb08-c152a55b079e", "2ffdba22-3154-40fe-a6b8-67688f707328"], "metadata": {"figures_content": "Contains information about Figure 1"}}}, "docstore/metadata": {"a122f401-8b11-430b-9e87-6721722ebb37": {"doc_hash": "dc4c2c8ea4ab41fc813c93161b38dd4d42b6b358499a0ec161916694e7850399", "ref_doc_id": "091958d8-6ae8-40fd-8402-d8b87f926048"}, "e0cbcf72-2326-4b0d-9115-96008c2e3394": {"doc_hash": "64e91ebeea6d9f000249c28eea33615dca16ab5cf284881091d4f45e454962bc", "ref_doc_id": "091958d8-6ae8-40fd-8402-d8b87f926048"}, "7577717f-1178-444d-9c39-0f08e8933e7d": {"doc_hash": "5ce836f767106fee181363dc4139e427d31ad58f3d35cd47b0440ea9439001dd", "ref_doc_id": "091958d8-6ae8-40fd-8402-d8b87f926048"}, "c50430e8-2444-4b9f-9ab9-91f5dfdd4664": {"doc_hash": "19a37bd3c8738e0a135af70896cc56a646c9c27d4b9b1f6c45909b09ba85a0af", "ref_doc_id": "091958d8-6ae8-40fd-8402-d8b87f926048"}, "dace5990-ec86-4203-bad4-48f8ea3e3188": {"doc_hash": "d2b4d6df3bc2d86c4ad72f1d47e37931a923e4b6a4a8c924e3b9b46e63881559", "ref_doc_id": "091958d8-6ae8-40fd-8402-d8b87f926048"}, "3c0e6ffc-ca0a-4672-ae04-a9ffe2400fed": {"doc_hash": "79ff829f4c06b701fc3589311b207cf91e1593b7a123edec40f790fefcc358fc", "ref_doc_id": "091958d8-6ae8-40fd-8402-d8b87f926048"}, "63b12fff-60ff-4d1a-a176-b3944e92d178": {"doc_hash": "be0506bc7b11ed79d695ca315d9dd818b9f52cb46b89ea9e9b0e0c7e4412ddf9", "ref_doc_id": "091958d8-6ae8-40fd-8402-d8b87f926048"}, "20418150-3c0e-48e4-82b4-76d1d1ff5468": {"doc_hash": "adfaa0d313a7cdc90afcda4db3c4714136cc0cd05ca9bfbbc97f00c74a0d4516", "ref_doc_id": "091958d8-6ae8-40fd-8402-d8b87f926048"}, "a2e0e182-59cb-4846-b349-b4d1924430ef": {"doc_hash": "0a271d775392c925f6a0048aae0f74d2bfe4f8df7da7da720717c17c89806468", "ref_doc_id": "091958d8-6ae8-40fd-8402-d8b87f926048"}, "e8827413-8fd0-495d-a064-5c5589497973": {"doc_hash": "888b7b35fff9a869a24b46e428f8ae28307a52a69cfb1c3ec55cb770362da6aa", "ref_doc_id": "091958d8-6ae8-40fd-8402-d8b87f926048"}, "a68299e3-5abe-45c0-8f6c-4ec8be6b3437": {"doc_hash": "cec1ea313dc8b2a87950ed5e66fa365085cd5022d7f8fc3d873fde70581c67a8", "ref_doc_id": "091958d8-6ae8-40fd-8402-d8b87f926048"}, "5081308d-89b7-4b49-888b-354d642e558c": {"doc_hash": "e7b46d0834ada5630af4697c8f71a17fce3f11fabc16917a0d8fe5c7b83c8163", "ref_doc_id": "091958d8-6ae8-40fd-8402-d8b87f926048"}, "b35ddc9b-9f49-49b3-9c57-617530f718f2": {"doc_hash": "ac0f10252a4de37ae41f4e3363a7e12ce45df85ae75c485729b9ea42def61e68", "ref_doc_id": "091958d8-6ae8-40fd-8402-d8b87f926048"}, "5fa8db21-9f34-4ff3-a878-a7208c9e7b04": {"doc_hash": "5cfa88fb42da7a26fecc40b3b29ea2e39acbc788a85a9e61b9df2b8213c08925", "ref_doc_id": "091958d8-6ae8-40fd-8402-d8b87f926048"}, "298cc13c-3155-4410-897a-60fb551d6836": {"doc_hash": "2140cf56c4e564850c3c5e8305412f9bd2e4e2e41ac82fc057deb4b56a0547ff", "ref_doc_id": "091958d8-6ae8-40fd-8402-d8b87f926048"}, "9a0b26c4-9ddb-46d4-9201-5f910bd3a586": {"doc_hash": "d560f19c59b5f730ed25c0aa3f0c061834d2639bd8ca812b4effe0ea29fe494a", "ref_doc_id": "091958d8-6ae8-40fd-8402-d8b87f926048"}, "d4d5d082-d14a-4700-9cca-9adf2a849c97": {"doc_hash": "197f1dcaf900dd2259c9119ddb8096d74021338308ede88411d3ebb4d08f9364", "ref_doc_id": "091958d8-6ae8-40fd-8402-d8b87f926048"}, "a2dde18a-f5a7-4a2c-8d6a-1dff22ea1d90": {"doc_hash": "b467f11d1ddd47e59e890f3b80eaee543cfbfccc4712c5f5baf65c2c0a86bb2b", "ref_doc_id": "091958d8-6ae8-40fd-8402-d8b87f926048"}, "faac303c-56b3-4bdc-bc50-f65c4e4842aa": {"doc_hash": "cf5c5e846cb5442849a4ff9b64ec1d11a970b73565114475daf5f2c42b8b7a81", "ref_doc_id": "091958d8-6ae8-40fd-8402-d8b87f926048"}, "2c0e31f3-af8a-44c7-8e14-cc7654e4b83e": {"doc_hash": "ef4c77034595444b5bb9f001933511777ad574a1c4723964233c6a63ce12eb9d", "ref_doc_id": "091958d8-6ae8-40fd-8402-d8b87f926048"}, "5fb969c4-420f-464e-9517-d1bab78b851b": {"doc_hash": "6a6789bc4b09ba35c51f54f3b8ff9a4f9f01790320d8d634171d3c54d0e80712", "ref_doc_id": "091958d8-6ae8-40fd-8402-d8b87f926048"}, "5a822087-6902-4c91-ab11-59fab7e6178c": {"doc_hash": "e5167b29c5856750cfdffdc7f7f5b655c37ff89a75714c346716b7f348a340b7", "ref_doc_id": "091958d8-6ae8-40fd-8402-d8b87f926048"}, "b0f5cd20-ce8c-42f9-98dc-61c6e54081c8": {"doc_hash": "c3165efa57b07285ec751a333a802a7a06fd5aed74d9afebe8c1b60ce6660042", "ref_doc_id": "091958d8-6ae8-40fd-8402-d8b87f926048"}, "27bef25b-6e8a-4a52-afb0-f5729f0916ba": {"doc_hash": "91ba4e53058de2aa456296e3c339a57409edb1ec84c333027070cde726f61a65", "ref_doc_id": "091958d8-6ae8-40fd-8402-d8b87f926048"}, "a5af0d70-ab78-4aa2-a2df-17c481317f05": {"doc_hash": "e638ce791ad2af8d172fa2c61d8670ca470a9a7a0340b720e5dbe17f507e8642", "ref_doc_id": "091958d8-6ae8-40fd-8402-d8b87f926048"}, "e964bbc0-0f38-4bad-a658-9031bc65d037": {"doc_hash": "7045b5975717c64b1db44c068f458c12fcd2d19a07019753b735aa63b49c6e1f", "ref_doc_id": "091958d8-6ae8-40fd-8402-d8b87f926048"}, "15d52232-7a03-417e-ad17-928160dee42e": {"doc_hash": "e5e9a920af004c00baaeccb136b78f91bc9ebad49b25ebd30fd6c0fd43b12d1c", "ref_doc_id": "091958d8-6ae8-40fd-8402-d8b87f926048"}, "57463a6a-25ab-406e-bfa6-9e71f47dcbc6": {"doc_hash": "c79932c9174a46d4021bd8caec097e5fb37b35277f3b299d9b2e4ebf8687def0", "ref_doc_id": "091958d8-6ae8-40fd-8402-d8b87f926048"}, "270ccca4-3a46-45d8-80f3-0f253c4f6888": {"doc_hash": "e60767536ca307ed05f3aa41458ab568c856da7613963642e4224d0c1a47bd14", "ref_doc_id": "091958d8-6ae8-40fd-8402-d8b87f926048"}, "415a1ca1-77b2-4357-850b-96da759a9075": {"doc_hash": "2a82386ec78685f4ee9e3d87acd943ff68ffe7f7e4dbf9440580fcd2f0bd09bb", "ref_doc_id": "091958d8-6ae8-40fd-8402-d8b87f926048"}, "116a6221-cb4d-48b8-8227-96e0d47c9b04": {"doc_hash": "f565e4bc4a8454e1d4ea4059098c6f23c9d2374b49c8b5aa3ca412c3d8b38403", "ref_doc_id": "091958d8-6ae8-40fd-8402-d8b87f926048"}, "495a62f6-4350-467d-b347-2ccfefd60594": {"doc_hash": "8908962077a90ad0c195c3af5b06c7924c9482f2dea4bf02bf913ee739b0deb4", "ref_doc_id": "091958d8-6ae8-40fd-8402-d8b87f926048"}, "33bd5a70-8ee3-44e2-9510-0bf9bdaaf186": {"doc_hash": "68661fafaf685a424cba7d666f7b3b89d8e8beab9415e0a4fccd558d01d823c3", "ref_doc_id": "091958d8-6ae8-40fd-8402-d8b87f926048"}, "50e3451d-351f-43e5-9ec7-67a2cc72a498": {"doc_hash": "d8d416ea9b3c830b7f536e36da421d021ab776fd1438524e319b209d13e001ce", "ref_doc_id": "091958d8-6ae8-40fd-8402-d8b87f926048"}, "6ee2b1a0-f4d6-418a-a005-262ddff287d2": {"doc_hash": "fc14637725ea43dd7458ed3198cd565926d2050f0ed6e7bc7ea40b76c8ab765e", "ref_doc_id": "091958d8-6ae8-40fd-8402-d8b87f926048"}, "b9ff7545-d408-4d44-8da0-c859692cd69c": {"doc_hash": "5bb38f4f118bb358b433d33a1c1d053953129ab154b584c3557da08ebe777b27", "ref_doc_id": "091958d8-6ae8-40fd-8402-d8b87f926048"}, "a32f6c94-7301-432f-ab02-bfa0d53f8f1e": {"doc_hash": "7528d35421af6c5ffc2c1dc09e060dd691ad07c055b0feeff4b3df3cbc76b23b", "ref_doc_id": "091958d8-6ae8-40fd-8402-d8b87f926048"}, "33c43575-ab5e-434c-8bc6-93e2f86c4305": {"doc_hash": "b50f26e9c75f4599309dc6e77563e167744b313319c2e298e852e3414df8c7da", "ref_doc_id": "091958d8-6ae8-40fd-8402-d8b87f926048"}, "408240e0-9251-472b-b4bf-0163b6c6dd15": {"doc_hash": "ae08721ec61d255c40f8e29a5505c83d34cd9d0f49d62b16646995c4e17f1d2d", "ref_doc_id": "091958d8-6ae8-40fd-8402-d8b87f926048"}, "0ee31883-91a3-48e7-a7a7-c28d2d09db92": {"doc_hash": "b85f74c779d271aa93b54da06cca7b174b790b4c7d4cfc29ef9c00f485d43fa3", "ref_doc_id": "091958d8-6ae8-40fd-8402-d8b87f926048"}, "e7572db6-2f3c-4833-9221-0563067f08cd": {"doc_hash": "1276b24a092273f8afd83ad782139463bf99804173284c64207c0d37a79582ce", "ref_doc_id": "091958d8-6ae8-40fd-8402-d8b87f926048"}, "a6c06295-576d-4efc-80f7-220c28316c17": {"doc_hash": "e1b3f6fa7a0f95fec7d262eeaa3d1c2d8f0a8a19b9f701db217796f353baae79", "ref_doc_id": "091958d8-6ae8-40fd-8402-d8b87f926048"}, "7b0f046c-2b20-4f18-8af9-cf7f72fc092b": {"doc_hash": "a8296f6748db96c09673db80d51f5f0ee70ba48b2156343de158d7e4623d9ec3", "ref_doc_id": "091958d8-6ae8-40fd-8402-d8b87f926048"}, "7aafb702-b71d-443a-b5e3-373808a84f83": {"doc_hash": "8f68d4c263eb55f3a0bbaaa1b3892abd223f47970ba18d0d60ba1197a5a810ab", "ref_doc_id": "091958d8-6ae8-40fd-8402-d8b87f926048"}, "cbda5a75-8cc2-4d02-8556-02f28f309cfc": {"doc_hash": "4d6fa42f99291bbab3ce0322c992302dc2dd3a93f52621995f345103c34bfffe", "ref_doc_id": "091958d8-6ae8-40fd-8402-d8b87f926048"}, "eac248d7-9cd3-44c1-8204-30e8a127e923": {"doc_hash": "c62ef88cfe72ff0c6987f4e1132ce9de1ffdf41e94cb45f19914a42ea28f1fef", "ref_doc_id": "091958d8-6ae8-40fd-8402-d8b87f926048"}, "4a986060-6e62-4c59-9e9e-df81d4844057": {"doc_hash": "48afed61227d38c19787a1b8400dbe98058d304c9ded7247de1a894a2ca1848b", "ref_doc_id": "091958d8-6ae8-40fd-8402-d8b87f926048"}, "4cc03d64-b700-4553-8786-eb41e5c559ec": {"doc_hash": "75c2ed495f4d42c595fc34c2fbb94ce5acb163f10e9e685ad59487f71587391f", "ref_doc_id": "091958d8-6ae8-40fd-8402-d8b87f926048"}, "130384a9-e1b0-4350-a122-4ebaa3e6010b": {"doc_hash": "9542fd685e03c3a215d7ac477ec00bfc3f14f95cc06bf541a924254673abe751", "ref_doc_id": "091958d8-6ae8-40fd-8402-d8b87f926048"}, "c97c51c5-ee24-49de-baea-a886c5f3cb44": {"doc_hash": "9ef106e59a2f865e32fa8cbc8d856d5ec99abfc8b01ba7d14a3d767faf84c523", "ref_doc_id": "091958d8-6ae8-40fd-8402-d8b87f926048"}, "426933e0-544d-4902-80ac-ade63bf21bfa": {"doc_hash": "aecc4bb1627e65030105af611bd8d3d9f93035fd37ada14c117e47400f97ca4c", "ref_doc_id": "091958d8-6ae8-40fd-8402-d8b87f926048"}, "1a907d86-fb47-48e5-84b5-6d682c72cf45": {"doc_hash": "27a11ac3199736cbe1ed97565bd0d57bca087b6def7041d662684b81a37b5dff", "ref_doc_id": "091958d8-6ae8-40fd-8402-d8b87f926048"}, "73df0960-41e6-41d6-97f5-d06aa1c949ca": {"doc_hash": "7c634f592d290c6423df178084eafe83f8a097853a2bb2f5b8041049fbfaae2e", "ref_doc_id": "091958d8-6ae8-40fd-8402-d8b87f926048"}, "a0ec2f60-4a0f-4f15-a89a-e827d80e5812": {"doc_hash": "e1056c6e0abcbb89a96583f3b5f5290c5ebc892a3ed0e668bd8940edb037a1bd", "ref_doc_id": "091958d8-6ae8-40fd-8402-d8b87f926048"}, "c3a863dd-cd66-4133-b873-1c1ab1e53f59": {"doc_hash": "b3965755dfd8800855f91df614241b846c1a272c113b1a5d28726f67adcd9173", "ref_doc_id": "091958d8-6ae8-40fd-8402-d8b87f926048"}, "972d3268-775a-4b7f-afaa-eac7c58b362f": {"doc_hash": "527cb55eeedaaa737796f81b2799ccdd137ab4077496bbd0120d84eae12261e1", "ref_doc_id": "091958d8-6ae8-40fd-8402-d8b87f926048"}, "a09db542-f8ce-4e3d-b732-7ce299077ef1": {"doc_hash": "ff0c1715ba175cf1120e1f452bc0ee7d0b07d9573a86003e5697d753bb7efa2e", "ref_doc_id": "091958d8-6ae8-40fd-8402-d8b87f926048"}, "a2caf28d-4c03-4f21-844a-55b4d9950ddb": {"doc_hash": "2af5300f6d07d1d4641cae4f4272efb17b49a68fe96218232369cc9b35ce0730", "ref_doc_id": "091958d8-6ae8-40fd-8402-d8b87f926048"}, "bcd63efe-6055-4ef5-9795-656601aa8e91": {"doc_hash": "ad68c5c442d9fb92e009406aa32b7edb0e5f812f14e04cdf74b10ab293383835", "ref_doc_id": "091958d8-6ae8-40fd-8402-d8b87f926048"}, "80437812-e7b2-4d72-8ecb-373bc49a9623": {"doc_hash": "a77b7763b0305eeee980f6fbbf1f24e5883bb4220fac1c89803a022eef69246e", "ref_doc_id": "091958d8-6ae8-40fd-8402-d8b87f926048"}, "c8858171-4225-4aaf-8fb1-5d0f33561376": {"doc_hash": "7911724507e7457a22a288861f52bf43ee21bb63a6fd396b3d8f2337a69438cf", "ref_doc_id": "091958d8-6ae8-40fd-8402-d8b87f926048"}, "7584ef20-7f35-4d43-8269-50a3fdbefcc0": {"doc_hash": "0472afb174b8390b63369305c7369de91a7dd7f852e58cf2694aa863617f7a59", "ref_doc_id": "091958d8-6ae8-40fd-8402-d8b87f926048"}, "c407acc7-3b1a-41fb-bb08-c152a55b079e": {"doc_hash": "097888b7ccc3c0f912d2556bd3e44a11f10f9539be28ae45aefca5cddd3aa6fe", "ref_doc_id": "091958d8-6ae8-40fd-8402-d8b87f926048"}, "2ffdba22-3154-40fe-a6b8-67688f707328": {"doc_hash": "2f7ed3b36e90c63af2135516372e4a9d67afb3acbfb7f0c00ada05a2e553b600", "ref_doc_id": "091958d8-6ae8-40fd-8402-d8b87f926048"}}}